b0306y
audio note: barely readable, the auto transcription needs to be fixed, this was a clubhouse conversation with Jeff Hawkins and Subatai 
regarding the book "A thousand brains by Jeff Hawkins"

Neurons Frames Re

00:00

Anything.

00:04
the question I have is the following. It's so cool that one microscircuit in sensory cortex can both process vision and process sound and process touch that is a mind-blowing fact and the concept that each individual.

00:42
Column builds its own model of the world and it uses motor commands to predicts upcoming century input is amazing. But what is even more amazing to me or at least additionally amazing is that the parts of neocortex that generate the motor commands themselves the parts of neocortex that generates skills and plans and volition those things that are even more human than just perception.

01:12
Use the exact same micro circuit in frontal cortex. So I guess my, My question is, you know on the research agenda have you folks thought about or when are you thinking about taking the micro circuit architecture you folks have started to work on for perception and try and re-implement it for actual action planning and creating volitional agents that plan in their environment?

01:35
Yeah, so I think, The short answer is you know guys we're doing one thing at a time and we're focusing on basic essential perception but I think as a slight misinterpretation perhaps Mac yeah every every column in the near cortex regardless of where it is regardless of what if it's doing high level thinking a few frontal orbits just doing basically sensory perception from the fingers has a motor output meaning if you look at these columns there's a certain cell type in layer five, which is the motor output cells.

02:05
We use people use to think there was a motor section of the near cortex and so there's motor cortex. That's not true at all. Every section on the airport takes is a motor has. More output So the the low level visual regions is in reason to get direct input from the eye they project back to the part of the older brain that moves the eyes.

02:23
So they actually control how the eyes are moving as they're building their models in the world and they can solve sort of I wouldn't know if I call it volitional problems, but they can say okay, you know, how would I move to see something? The same thing is true of touch the parts of getting input from your skin and control the movement of the skin.

02:43
So that thing can learn like where how do I move my finger to hit this hit my the smart button? I mean the start button on my cell phone something like that. Even audition is like this because you get you don't think about dishing as a motor thing but the parts of the cortex could get input from the ears project to the brainstem, which moves the moves ahead.

03:01
So you change your orientation the ears to the world just like you change your orientation to the eyes several. So there's this core algorithm is a sensory motor algorithm The motor behaviors you might think about for low-level perception are moving the eyes and moving the fingers and tilting the head as we as and that solves certain types of low-level problems, but not you don't think it was like, oh how am I gonna you know create a new bridge?

03:25
That's not gonna happen there. But the basic core algorithm is like okay have these I have these reference frames the reference frames tell me how I should move to to achieve certain results and that result may be something simple like where is the the powers would Tell my smartphone but it could be applied to something else like what what action should I take to to design a new bridge or a new type of you know material.

03:49
So I think when we're really getting out these core algorithms, even in the sensory cortex, you're you're getting at the core functions for all movements and even even though those some cases of movements are much more high level and you know more volitional if you want to term you used maybe we're not even a we're not even aware of the movements of our eyes most of the time, you know.

04:13
We're not aware that we tolerant to cause three times a second but else time I might be aware that I'm doing something more of a high level thought but we think I guess the I'm trying to say that the the by studying any part of the cortex you're basically revealing the mechanisms for other parts and we are just you know, we're happy just to be able to figure out how to get a machine to see and grab a cup and don't know what it is for starters, that's that's where we're How do we basic vision would be a good place to start?

04:50
Yeah, basically. Approach, you know, figure out how to grab a cup and to understand what it is is probably one of the hardest problems to overcome. That is interesting, you know, you mentioned that because you know, we've made my lot more progress first on things like vision right and because people who think like oh vision should take in this picture and let's label the picture, right?

05:13
But then you say like, well, what about a hand it's like well what's the?

05:21
Exterior anymore, right? So it seems like we already can't use the same. I'll go through doing a touch but but now we know that it's the same algorithm and we can explain. Thinking about vision wrong, the vision actually is exactly the same as touching a cup and and if you build vision that way you're going to you'll understand how to build a hand.

05:38
Yeah, exactly. And even with vision do you remember, you know AI confused Chihuahua from blueberry muffins and humour would never even never make them mistake, right? Yeah, thank you. Max great question. We don't please briefly tribute yourself and ask questions, please. So very happy to be here to talk to you.

06:14
And obviously I love to book a thousand brains and my feeling is that you probably got it right there is this very general algorithms throughout the cortex that's doing different jobs and that can be stacked together to be more abstract and it's really great but my question will maybe fall into a similar category as previous two persons, which is there are certain things that I haven't been able to conceive of using reference frames, so I'll give you an example so say I think about the problem of why?

06:49
There are seasons and through some learning or experiment or observation come up with explanation that involves this giant ball running space is surrounding another transfer and there's this explanation that will work that will tell me how it is so this general process of coming up with the story that is about what exists in the world and I cannot interact with through my census and my motor actions and yet I have this theory in my mind and it is helpful in a very.

07:24
Very interactive way to me understanding my sensory environment do you think of this kind of processes also in the in the framework in the same framework or do you think maybe there are some different level of analysis that is required well at the moment we don't know the answer question?

07:44
I would I would say, Very very likely that it's the same thing.

08:01
Oh yeah systems computational yeah. I used to study some birds and now moving to more cortex but just started starting to learn yeah, okay, so just take the example of like your model of season. So there's two problems two parts one is a little bit fuzzy you have this vision in your head of the earth as a ball speeding around and the sun you in that division in your head those objects have structure and they have relationships to each other you have an image of how the how big the Earth is relative to the Sun how far away it is, you have it imagining spinning as it moves around to have that knowledge requires reference ranges to say something is at some location to something else but some distance or Ientation imagine the earth or changing it still it's changing it's it's orientation.

09:02
Those are all part of what reference frames do that is. And. The coffee cup handle to the cylinder version and the orientation of of my finger relative to the coffee cup things like that so that structure from representing any kind of knowledge in fact. I've come to understand this it's a very deep idea that all knowledge has to be represented in some structure that makes it actionable that you can you can imagine things you can say what would happen if I do this or do that what happens if the earth didn't rotate whatever the earth tilted too far in and and the referencing gives you the ability to manipulate these concepts as they should refusally manipulate.

09:45
Now part of your question was like how do I relate to my personal actions right I'm not actually doing something when I'm imagining the things and the argument I made in the book and I can only make it a certain level today. I can't go too far with it.

09:59
Is that all fun is essentially moving through reference frames? That is when you an idea or some thought in your head is knowledge stored at some location in a reference fan. And when you retrieve thoughts you're moving through reference frames. And you're moving from location to location. The analogy is similar to like if I want to think about within my house, I have to.

10:20
Imagine moving from room to room to my house and as I do that the ideas come into my head So the idea of a movement now you're not physically moving something but you're still moving through a reference frame. So there has to be an analogy to physical behavior. That is I I'm not physically moving something but I'm doing the same neural process.

10:39
I'm saying here is an operator that I'm going to say which is like a movement and when I do that I go to some new locations. In math in the game in the book, they can example the math of attics and you can think of like a mathematical operator is like a physical movement.

10:52
If I multiply something or use a Laplace, Transform on it right or I do some sort of matrix multiplication this is like a movement that says given where I am and I do this movement I can now predict where I will be and what will be the result. It's a bit I have to admit it's a bit fuzzy but the neuroscience is very clear about this.

11:12
We don't see neural structures that are substantially different than different parts of the cortex. And so we take that as our guiding principle to start with is that until we see those differences we're going to assume it's the same. And we're going to see how far we can go with it, even if today we have to be a little bit, you know.

11:30
Like well, I'm not certain exactly how. An argument that. Likely will figure it all out. That's the best I can do. Thanks Jeff. Let me add the very quick flow up. I think what you just said is a really good description of how of this can be expressed in reference frames and my puzzle comes from how do you arrive at those specific structures to operate on?

11:56
Oh, how do I decide the right reference frame? So yes, yeah. Well a couple things I believe clear that a column in the cortex does not have a pre-assumed knowledge about the the structure of the information. It's going to be storing like it doesn't know the dimensionality of the space is going to be working in and it doesn't know it doesn't have a it's sort of a very open-ended system It says okay I'm going to learn how many dimensions this thing.

12:28
I'm modeling something in the world. It could be a coffee cup or could be the solar system or it could be concept like a democracy. And it doesn't have a pretty soon knowledge like oh here's my reference jam. I'm going to put the data into it. It actually has to discover the right way of doing that but get a little technical here out, that's okay.

12:44
The way I think about it is I believe that the many columns in your court took are representing one dimensional. Factors so you actually have like hundreds of physical a single column can have hundreds of potential dimensions, it's an over complete set of dimensions and it figures out through observation, what is the correct what is a useful way of of discovering the structure of the thing and I actually have a very concrete theory how this occurs.

13:12
I haven't published yet it's getting really kind of details probably too detail for this group, but I've talked about in some of our research meetings where you know, the cortex has to learn it that's it doesn't come in like saying, oh the world is going to. Fit into a critician coordinates of XYZ now it says I have I have a hundred dimensions of work with a 200 dimensions to work with I'm going to figure how to use them to define the space of the thing I'm observing and and it's it's basically all been going to be based on observation as the data comes in and we get movement data and we're going to say okay what's the best way learning this structure?

13:46
I also make a point in the book that we can learn that things that affect can be applied to different type of different reference trains. I use example of this history you can take a set of historical facts you can align them along a one reference frame, which is the timeline.

14:00
And another reference frame which is a map of the world and both are valid but you end up with different sort of inferences and beliefs about causality depending on how your range of so it's not that there is one correct way, it can be multiple ways and there can be incorrect ways and this is why when it comes to knowledge that we can't directly observe things we can't physically touch we can end up with different beliefs about them because we can take the same facts and arrangement of different reference frame and come up with completely different beliefs about those facts, it's harder it's hard to have those different ways.

14:35
When you're when you're all touching and seeing and hearing the same thing, but when we're relying on language, it's easy to get that confused. You just hope there's a whole bunch of concepts there that's great thank you yeah thank you right down. I'm gonna take a bold guess you're from China and Jeff's first book intelligence, there's actually quite a cult following in China, oh yeah.

15:03
I'm sorry yes so so once Jeff's a thousand bring a Chinese version come out we might have to do a Chinese version of discussion. I don't yeah. That's great. I've heard this story quite a bit but around the world actually it always makes me nervous because in the book a not intelligence I made a call to action I said, you know, why don't you come and get in this field it's gonna be exciting and and then when people actually did it.

15:33
I'm like, oh my gosh. I hope this is working out for you. I'm nervous I can tell you going to neuroscience conferences you know back when we went physics to these conferences It's really fun walking around with Jeff at these conferences because you can hardly take two steps before someone comes in and says, oh I'm in this field because of you and you know read the book as it's really quite fun to walk around the you know, it is nerve-racking to hear that and we hope people's careers turn out well and hope they're happy.

16:04
On the other hand, you know, I think that's the goal of this book, right? They call it my new book is to say my gosh evens even a better time again because we made so much. If you want to build machines that work on these principles. Is this really going to happen?

16:18
And if you're young it's going to happen in your lifetime, you know in the and so it's one of the reasons I wrote the book I guess is to get more people excited about it get them get an engage because there's so many really smart people out there and you know, just trying to get some of their minds sure, you know.

16:37
Yeah, thank you so much Chris you're next and Mill Alexis and Mika Jory, thank you so much for your patience, we'll get to you Chris you're up. I Jeff so my question is related to chapter 9 in your book which is titled when machines are conscious. So, of course the interesting property of consciousness for me at least is how when I actively observed what is in my consciousness and I am aware that I am attending to those contents it feels like something it feels like an, Experience and this is my conscious awareness.

17:16
It's fascinating how like seemingly dumb matter can create this feeling. So my question is do you think this ability to feel my awareness to be aware that I am aware is critical for a machine AGI or do you think this property of consciousness is something that is just like one possible method that emerges in humans to accomplish certain cognitive goals, but is not necessary and principal to have an in an AGI.

17:47
Yeah go ahead any question Well I was always gonna ask if it is possible that this is necessary how might we attain this or configure an AGI to do this feeling. Yeah. So I took a stab at some of those some of this question to you in that chapter and the first thing I wanted to point out is that I don't believe that I mean, I do believe that brains physical matter could be conscious that is we don't have a separate mind we don't have a separate consciousness the there's no other me inside the you know, the brain of the mind or one of the same and I, Both know scientists hold that belief and I no doubt about that to true And so then the question is well how does this matter do this right What does it And I make is there's two major points of this.

18:34
One is your brain has a lot of the world that talked about that but it has a model of itself too. The good portion of Newport Texas is dedicated to modeling yourself. This is the way you call the wear pathways. So you have a model of your own self in this world.

18:49
So you're imagining yourself as part of this world you imagine the world you're watching yourself, your brain is modeling yourself moving through the world and knows about itself. But this idea of Presence is the term. I like to use is you know is an interesting one and I know it puzzles a lot of people it doesn't puzzle me so much maybe I'm just I used to say maybe I'm a zombie, you know, I just don't have this but I make an argument that I think a key component of this is this idea that at any moment in time there's a state of active neurons in the brain there's some neurons or active, that's what your current thought.

19:24
And as those thoughts come into your head one after another and the basically just instantiation of active neurons. The brain actually remembers them and remembers the series of thoughts it may not remember for very long but remember them I can recall some things we just said a few minutes ago here.

19:42
I laid down a memory trace of the things I was thinking the things I you know, the thoughts that were going through my head. I also can think about the future I can imagine oh what would be the next thing that's gonna happen or what will happen if I do this and I remember those speculations too, so those are just activations saying, oh these are things that might occur in the future, so I have this memory of not only the the things that when the recent past think.

20:07
S that are happening there's a state of the brain right now what's happening this incident and also I can remember what I was thinking about doing in the future and we kind of slide back and forth through these all the time and this gives us our sense this gives us our sense of presence is if I quit or remember what I just did a minute ago, if there was no memory of my thoughts it might when I said then I would be like I would be like a zombie I'd be well I could constantly waking up saying why what am I doing what's happening, why am I here and so we we slide back and forth between instantiating this previous memories and and a few to the members of the future and the, Day and this gives us our sense that we're here that we're present that I can say yes I was just doing this a second ago my body was doing this I was thinking this my thoughts were this now.

20:52
I'm doing this I quote what was I think I'm gonna do and it's it's this ability to to slide back and forth between this I was thinking I am doing I was thinking about the future that gives us our sense that we're here that we're present that that I exist in the world I argue and I give some thought experiments if I race that ability that you can no longer remember what you just thought what you just did you would be like a zombie you would be just, Waking up going what the hell's going on now your question relates to this because is it I think most intelligent machines that are gonna be useful if I'm gonna build a machine that thinking about mathematics or build a machine that's gonna build, you know structures on Mars or something like that those machines are gonna have to have this property and therefore they will feel conscious in the in that way it is possible we might build some build machines that don't have to do that they just have to solve this one thing do it and forget about it and then through the next thing do it forget about it and in some sense that's where our deep learning networks are today, they don't remember that they just, You know if you showed a picture of a cat to a deep learning system and it says it's a cat then you throw a picture of a car it doesn't say, you know, I was just thinking about cats but nothing about cars it doesn't do that it's no memory whatsoever and that's still useful so I imagine you could come up with systems that are useful that don't have that property, but if you want something that we would say, nothing is really solving difficult problems and it's it's contemplating them and it's working through them, it's gonna have that property and therefore it's gonna have that sort of sense feeling a sense, that's my belief.

22:24
Well, it's fascinating. Thank you. I mean the feature of being able to slide between future and past memories of those things. It gives the emergent feeling of something happening right now that that's kind of fascinating. So, that's why I guess that's what yeah, we'll say that's right. I think it might be.

22:44
Yeah. Now, Hello I'm hijab. I'm thank you so much for taking my question. I just wanted to preface this with only the neuroscientists nor an engineer but I have been deep diving in your YouTube channel for many years, so I really appreciate everything that you put out because it helps people like me get access to incredible information.

23:05
So just a little prepaid but I'm I wanted to ask I have I sort of have two questions that are until the first one is how do you think about what context looks like in the brain? I'm gonna ask you to clarify that then maybe I'll enter maybe super talent more when you mean by context.

23:29
If we use that term for something very precise and I don't know if it's the same way. Well, I've been that's kind of it's interesting because I'd love to know where you what you use it for as well, I guess. Well, we can we can start with that. Yeah because it's it's pretty low level sort of idea, maybe super tell you want to talk about that.

23:49
Yeah. I think we've talked earlier about how the brain is constantly making predictions. And it's learning from predictions and mistakes and you know prediction mistakes and correct predictions and so on. So in in a lot of the the work when we're actually modeling these things we have a very specific definition of context which is basically a representation in of the information that's currently in your brain that's allows you to make predictions and allows you to anticipate things and form expectations and you know, I think that more technical than that, but basically it that's how we think of context.
24:25
It's any sort of information that allows you to then predict something that's About happening or perform expectations. I can bring it up to a pretty high level is it maybe a little bit more tangible imagine you're listening to a melody, right? Now the notes in the melody command or the interval actually, but let's say no it's to come in and you're recognizing this, right?
24:46
And then you predict the next note in the melody. Now, what was the context for picking the next note? Well, it wasn't just the previous note. It might have been six notes before or ten or maybe even a whole you know, Stands on before And so somehow you have these patterns coming into your brain which is this note or interval interval interval and and then you make a prediction based on some previous context?
25:10
So internally the neurons have to represent not only where you are in this melody. Like what was the last note do you heard but it has to sort of represent the entire history up to that point in a way that makes you laws you make the next prediction correctly.
25:28
Because the previous note of the previous two notes and previous tenoas may not be they may be identically you make a difference. So there's an actual way that the neurons that we've written papers about this that neurons can represent this sort of input in context in a way that incorporates both like, oh I'm listening to you know, the interval of a third and that was to be, you know, the the fourth interval of a third in Beethoven's, you know, third symphony or something like that.

25:55
And and there's a neural substrate for that so that allows that prediction to be made and it's pretty fascinating how it works, but that's that's a sort of bring what super ties set up to although. Relatable exercise And maybe one other thing to add what's interesting you know from a theoretical standpoint is it looks like maybe 90% of the connections in our brain are all about processing context.

26:20
And and so this is you know, it's quite remarkable when we realize that most a lot of what we're doing and a lot of what's going on in the neurons is processing context, and that's how it's making predictions constantly. For those who know neurons, I mean, the neurons are the cells of the brain and they have these things hold synapses which are the connections on them and a typical neuron the neocortex makes.

26:43
Any from five to ten thousand of these connections but most neural networks rely on just a few hundred connections They don't have ten thousand connections and and in the neuroscience it doesn't it's hard it was hard for people to imagine what all these other connections were doing. They didn't seem to be strong enough to make the neuron fire.

27:00
They were like we have all these thousands of connections, but they don't really make the neuron fire. What is going on? And we propose a very concrete theory what's going on and and those all those you know, 90 percent or 95 percent of the connections in the brain on each individual's neuron as is more than just.

27:18
The brain really neuron is too much I said or dedicated to this context to two prediction to saying this is a context. I recognize where I became active once before. So I'm going to predict my activity based on that context. So yeah, I guess it's sort of like the whole brain is a big context processor.

27:36
It's yeah, it's a very good back. It's I don't know how deep we want to go here, but tying it back to reference frames. You know, we we talk about representations of location and knowing where you are. Those are all that's all that all becomes context for our neurons to then make predictions.

27:52
So knowing, Where you are on the coffee cup that there's some vector of neurons that represents that location using reference frames and that allows you to predict what you're going to feel as you touch that point of the coffee cup. That's in very kind of low level example, but it it ties all the way back to reference rates.

28:10
And it's interesting how movement and time ties into all of that which is you know, obviously all the way back did the foundation of many of your your theories, which is yeah, it's it's super fascinating and amazing. So my, Hair's question that was tied into that kind of interlace genomes.

28:31
I'm sorry. I've spent two questions. I hope that's okay. I was wondering how you think about authenticity within all of this? So, how do you capture measure track authenticity in the brain in relation to that? If you thinking about what's emerging from this these 90% of contacts? What do you mean by generating this?

28:53
So it will this is the thing like how do you think about that is in behavior authenticity is like the that whatever behavior emerges next as a spontaneous reaction to what is already had right so how you thinking about that as a representation we don't use the word authenticity at all so super tight, did you have a any idea, you know, how you might respond to that or?

29:19
But yeah I'm not quite sure what you meant you mean it's almost like in individual behave yeah yeah so it's like individual behavior is nuanced by a sort of idiosyncrasy that's authentic to an individual experience or collective right okay, so look we are this all goes back. I can't emphasize this enough the cortex is building this model of the world and it's a it's literally like a cat model the world it's like figuring out where everything is it's structure where everything is related to everything else, we don't all build the same model of the world, we don't have the same experiences and and so our models can.

29:54
Be different they are different even observing something simple like a chair well depending what culture you're brought up in you know, you might see something as a chair and someone else and and so. We're different it's just no question about it and sometimes these different is our parents, sometimes they're not the so subtle that we don't notice them but I think this idea of individuality is just the nature of the business our model of the world is not an accurate model it is the best model our brains have made and it's not a model of the complete world, you know, we can only model the part of the world we've experienced.

30:35

And and so, you know and it can be wrong because we have limited sensors so it certainly can be a limited part of the world so I think it's natural that any two individuals brains even two people who are had nearly identical experiences in life well end up with different beliefs about certain parts of the world and different understandings of them and if that's what you're talking about.

30:56
I think it's that natural outcome of this it's a selfless on avoidable. Almost an advantage point, thank you Mel because thank you so much I everyone I  and so so my name is Micah Bloomberg and like many people apparently that you've met my life was changed after I read the book on intelligence co-authored by Jeff I guess he was the the main speaker though.

31:24
I've watched I've read both of the books. I've watched so many of the videos talks that Nementa has shared including many of the detox by Jeff. And in many of the the other ones too I want to say I should I should probably talk a little faster so I I've studied neuroscience and computer science since then including computational neuroscience neural networks.

31:52
I became a computer programmer since then I maintain a couple of open source projects. I have a group on faceobok called self aware networks, it's pretty cool a deep learning group on faceobok has 147,000 members neurophysics group, no neurosurgeon group. I did the neural lace podcast actually wants to ask the people if I can interview.

32:12
At the time I was not successful at maybe I'll send another I'll send another request.


32:24
I am totally understand what's your question so I I wanted to get this thing attended to get another question then so if single every single micro circuit is doing multimodal assembly of objects or ideas or abstract notions in every column in the neocortex has motor output is everything neural column doing multi-modal processing is every column of the visual cortex doing processing with the somatosensory cortex and audio cortex, okay?

32:49
The columns are not multiple so a column giving you performance is modeling the world from what that finger can feel right so if I move my finger over and touch something and build the model the thing touch it a column in the visual card text is looking at small patch of the retina and it's like looking through a straw and it's trying to build the model of what it sees by moving around so in some sense the columns are not multiple of them, however the columns vote and we didn't talk about that yet, but they vote to reach a consensus so call.

33:24
Was individual cortex project. Ed this was. Surprised to neuroscientists when they found this because by traditional theories you wouldn't that the the low level visual inputs wouldn't have anything to tell you about the low levels, you know touch or some other century but but the voting explains this and so what we find but we find what neuroscientists who do empirical studies have found is that we can say, oh the visual cortex is just doing vision but but it's it's modified by in some sense the context is it's giving context from the somatic center cortex or the auditory cortex and so they can see these these these.

34:03
Influences but it's really they're just trying to vote they're trying to say like I could buy if my visual cortex if I'm feeling I'm feeling something and I said this feels like a coffee cup, but my visual inputs are highly obscure. Then I can then the visual cortex and say well, you know, the the the somatosensor critic says it's filling your cop pickup.

34:24
I'm probably looking at a coffee cup so let's see if we can interpret this as a coffee cup and yes I can and and but if I didn't have the input from this medicine cortex the touch, I wouldn't really do that so in that way, they are multiple they get this voting neurons these voting that go.

34:42
But the actual input it's not like this is commonly visual cortex it's processing sound and directly from the ear and and and likely honest when you get to higher levels of cortex, of course, you you do have things that are modeling things independent of the sensory modality and that but you can argue those are are multimodal in some sense but if you think about from a column itself, it doesn't think that way it says I get some input from someplace and I'm going to try to build a model from it and it might be in some higher level region of the core tech it might be getting.

35:17
Input. Three other places at once but it doesn't know that. It's just that I'm just getting this input and I'm going to try to figure out what it is. So it's a little bit complex that question about multiple dialysis. So the the division of labor across the the cortex still might be similar to what neuroscience has already talked about.

35:44
We were totally been bought into this as well We thought that columns in in the saving primary visual core decks for the primary center protective once again they would understand anything they would just be extraction sort of feature and and someone else was recognizing what's going on. We now know that's not true but now we know that even these little early on columns can understand the larger things because they integrate movement in time.

36:08
They can it's like it's like yeah, I've been traditional ideas like imagine looking at the world through a straw and say, okay, if if I look at the world there's strong and the visual cortex could only see like a little edges or something like that. And no one thought that those columns could understand what a coffee cup was but now we understand like oh they moved that straw around and I look at all the edges, you know, I can now recognize and learn what a coffee cup is and that happens in v1 or v2, it's doesn't have to go someplace else in the brain.

36:32
It's happening really low down and that's new that was not that is that's a new idea. So and the rapper, It's not it sounds like we might have a thousand visual concepts of coffee cup and a visual cortex and a thousand audio concepts it'll coffee cup and an audio cortex and those are just linked together but right but I wonder for you this is sound similar to like, you know, like a hologram when you have many copies of the same thing or like a fractal.

36:58
No.

37:02
So yes distributed systems there's lots of types The key to this is these columns have these reference frames and they have movement and holograms have nothing like that. They're just a very interesting mathematical technique but but it the key is integrating movement and sensation over time that is the whole key to the how the now you can understand how models are built the milk by literally constructing reference frames and putting features and objects in relative positions to one another in learning with the structure of the world looks like.

37:33
It's super questions, do you believe humanity? Because there are a lot of people still waiting quite patiently. If we have time after we go through we think about two years now, okay? So I'm conscious of her Jeff and supervised time we coming up for two hours soon. So jewelry mark Vince can you in turn ask your questions and we can combine this questions in case of supatai.

38:05
Jeff can combine their answers jury your question, please. All right sure It's two part you can answer whichever one you think is more interesting The first one is you know I have authenticio which means I don't have any sort of visual experience when I think I don't see images when you're talking earlier about reference frames we're talking about how when you were thinking about your house or the things that in your house you're kind of like mentally walking through your house.

38:33
There's a circumst people that just don't do that and so I was just curious first part of what you know, how you think about reference frames and relationship to cognition that doesn't involve visualization. Uh in a second question just would be that, uh, How important do you think it is for our episode intelligence to have some kind of embodied experience in order to take it to the next level in terms of thinking whereas, you know, we form abstract ideas by you know, picking backing off of our physical experience.

39:08
So we think about ideas as objects that we can grasped with our hands. You mentioned earlier it's very hard to get a you know, something to just pick up an object and and you know, we think about ideas as objects which we can grasp people over our heads, you know, we can't get our hands around them.

39:23
I was just curious how important you got it was to get machines to be even be able to grasp things to you know to really be able to get them to think about he is in general. Um, thank you Jeff a super tight, can you hold on your answer if you can remember the questions?

39:42
I will try to write on as well. Marvin Vince. Mark. Kudu, please ask your question.

39:51
Mark. All right, let's move under Vince are you ready to ask your question?

40:00
Again, that might need to unmute themselves. Yeah, yeah. I see. Mark is a new user. Mark, okay. Mark, do you want to ask your question please? Yeah, sorry about that. Yeah. I am in the user. That's very good. Neocortex there. So Jeff, you know one of the reasons. We're not supposed to fear.

40:23
AI that AI as I think you propose in your book are it's simply a reasoning machine like the Neocortex and our our the things that drive our emotion the old brain the fight or flee impulse which is how geared towards our user survive. Those are kind of our that's the dangerous part of our brain and our and so my question is like where does the desire to know things come from like your passion to understand the brain and the, Pleasure you get for that it seems like to me the the older brain is geared with Maslow's lower needs the heck, you know, the shelter food things like that survival and that's where the fear impulse comes from clearly the hatred but the the noble side of the brain is just not the neoportex the things that we've invented like ideas like law or the ten commandments, but we saw value in them as ways of constraining the whole brain constraining a impulses and emotions and doesn't.

41:32
Desire for something more noble. And so I use my question is couldn't AI equal to our greater create its own ethical moral constructs and perhaps say, you know. For the good of the earth, we need the limit humans, they they seem to be edging earth versus structure, we need to do something about that as a logical thing and so that's kind of my question is.

42:01
I think thank you Mark Vince can we move on to your events, what's your question yeah, my question is um, basically. Theory actually two questions one is screen time on children and I got a 14-month euro and so is there like any evidence that it really decreases the intelligence or kind of makes a child hyperactive or something like that and in a second question is I have a theory that you know, you know, like the jeans that a child gets past over, you know, sometimes the child can have like a high IQ way higher than the both parents and I my theory is like maybe that, you know, assuming everything else is in place like, you know, breast, you know, all the breastfeeding.

42:46
Reading you know all the nature and all that stuff but I my theory is like maybe that you know certain child's there's things that are unaccounted for like maybe that child ate, you know, a bunch of pomegranate between nine months 12 months or 20% more water, you know in the age of one or two or so, I'll just curious on your thoughts on both those questions sure thanks let's take one more and so we can save some time they pass is that the right way to yeah, let's report thank good things a lot for letting me in and it's pretty to.

43:21
Hear from such brilliant and giants my basic question is how how can be think about fast thinking and slow thinking in context of playing like sometimes I feel like my reaction thinking and might keep thinking the outputs are very different so how do the modeling of those places have been thank you for a time thanks a lot.

43:46
Thank you so much super tired Jeff do you think you can combine your answers with the last few questions we can try the very different questions. I think we can go through them really quickly, okay, first of all the things I don't think we have answers to your questions we don't we study like how the healthy brain works what the base is going on there and when it comes things like, you know, the effect of screen time on a brain.

44:13
I have no idea obviously it's gonna change the brain you can learn differently, but it's a good I don't know and we're not gonna we don't even get into the Idea that you know, what how different is one human's brain versus another basin genetics comparison of IQ we don't we know you want to touch that stuff so sorry.

44:30
I can't give you pictures on those Mark. Weiss, hi Mark our friend of ours I see you so his question about a basically about ethical constructs. I the basic idea and a ladies out of the book is that the new cortex itself is essentially devoid of these it's anything that the word of any sort of built-in emotional constructs.

44:56
I'm. Those are older parts of the brain and we don't have to build those if we're gonna build intelligent machine. Now, you might say well, maybe the cortex itself will have some little develops some ethical contracts. I don't think that's really likely to happen in this in any sort of sense.

45:14
I think the court checks is built in that has a built-in desire to occasion. Is dangerous but exploring leads to death And so we are biologically programmed to explore mostly when we're young so you know if you're gonna die get it over with don't do it once you have children.

45:35
And so there's a sort of built-in like hey, I'm gonna try to climb in that mountain just for the hell of it see what's on the other side and then someone else my old immersion city. You don't want to do that because you know, it could kill you. So we have this biological bias to do this and I think as we build intelligent machines we'll have to ask ourselves do we want to do something similar and when do we want to do it?

45:54
Only what conditions if I'm, Relying on something maintaining my with my you know habitat on Mars the example I use in the book a much times I don't want it you know experimenting much you know I don't really well to try new things too often. I want to go out there and get the job done of the other hand if I'm building a mathematician robot.

46:13
I might say, you know go ahead and experiment all you want try new, you know go down past it don't seem freaking fruitful, but you might find out the answer that question. I think he's a parameters we can put on top of an intelligent machine but I don't think they're built into the substrate of intelligence itself.

46:28
I make the argument to intelligence is like having a little. More This is a lot of the world on its own It's kind of indifferent It's just a map that says okay I know how information I know what the world is like, here's my structure for the world and how it's used by other parts of the brain matter a lot.

46:41
And then Joni in maybe suits all you want to jump into this one. We think brains need embodiments. And I make the point that it doesn't have to be a physical environment. You have to the goals the system has to be able to take some sensory input and in the thing that's getting an essential move.

47:01
And so the example I give in the books. I will come is that you can have something that's Um agent on the internet. Essentially following links and going to different web pages and sensing what's there and learning a model of something but it doesn't have to be physical. There's still a concept of movement in sensation.

47:27
That bothered me. I don't know if you wanted to get that anything out to that one super time Yeah I mean we do think, like I said embodiment is critical and we will need to build embodiment into a systems in order to make them truly intelligent, you know, I think AI systems will need to be able to make actions will need to have predicted make predictions about their actions learn from the consequences of their actions and this sort of active paradigm of actually being able to you know control and move through things is critical to learning and to building a model of the world and and really understanding this.

48:04
Structure. Of the world I think you have to question about you know visual input and you know, how critical visual input is and forming visual sort of models of this. You know, that's that's optional. You know, there are people who are totally blind who have very very rich reference frames and models of the world and structural models of the world.

48:25
You know, and and the exact modality is not that important and that's sort of one of the really interesting things about cortical columns and the common algorithms is that the exact sensor modality is almost irrelevant. You need. Which you need rich input but any sensory modality will work and the same algorithm can work across all modalities.

48:50
I think the last question about the fasting and slows we talked about that earlier and I give a long-winded answer to it I don't want to do it again here I think there's not a really it's not a clean our models and what this concept of fasting can slow thinking and I do believe that fast thinking and slows thinking that concept is maybe useful way for humans to think about a little bit but from our point of view there's really not much of a distinction between those two.

49:15
It's it's just a matter of how much you're attending to something or not and if you don't attend to what happens quickly you just make you basic or build your model. It's not something intuition. It's just, You have a lot of the model acts. If you want to not act right away and think about alternate.

49:31
But it's not really a hard distinction. The way we try to we couldn't really bright combine those together, but we. Yeah. Thank you Jeff. So we we are coming up to two hours. I have a couple more people raising their hands once to come on the stage. I'll refrain doing that and once we address the rest of people on this stage the questions and Jeff's attire up to you to to decide to stay or not.

50:03
And when we leave we don't have to close the room people in the room can continue this fascinating discussion. So Montesa. Matsu actor and EF Peterson if you can get your questions ready and we'll come by those questions again. Morteza. Yeah. Thanks for your room. So I have a quick question for Joe.

50:27
What is the difference between the representation and computation and I haven't another question all these framework, how do you compare that with the internal model and predictive coding when the in the absence of any external stimulus means when you close the eyes and there is no stimulus neither auditory center visual note stimulus.

50:48
How do you compare these two? Are maybe you understood that question better than I do. I don't know if you did or not. Oh shoot, do you want some type to do my yeah let's go get those through the questions together. I'll get back to you. Okay. I'm sure I can ask my question but it's very different from what most is I'll ask.

51:17
So mine is about distributed intelligence. I remember you talk about it in university on distributed intelligence, but I wonder from the perspective of a neuroscientist when you study brain do you consider the social aspect of human intelligence in our this extended or distributed intelligence that we have? So, um, personally I study multiagen system and I'm kind of applying it.

51:46
In my own practice so on robotics. I'm so what I notice in a lot of these social colonies because they and will be or even like fish it embeds a lot of 
complex phenomena or emerging from very very simple behaviors in local interactions that are emerging in the growth of level.

52:07
So I wonder studying brain can be considered some of these extended or social behavior that we have that also sort of like how the complex emergence they bring. So for like, Social colony that we have as a human. So then potentially we could apply it in. Distributed artificial intelligence and building our models without problem solving, but also looking at the agent system for ARI.

52:40
Income those true quite complex questions Every tackle those two and then move on to the next two just super time. Sure, I guess I can maybe take the one about predictive coding for those who don't know predictive coding is a particular kind of mathematical model of how the brain works it's a Bayesian model and I think there's some relationships between the stuff that we're working on and and predict the coding it's one of the few models that also typically looks at behavior as well, but the they're quite a few differences as well and and you know, the predictive coding, for example has no concept.

53:15
Frames or any sort of, you know, location-based representation and it doesn't really talk about kind of each each sort of level of the hierarchy being complete sensory motor modeling systems that model the full structure of the world. So, you know, there may be aspects of predictive coding that that relied that we think the cortical columns are a lot more than than what that theory kind of embodies.

53:41
And I'll take masses questions. I got this question earlier. I've also gotten this several other events I've done and I guess it must be a current thing that people think a lot about this sort of social aspect or the you know, collective intelligence. I totally agree that these are very fascinating aspects of society and and other animal behavior included play an important role in human endeavors.

54:09
Our focus has not been on that, our focus is really been on telling how to understand it a single. Works how it builds a model of the world and you know how neurons actually do this what's happening when you're thinking and seeing that's not to say that everything it currently isn't but it's a big component of the problem as a very large big component of the problem and and I honestly have to say unless it would type feels otherwise, you know, we haven't really tried to deal with these more extended phenotypes if you want to call it that way and it's you know, that would be just too much it wants to handle so not to deny the importance of it, but I do think.

54:52
Understanding how an individual brain works would be sort of a key foundational principle for any sort of extended behavior that that might acquist across, you know multiple yeah maybe I can add that, you know, the whole area of how political columns sort of operate on their own and then interact and coordinate with one another is a very concrete example of a distributed system that's very fault-tolerant and has a lot of the properties that you might describe up, you know, some of the systems you mentioned so maybe you know understanding in detail exactly how the, Thousand rates theory works and and operates might give you clues as to somehow some of those athletic measures idea.

55:33
I don't think we've ever talked about that before that that the voting mechanism that we have modeled and understanding going on the outputs could be essentially a very good analogy to what's going on between animals and between species or between individuals that that's that's really fascinating. I just want to say that not that we've thought about it much but that that is a really good idea yeah we haven't really talked too much about my person is a complete sensor motor model yeah.

56:02
Just made that up so we type it that was great yeah, okay. Hector and BFerson. Yes I thank you very much first I am I working in a happy working in the eye probably my whole life first. I wasn't academia doing listening and last year having been doing martial learning basically obsessed with attention people learning a reasoning and any particular unfocused on what happened after you have learned in the inference moment in that particular case, what are the sort of property we can get so this is like the context of my question and then so I was trying to understand because I'm very concerned with it with the multiple the reasons of the combinations that we faced.

56:48
When we are acting right this community of the world some level of abstraction, so the question is how is that possible that we have some kind of temporalization of the connections using this this notion of the French you mentioned that never have this 10,000 connection and they might provide a context but for all the combination 10,000 is nothing right because I mean, there are many many many things there and and just for putting an example suppose.

57:19
I don't know we are we are in a trip and they need them there are something. We we re-elected we forgot something and then go back back and then yes I left that in that place and I know who I'm gonna call and they can be a fraction of second so the question is how is it that we can have this sort of it's so precise recall or something that can be far beyond of this scope of 10,000 things.

57:46
I try to understand that because so that's my work take a right way we said a neuron has 10,000 synopsis that doesn't limit anything here's what I think about it, you've got let's say I Have 10,000 neurons which is a typical number that I might have representing something with a lot of their entrepreneur 10,000 are let's say they're activated as far as activation a 2% see of 200 active neurons now the question is how many things can you represent that way it's not 10,000 it's it's 10,000 choose 200 which is the national market is large number many many many times bigger than the atoms in the universe and those representations of almost all of them will be very distinct, they'll overlap very little so the representational capacity of a bunch of neurons is extremely high it's There the question then the limit comes in memory how many of these things can you store and it turns out that to store a pattern even a large pattern across 10,000 neurons only takes about 20 to 30 synapses.

58:48
I know that sounds weird but that's true and you can do the math which it's all about the sparsity so there is a limit there's no limit to representational capacity, but there is a limit to memory but the limiting limit is much much higher than you might originally think is because you don't really have to remember all the details of something to remember you only have to remember a few little pieces and it'll be unique.

59:08
So these are mathematical properties that you can easily show and and they play out in neurons so that that question about capacity is when we deal with all the time and we think there's good answers to it now the question about learning and reasoning I'm not sure you know, I don't think we make that the station learning is but we can just say learning is is what is a personal and brain learning never stops it's learning all the time it's you never stop learning every time you observe anything you walk into your kitchen, you see where the dishes were left there with the you know, some piece of food on the counter you learned that it's it's not like and it's, In you remember it after I walk away I'll remember it two seconds later so we're constantly learning and then the question about reasoning is essentially you've got this model of the world in your head and you can say sit there and you can even close your eyes and say okay well what I what would I have to do to do this or what have you do that or what would be the consequences of doing this and that's just playing out the model let's just letting the model play itself out you see what I did this what would come back next what would I do this will come back next so I don't think we really make that distinction too much between learning a reasoning you kind of do in both simultaneously all the time all you can 
shut down the learning part and just sit there and close right?

01:00:18
Think for a bit but most the time you're doing both of these things you're you're saying not only do I'm saying, you know, I'm learning new things but I'm also predicting what's gonna happen which is a form of reasoning. I'm gonna predict what happened if I if I turn left I'd turn right or open the door or not open the door so we don't really make that distinction unless it's disagrees with me it says we do think that the distinction.

01:00:36

I don't think no no.

01:00:42
Great. It's a fascinating thing these no behind the just really amazing when you get into it. How these things are how this is unlimited capacity. I would. Thank you Hector Peterson and after beer the Peterson Jeff is super tie if they decide if you want to continue the discussion or not be a person what's your question?

01:01:06
Thanks Jen Subutai and Jeff thanks very much. My question is do free transparent and open societies potentially serve as better stewards of revolutionary technology like AI or is that concern overblown? I don't think it's something I'm an expert to talk about. So I would be a novice speculating so I'm gonna pass in that one.

01:01:34
You're you're an AI expert, right? Well, I'm an expert on brands right and how brains work and we have a very close theory about how we will build intelligent machines and you're asking is what is the better societal structure for doing that? I think that's what you're asking. And I don't know the answer that question.

01:01:54
I mean, there's some societal structures. I like better than others. I like open societies and I like free information. You know personally but you're asking me when is the better structure for doing that? I don't know how to even measure that better. So I'm not trying to avoid repression in the sense.

01:02:11
I really feel like I'm not an expert at this at all and I and I think it would be so disingenuous if I if I pretended it was I don't know if it's how you feel any differently. No you know they you know perhaps it's an opportunity to mention that you know a lot of the stuff that we're doing is super open we make sure we you know science quite often a lot of science is done behind pay walls and it's often hard to access some of the scientific articles we made sure to always make publishing open access articles and we publish our you know, research openly and we try to do as much openly and collaboratively as as possible.

01:02:47
So that that, you know from a scientific standpoint. I think you know, that that's been really important to us. Yeah. I think that's all our work, you know open is is absolutely invest. I mean, there are countries in the world. Who restrict access information and and and if you do that you're just eliminating possibilities It just to eliminate, you know, whatever what does some countries said, you know.

01:03:07
I'm never gonna tell you about you know the planet Saturn in and I just if you grew up and you never heard about the point of Saturn, well, you just wouldn't know it existed and you wouldn't know that their plan was rings I mean. And so you and then you wouldn't be a good, you know, the puns are scientists done.

01:03:22
That's a very choice example, but so yeah, I mean super right, you know, it's sometimes scientific research is hard to get because it. Behind people's difficult to get so that's a that's that's it the disadvantage. Yeah on that actually, you know, I want to mention that you know, I feel so thankful that new mentor as a platform has offered so much, you know research and thinking and share with with the world and it's remarkable work you you and your team have done and it's so valuable for us and you know, the the website itself is such a treasure trove for people who are interested in is topics that highly.

01:04:07
And everybody visited the visit the the, you know website and the channels on YouTube, et cetera, you will learn a lot. Jeff supatire we are 12 minutes over two hours, how do you feel I should have made a few people on the stage as moderator which means when you really leave the room the conversation will not end so it's completely up to you we have four more people raise their hands to ask questions so completely up to you if you want to continue.

01:04:36
I myself have to leave the latest in 18 minutes. I have something in 10:30 here. But for my perspective I have it's 7:15 in the evening here and my wife at home and we're going to have dinner soon so I don't want to go too long. I guess I could stay for a couple more questions but I think I don't want to go after that.

01:04:57
I'm about seven times but yeah. I think that's the same for us. I think maybe Jen your timing and our at least my timing lines up pretty well.

01:05:10
Yeah, it's good.

01:05:15
After we actually have quite a few people waiting so very much oh yeah yeah thank you so joy and taring well thanks so much. I took the chance so hi Josh I think I've met you like five six years ago at your office, you probably don't remember me question is so for the people last couple years we have tons of glow we have tried towards to do the like the actual machine learning stuff for like image costing and stuff, but can you update us on?

01:05:50
More like what kind of security. Complex scenarios, we should use are you meant as framework instead of others? I think silicide we're gonna start talking. Technology.

01:06:06
Yes so you know we've as we've talked about earlier we've started down the path of implementing different components of the thousand brain's theory into two days kind of machine learning frameworks and so you know, we're still early in the process so you know, obviously we can't run the full classroom theory yet, but we're working we've been working a lot on sparsity and so we do have a pie torch based framework for applying sparsity to deep learning systems and that's sort of was the basis for a lot of our work on showing house varsity is robust and And house varsity can lead to really fast computation that official computation so you know, people are working on people learning frameworks and then high torch specifically they can look at our code it's all open new available torch it's on GitHub so that's one sort of concrete framework that's available in terms of kind of scenarios.

01:07:04
That should be applied to we're really are trying to move as fast as we can towards doing much more embodies scenarios where you know, we have agents that are moving around in a world and and active. And learning from their prediction area, so anyone is doing research on that these areas that follow our research meetings these areas that we're trying to focus on and then make progress on so it's trying to.

01:07:30
Exactly yeah, yes or not. I don't think we fixed them anything but will talk about it in some of our our research meetings lots of the great areas.

01:07:45
Embodied areas taking some of the sparse stuff that we've done and trying to apply them to these domains would be fantastic the dry ice again. Thanks so much.

01:08:01
Okay thanks Jen yeah great to have super time Jeff here on stage actually a big fan of your work, if you know other reason that it goes against the prevailing dogma that we have today and with a deep learning machine learning so there have a question that's kind of like an open-ended question maybe they're just for pursuit.

01:08:20
I is you know, this this this sort of like the sort of subject of hey, you know, what all you need is is back prop and you know universal proximation and that has a lot of utility you'll have applications so and so forth. You know that that seems to be the the prevailing dogma today within within you know, deep learning and stuff how how do you like to to talk about the sort of like mitigating that dogma as far as as far as you know back prop goes and and things like that, what would you tell your detractors if we say that you know, what we we don't even need to study the brain or all we need to do is come up with better, you know better learning algorithms all other paradigms that we already have what might you say to to to the, Like that because there's there's a bunch I don't view ourselves as.

01:09:16
Actors or? Who it is.

01:09:24
In the end there's going to be where we're doing that I don't think there's going to be multiple we're not going to you know in the end we ended up with the touring machine for computing all right we're going to end up equivalent set of principles for intelligent machines and you know and the question is what is the quickest way of getting them some people think that you don't need to study brains is not that useful even though brains are the one existence group we have for intelligence and they can make a good argument the brains are really complicated they're hard to understand maybe they're messy, you know, it's going to take too long.

01:09:54
I don't have time to do that. I can just think about this and I'll come up with this album great. That bad of work people being made that argument 40 years ago when I got into this field I was told that argument and and I never believed it I said brains are obviously very complex, they're much more complex than any kind of stuff we're working on here, they must be working in different principles, but I could have been wrong and so right now we have these very capable of deep learning network, but very few people think they're really smart, they're really intelligent.

01:10:25
I mean, that's pretty that would be an extreme position most people realize they're pretty limited and and that is still with the question is is why well, some people are you. Yes, you could. Supply more back property, you'll get there. I don't think that's a universal. I did. That actually I think might be somewhat friend.

01:10:42
I think you know the leaders of AI girl all come out and said you know that's probably not gonna work so the question still then becomes you know what's the what's the best way of going forward we we think the best way going forward studying brains if we're wrong that's fine someone else will come back right moment we're making great progress we've now discovered these major principles underlying intelligence which we quit to figure out if you haven't studied brains, no one else has figured out still right about that then you know, that's a good way forward, so I think that's where I look at it it's not like oh we have the tractors we're competing.

01:11:17
We're not competing for resource dollars or something like that, it's like we're all trying to do the same thing here we think our approach has got merit and we're gonna stick with it until we find out otherwise that's the way I kind of view that in the angle find out what's right, you know, we'll see what works we're betting on our approach but it could be you know, someone else can beat us to it, but you know, I'm pretty confident.

01:11:40
I'm betting out of your approach after but I imagine how much energy Google has consumed to just to to training the AI to identify two dimensional image of two hours and the boom very muffins and the steel it confused right away you might actually even need some lakes like new type of hardwood just to have a proper substrate for a lot of this yeah, oh absolutely but again, Yeah you know we we're spend a lot of time and I gave a talk and you know every year we give talks at these they're more for computing conferences because they're interested in people building new types of substrates new types of processing elements and I just clearly gonna be necessary at some point so you know, we're gonna go through a series of innovations just like the computing news we did, you know computers got started before they they knew what the the transistor was and then they were going before they knew what the integrated circuit was and then they knew it before, you know, that there was wireless communications and so on and we're gonna go through a series of innovations you.

01:12:50
Year two in the intelligent space, they're all gonna be working on the same principles, we're gonna have these principles defined just like touring and and forties and thirties we're gonna come up and set a principles but we're just gonna be a long it's gonna be a cycle. I know how long it'll be but there'll be a cycle where we're figuring out what's the best way to implementing these things a lot of creativity is gonna go into that it's gonna be exciting.

01:13:12
Well thanks guys, that's pretty amazing for both of you, thank you very much, thank you. Jeff bring is that your real name. Just bring. Okay, it's imaginative brain. Um, yeah on this stage just bring that's her name, hello. Jess not me. I think trying to me, yes, no. I'm sorry, it's just.

01:13:38
Yeah, just praying that soon says yeah.

01:13:46
Sure yeah, thank you. Was about. Actually um, no in that in that framework and what's kind of being used to generate. I guess like in the body learning now what's the symbol grounding mechanisms and how you guys just mentioned like hardware my mind to like, you know embodied hardware or not computational hardware but seems like that might be necessary or can we drown symbols and another ways with the buddies learning?

01:14:20
You know the symptoms I do feel comfortable talking about that. Um but you know, I think in a book you talk a lot about how knowledge is represented and how the binding problem is can be solved yeah not sure if that's the same thing, you know, we think they're used to as a it's a very convenient substrate for storing knowledge, you know, I don't know about meaning per se but knowledge can be stored is stored in the brain in reference frames and you can make inferences about about that knowledge you can make predictions about that knowledge, you know, so there's a lot of Capabilities you get from storing yeah data on in reference frames per se but yeah may not get to your question but first of all these reference range we know how you're done to the brain, there were these things which have been studied for decades in and we actually know a lot how this is done, it's not totally this is not made up speculation stuff, but as I said, what reference frames give you is the way of organizing knowledge about something in a useful way, it is makes it actionable it makes it say that I can form I can see analogies between structures.

01:15:36
That are different that are different components but they have the same structure to them. I can arrange similar I can range things in a certain way that is different things but new same arrangement and then I can infer that I could you know operate on them and the same way so it is a very high level you can brighten sort of a metric structure to knowledge and that lets you act.

01:16:05
Solve problems even in spaces that are different as long as they have the same underline structure, so it's a very fundamental property and I think again, we don't use the will remaining in our work it's maybe I don't look at the definition exactly that is but if you want to say meaning is knowing that knowing the relationship to something to other things and how if you act upon this thing how it's likely to behave relative to other things you see then 
reference frame by the answer to that.

01:16:37
Thank you. Oh thanks as thank you so much Jeff and Super. Ty this has been such a rich discussion and the book is called a thousand brains and I highly encourage all of you to to get a book and read and prepare your mind get blown and the research platform called new mental that super title ads leads all the using the theory applying artificial intelligence, and as I mentioned the new mental website is it's a treasure trove of interested in those.

01:17:15
Other topics I guess Jeff and Strubetai this I think this is a good place to end the discussion we can leave the room and people in the room can continue the discussion and the I guess the best way to learn more is to visit new mental website and also read the book.

01:17:34
You won't be disappointed if you're interested in this topic. There's a lot of also a lot of lectures we've given you. Technical stuff. Hey, Jen. I wanted to thank you for organizing this. It's really. Great. I think. People questions with fascinating and and it's great to get. A discussion about this stuff going and I appreciate you going out of your way to make this happen.

01:18:00
So it's not my pleasure. It's a true pleasure. Thank you so much. Clubhouse. Experience. Yeah, thank you. Yeah, thank you. Thank you very much.

01:18:21
So much. Besides thank you so much bye, thank you so much.
Transcribed by Pixel

Audio
