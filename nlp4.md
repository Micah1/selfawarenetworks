The Neural Lace Podcast #4 Guest: Andre Watson

May 5, 2017

Original audio here https://youtu.be/RRN91RwiYiw 

Audio Transcription by OpenAI's Whisper

Welcome to the Neuro Lace Talks with guest Andre Watson, host Micah Blumberg, edited by Adam Alonzi.

I see myself mostly spending time between the world of engineering biological systems and materials and science,

materials science and engineering as relates to making nanoparticles to deliver genes to different places in the body.

So what I spend my day-to-day really building is my company, Ligandl, where we are using Ligands or things that stick to different markers and things like receptors

to guide these vectors for gene therapy to really specific locations in the body.

And I have spent a lot of time on thinking about Synapse Physiology.

I was going to go to McGill for a neuroengineering PhD, but I decided to come out here and work on this.

So I really love pharmacology and for me, understanding consciousness or at least a piece of it is incomplete unless we try to look at the molecular picture too.

Yeah, I agree.

So it would be really fascinating to talk about maybe how that plays a role in the future of the human experience and also how we're going to build machines that capture various aspects of human intelligence.

What got you on this journey?

What got me on this journey was a book called Unintelligence by Jeff Hawkins. He was a neuroscientist at the Reading Institute and he was also the president and founder of POMP, made the POMP pilot and the POMP 5 and the hand-spraying device.

And then eventually that sort of, you know, then iPhone came along and sort of took over the market.

So the POMP went away, so what Jeff Hawkins did instead was he started a neuroscience research institute and he wrote a book called Unintelligence.

And he started this computer company called Numenta and Numenta has their whole idea is basically create a computer that's based on the neocortex.

And so this computer uses what they call hierarchal temporal memory and they say the neocortex is like a hierarchy and the top of the hierarchy is thalamus.

And so hierarchal temporal memory means that, well, basically you're sort of describing the structure of a neural network, like as if a deep learning network was specifically structured like a hierarchy.

And so the lower levels of the hierarchy would just focus on the lines and edges and bits and at a higher level you turn the lines and edges into the computer recognizes a concept because it's like a statistically relevant coincidence pattern.

And then at a higher level of the network, you have the computer begins to put together the concept of eyes or words or, you know, it's just basically a map of the associations of the lines and edges.

But at a higher level, the computer says this is an eye because that's what the neural network represents with its weights at different levels.

So, so basically he was describing his book on intelligence he was describing deep learning, which was sort of like this.

So the neural networks that existed since since the 80s.

A lot of a lot of great designs for computers came from the 80s.

But now that since 2012, we, you know, we had some new ideas about how to make the neural networking deeper.

So they called it the deep, deep learning, because you pretty much going to get about three layers deep.

And now you can now in some cases there are networks that have 300 layers deep.

My curiosity as these technologies evolve is the level at which we'll really be able to understand and or emulate the human experience.

And that's something that would be really interesting to discuss with you because I've spent a lot of time thinking about synapses and sort of how things build from a really bottom up level just, you know, molecular pharmacology,

how different drugs and ligands and things in your brain bind to these different receptors in order to create all these different effects.

And something that I've learned through studying that is the amount of layers within even a single synapse of the gradients of state that can exist at any given point in time to represent any range of things that are not just a one or zero or an on or off.

I feel like that is something that isn't talked about very often or frequently. And I'd like to at least think about and sort of forecast, you know, as we build these technologies.

An EEG can tell you some basic things. And if you have a direct interface or some more advanced technology, you can learn a lot more. And certainly even with existing fMRIs, we're able to recreate visual imagery that our brains are seeing based on the fMRI data on its own.

And so, as a starting point, there's definitely a possibility for having some interfaces. The question is, a lot of people also speak about these technologies eventually being able to completely function as humans or transcend humans.

And while I believe that we will have different AIs that will do different things, I really wonder if we're going to see humanity become obsolete or kind of the core driver of all of the peripheral artificial components that become the future of humanity.

Sure. And I never thought about that. Because, so do you remember, Steven Spielberg made this movie called AI Artificial Intelligence. And in the movie, it was good. It was good. It was a vision of what the future might feature in the future.

Definitely worth checking out if you haven't seen it. But one thing that, in retrospect, the movie was fine when I saw it. In retrospect, I do have one small gripe with it.

And that is that the humans made the distinction between mechas and orgas to say that you're a mechanical robot. You're a mechanical person. And I'm a real person.

And so, this is like a really, see what's interesting is, you know, you say, well, what's an organ? Organ means organic. It means grown. And mecha means made in a factory or something, artificial.

But, okay, so the thing is, you know, and I've heard people describe this concept in other ways, you know, we're like, if we're robots, we're, you know, like, you know, organic robots or, you know, kind of closer being trees.

And this is like, we're not metal robots, you know, we could have a solar. So it's not possible for machines to have a solar because they don't have the same sort. These are things I've heard people say.

And I think that we are metal robots. And, and so there won't be in I said, because we're metal metal, I think humans are metal robots, because, because our, because our nerve cells, for example, are filled with metal, filled with with with any outer sac filled

with calcium ions, and on the inner sac filled with potassium ions, you know, the calcium ions are, you know, the positively charged and the, or, and the potassium is the potassium positively charged and it's also positively charged.

I guess, are you, if you're saying metal in the sense that is capable of conducting ions in the presence of a variable solution of electrolyte concentrations, then, you know, we could redefine metal for the purposes of this, though, from, you know, strictly speaking, that's not a metal.

One solution, you don't consider calcium and potassium to be metal, not if they're in solution, not if they're in solution. Okay. Well, wait, hold on. Let's talk on the table, on the table of elements, we've actually got a periodic table. Yeah.

So let's let's pull this up. I mean, yeah, I mean, they're definitely, you know, in the strict sense they are alkali metals. Yeah.

Going down from, from lithium to sodium to potassium, yes, then that's, I said, where we have the alkaline earth metals, I suppose that is a really interesting way of putting things because by moving around all these positive charges through active energy

spending processes, we're able to control not only the action potentials, but sort of the, the arc of, yeah, the shape of our firing and magnetic field. Yeah. Yeah. At a really just fine, superb level of electrophysiological weirdness.

That's why, you know, I like to say I believe that consciousness is magnetic, because our brains are manipulating a magnetic field.

It's so interesting.

And that we are metal robots. And once we solve creating robots in a factory, they'll, they'll be no different from humans. They'll just be, and people will not say, Oh, this is surprising. People will say, Oh, of course, it makes sense.

The universe is a fractal. And they'll be like, Okay.

The interesting thing to consider is the, the basis of the kind of consciousness that we have versus the kind of consciousness that a machine intelligence would have.

Because we've entirely evolved even from the time of being single cellular organisms to feel the world around us in the form of receptors by these different molecules.

And you can think about the electrical part of our biology and our consciousness, but there's also at even the most baseline resolution, a physical sensing one.

And we are built out of these exquisite nano sensors that have the ability to distinguish serotonin from dopamine and a range of thousands of different compounds from each other.

And this is actually, I would argue, one of the core facets of our consciousness that cannot be adequately modeled through electrophysiology alone.

Okay, we explain that one again. You said, Why, why can't we model it?

Well, we're starting from a position of biology by its baseline interacting with its environment to use an example of the sort of sensing that biological cell can have.

You have this family of cell surface markers known as integrins integrins bind to collagen, elastin, these different extracellular matrix proteins that form the mesh of what comprises your skin and all of your tissues.

And through binding to these surface markers, these receptors, the receptors are actually mechanosensory.

As you pull on the strings, so to speak, they engage signaling cascades that are so precise that they can upregulate themselves and produce more of that specific protein or more collagen and things like that,

as well as things to remodel the matrix or break it apart and chop it up with these things known as matrix metalloproteases.

And this is just one example on describe that matrix.

So you have an extracellular matrix of, you know, we think of cells as having, you know, we have, you know, 70 trillion cells in our body.

And those cells are not just floating around freely, they're interacting through a series of proteins, glycoproteins, like sugar proteins, sugars, lipids, glycolipids,

and you name it, that are all latched together. And amidst all of that randomness that you perceive, if you were to just map what all these things are,

we're able to derive very specific information where pulling on a single receptor that is bound to by an extracellular matrix protein can trigger very specific signaling cascades that cause remodeling of the entire system around it.

And this is no different with neurons. If you think about a neuron and the axon and the dendrite being latched together, people always think of them as just, they're just sending signals and it's just electricity.

Have you ever wondered why a dendrite sticks to an axon?

Yes.

And that's, that's the same thing, actually. It's an extracellular matrix that holds them together. And you have these different surface markers that latch the axon to the dendrite physically.

So you have, for example, this family of proteins known as neturins that bind to neturin receptors, and they're one of the major extracellular matrix components that hold together axons and neturins.

What are their electrical properties? I mean, they want to, you don't want to have like, because you need this synaptic gap for the chemical synapse. So whatever's connecting the two can't, can't, you can't have an electricity running across that because otherwise it would defeat the synaptic gap.

So the properties must be inhibiting electrical signals somehow.

I think there's still a space there. I think it depends on which protein you're talking about. And I think for the purpose of thinking about how

the potentials are propagated.

It is really hard to envision scale at which this is interacting because there are, you know, 20,000 proteins and thousands of these proteins exist on the cellular surface and they don't need to be homogenously tight junctioned in order for them to be serving their functions.

You can have a distribution of a lot of things that aren't going to negatively impact the way that cell functions.

So I mean, anything that we would say about that would be completely speculative.

I guess what I'm going with this is that.

Well, someone was saying that the deep blue, not deep blue, but the guy who's working on the blue brain, he was saying that they created a model, a computer program to try to simulate where synapses would, where they would connect, where cells would connect.

And they said that basically what they found out was the computer model was able to, you know, they basically did it randomly and it was pretty much close to what actually happens in the real brain.

So they're basically, they're saying that basically in the beginning when people are born and their synapses are first growing and connecting, that it's basically like random.

What does that mean?

What does it mean for it to be like the brain? Because it's one thing to have a small set of neurons.

I'm sorry, they were specifically stimulating just how neurons would form their initial connections with each other.

It was basically, it's a controlled experiment. So in reality, there's so many other factors that could be tilting that. So yeah, you can't, when you have a model on a computer, it can't compare to the bizarre reality of a real brain.

Well, one of the things there that I really wanted to talk about is the nature of kind of, we can call it the, the now brain versus the evolving brain. Or if we want to say it perhaps in terms of pharmacology, the ionotropic brain versus the metatrophic brain.

So when you think of an action potential, when you think about these metal ions flowing in and out of the cell and being pushed around to change the way that charges work, that's ionotropic.

Oh, you're talking about the glioceles metatrophic?

No, no, I'm talking about every neuron, every receptor that generates a quote unquote signal.

You can have ion or voltage gated, you can have basically voltage gated channels for ions.

Yeah, yeah.

That can either respond to a neurotransmitter or to some voltage changing on the cell surface.

Sure.

That's all quote unquote ionotropic by definition.

Okay.

Metatrophic is everything else.

So most serotonin receptors, every dopamine receptor, if as you go through the thousands of receptors, like, you know, 800 receptors that are G protein coupled receptors, they're actually the most common protein in your body.

You have about 800 of them.

So all dopamine receptors, all but one serotonin receptor are G protein coupled receptors.

They have all these different subclasses.

G protein in itself is a ton of calculation, chemical calculation.

Exactly.

And so it is like a chemical computer versus an electromagnetic computer.

Yeah.

So think about this, right?

But the thing is all the chemicals are doing both at the same time.

Not all of them are?

No.

A lot of them aren't doing electrical things directly.

Some of them are changing the way that receptors.

Well, what I'm saying as an aggregate, as a whole, they'd be affecting the ionotropic brain.

Yeah.

And the interesting part is that if I could capture a perfect snapshot of your brain over 30 seconds of every neuron, every astrocyte firing, I would learn a lot about you.

And I could see that you're having these changes occur in your brain.

Sure.

But that exact pattern probably never happened twice.

Exactly.

So how do you model someone having more or less testosterone or being on LSD or not?

If they never have the exact same...

In your neural network, if you only capture the ionotropic part, how do you predict how each brain will change?

Well, I mean, okay, so I mean, you know, I think, okay, so I guess in terms of, you know, look at, consider diffusion tensor imaging, right?

You're basically...

You don't have to tell me more about that.

They blast a radio signal at the water in your brain, and it's a specific frequency, and it causes the water molecules to release energy, which is at a specific frequency.

And so you have a camera waiting on the other side.

So the magnet, the big giant magnet, what it does is it's getting your molecules aligned, and then they hit it with a radio frequency, and when the magnet stops, and then...

Am I doing that wrong?

But anyway, so maybe I'm describing it incorrectly, but...

Well, what is the...

So the magnet gets your waves aligned, and so they blast them, pretty sure they blast it with a radio signal, but they have to stop the magnet first.

They blast it with a radio signal, and then the result is you admit like lambo waves or something from all the particles, all the water particles that were aligned.

So the water now has to travel... It can't travel... Once it's released by the magnet, it has to travel along the axonal fibers.

It can't travel freely like it would if it was just in the ocean, right?

And so because it's admitting that specific frequency while it's traveling along a specific line, and you're capturing it from a specific angle,

you have a camera that is doing an X capture, and a camera that's doing a Y capture, and a camera that's doing a Z capture, at least three.

And then you can do tensor calculus on it and figure out the position and direction of those water molecules to become your tensors.

What resolution of data do you get from that?

So with the standard MRI or DTI image, I believe, is the voxel size, you could fit in like a thousand or more, or a lot more neurons in a single voxel.

So it's really not that detailed, but the idea here is you've probably seen division tensor images where they have these...

They're basically the really colorful images of the brain. Yeah, so they're really colorful like brain scans.

Oh, and it's MRI-based, I see. I didn't follow that. It's using an MRI.

Yeah, so the MRI is just like a two-dimensional photo.

So this is how you kind of keep track of the tracks?

Yeah.

Right, right, right. I've seen a lot of these.

So my hypothesis is if you did like 3,000 photos, you see they only need really three photos because you're just getting the basic geometry.

I think if you did 3,000 photos, sort of like using like a light field type of camera, you know, like the new light show rig where they have like 90 cameras all pointing in the same direction.

If you did that kind of DTI, and then so you're kind of like trying to figure out the light field of the brain, not only where those...

Not only like where the water molecules are and which direction they're traveling, but also, you know, you're figuring out the direction of the frequencies that are traveling towards the camera.

You know, and that's the light field. And so you could create like a hologram that has potentially a higher resolution if you're using a lot more images.

And you're going to have to use a technology-like videogrammetry, which is like photogrammetry on every single frame.

So that's the proposal for a new kind of DTI. DTI is not limited to MRI. A lot of people confuse it.

I mean, actually, the diffusion concept is MRI, but what I mean is that, oh, really, it's a tensor cataclysm. It's tractography.

And you could apply that concept to other types of sensors, whether they're inside or they're implanted inside.

So if we put sensors inside, you know, like these doctors, and you could...

If you have, you know, at least three of them, then you could calculate...

I mean, you could calculate the... Whatever you could calculate, you could do something like tensor calculus on it.

You know, just map all the ions within a specific field that you decide to focus on with your sensors.

But you could also do something like this with EEG or MEG.

Just do this with sensors that are just sort of like pointed at your thalamus from your nose.

Just point them straight up the nasal canal, you know, or, you know, shoot a sensor up the nasal canal.

As far as you can get it without, you know, breaking something.

That's really tasty.

You're drinking Urbimonte.

Sponsored by Iguayaki.

There was one thought that I had about, you know, so you and I on the phone were talking about this synapse,

and you were talking about how astrocytes and oligodendrites have all these interesting...

It's part of what you study, of all these interesting properties in terms of their networking and the back propagation and how all...

So basically there's this whole, like, people think of...

Because people think of, you know, people in computer computational neuroscience think that the brain's all about the neurons.

You mentioned that there's an iotropic brain and a...

Metabotropic.

Metabotropic brain.

There is, in a sense, you could also say there's a neural net and then there's a glionet,

and that these two nets are interfacing and...

Yeah, and there's so much complexity there, both in terms of how the neurons and the astrocytes and the microglia interplay with each other.

And does mitochondria talk to other mitochondria?

I mean, maybe there's a mitochondria on that, too. I don't know.

That would be interesting.

I mean, I'm sure they're connected via...

There are mitochondrial localization signals, like protein sequences that directly go to mitochondria,

but I mean, I'm sure microtubules connect mitochondria, as well.

But I don't know what the intra-marticontrial signaling looks like other than this sort of network of the electron transport chain, but we're digressing.

Well, sure.

Well, okay, so no...

So, I mean, really, so this podcast is about neural asin,

and there's so many different potential ways to interface with the networks of the brain.

It doesn't have to be an ionotropic interface.

You could potentially also do a chemical interface, a metabolotropic interface.

It's going to be harder.

Harder, sure.

And I think that...

But there's something special about how the metabolotropic interface is influencing the ionotropic interface, I think.

I mean, you're talking about... I think that is everything in terms of how we dynamically change throughout time.

If you imagine kind of the picture of the neural tract that you mentioned through the data of the fMRI.

Yeah.

Oh, DTI.

DTI, right.

Fusion tensor imaging.

Yeah.

Or tensor pack.

Right.

So, if you look at those tracks, how do you...

And what do you need to determine in order to have a snapshot of the person's consciousness in a way that captures the subjective experience, too?

Okay, so this goes back into... So, let's say that we're never...

Okay, let's say we're never actually going to capture the same brain signal twice.

For the same reason that you're never going to capture the same photograph twice.

And that the universe has one direction, as far as we know, because of entropy.

Or because, you know, entropy is time, right?

And so, you're never... So, it's like... But here's the thing, though. Here's the thing.

We're able to identify objects in this bizarre world.

Like, I'm holding right now headphones in my hand.

And I recognize their headphones, but I've never seen headphones from exactly this angle, exactly this way, in exactly this room, with exactly this lighting, at exactly this time.

It's all brand new.

That doesn't mean we can't identify stuff in it.

So, it's just like... That's why using neural networks to decode brain activity is going to work.

Because we can identify the pattern of broccoli in our real world.

And if we're able to look at brain waves long enough, if we had the senses to understand brain waves long enough, then we could identify broccoli in our brain waves.

What do you mean by broccoli?

Broccoli, what I mean is that... The idea is that broccoli... We learn to know the taste of broccoli.

Because, well, let's look at... I mean, a good analogy is to look at how does a self-driving car recognize if it can move forward or not?

So, you dive into this topic and it's... How neural networks work is useful to talk about because then you can start to have ideas about how our brains are working.

So, if you say, well, a neural network is recognizing that there's a car in front of its path.

It's recognizing that something is in front of its path.

Well, how is it recognizing that?

Well, you say, well, there's cameras that are pointing at this car that's in front of the car that's driving.

Maybe that's a used tree.

There's cameras pointing at the tree that's in the path, okay?

And the cameras are breaking video down and there's also, you know, lighter and a bunch of different sensors.

The cameras are breaking down the video into pixels and frames and then pixels.

And the neural network is putting together all the little different...

At the lowest level, it's putting together the...

It's putting together, you know, whether there's a line or an edge or a color.

And at a higher level, it's, you know, recognizing, well, this is a long line or this is a curve or this is a...

And then at a higher level, this is a leaf and another part of the network is saying this is another leaf.

Another part is saying this is another leaf and another part says this is a branch.

And at a higher level, it says either this could be a flower or this could be a tree.

At a higher level, this is definitely a tree.

And so the idea is that our minds are basically doing the same thing.

Your eye has tons of receptors in it.

Tons of sensors, light sensors, blue light sensors.

And you have these photons that are bouncing off your retina and they're causing proteins to flip.

And as the proteins flip, the ionic charges displace eventually.

And then eventually there's this...

You know, you have a separation of positive and negative charges and there's an action potential

and all these neurotransmitters get released throughout the network of the brain.

And people will see...

Well, signals, they say, oh, I think there's a signal traveling from the eye along the optic nerve to the thalamus

and then back to the occipital lobes and pridelobes and the rest of the brain activity.

And we're like, wow, we see this signal and we're like...

And the question is like, well, what is the brain way?

Because we see these signals and they're being triggered and what is the brain way?

And a brain way seems to be triggered by these incoming signals.

Somehow you have the incoming...

Something that you see, the idea that's popularized is that photons are bouncing off of that

and they're bouncing off your eye and then they're triggering brain waves.

And these brain waves, they have characteristics that in time, like frequency patterns

and they have characteristics in space.

And your brain as a network is processing brain waves that have their spatial and temporal patterns.

And this is the kind of information we see moving all around on the ionotropic level.

And so the basic idea is I'm thinking that if a bottle is getting translated into a brain wave

and the computer is watching the brain waves while the computer is watching the bottle.

The computer is learning the brain waves in the bottle at the same time and saying this is this and this is this.

And I'm bringing these two things together.

This brain wave represents this bottle.

This brain wave represents that glass.

This brain wave represents this table.

And even though we're never going to have the same brain pattern twice.

You still have the pattern.

You still have the pattern.

What neural networks are able to do in terms of pattern matching and the self-driving.

Even if you look at that video of what a Tesla is seeing when it is processing the environment around it.

It's fascinating.

There is some really advanced.

But here's where it gets weird.

So let's say you capture the pattern of a glass.

Now at first you could say okay well now that I know what the pattern of the glass is and I can just build that model on the computer.

Press the button and the computer sends that pattern directly into the brain.

But the weird thing is if you know that there is no glass there and the computer is trying to send you a glass.

And the glass is interfering with whatever is in your brain right now.

How do you resolve that?

Right?

You almost have to figure out like and where is the glass going to be positioned?

Is it going to be on the table?

Or is it going to be on the air?

Or is it going to look like it's falling off?

Will it cause you to have some sort of unintended hallucination?

Will it cause your reality to crash?

Like a programmer?

It's all sorts of weird things you have to think about.

The thing I really wonder about is how do you teach an AI context for the material world, the scale of things.

And the way that they interact with each other, that to humans is intuitive.

But to machines that don't have the ability to touch and feel and IDA's and understand those different things in all these different contexts.

With really the semantical brilliance that humans have despite the fact that we're really really slow at other things that the computers are good at.

I really wonder what that is going to look like.

I don't have to say that massive parallelism can make up for chemical latency.

Chemicals are slower, but if you have massive parallel capabilities, you can make up for that difference.

I think that people is often repeated that computers are far faster than human beings.

Only linear things.

That's a good point.

I actually lost my train of thought just there for a second.

The human brain, for example, has amazing metabolism.

If you take a gliosol out of a human brain and you put it into a mouse, its memory will improve.

At least that's what some studies suggest.

There are network efficiencies that our brains have because we're robots that are billions of years old.

We started with nanosensors on single cells and we've grown into fully electrically conductive organisms that still have that in them that are pretty weird.

Our network, and not only that, our brains run on the power of something like a 9V battery.

I need to check the voltage and or the wattage, but I think it was around the light bulb in terms of the wattage.

Imagine that you have a computer that has trillions of connections and it runs on the same amount of power as a light bulb.

That's a networking efficiency that does not exist on the internet and not even close.

What's so fascinating about it is that through the chemical soup and being able to sense the finest gradient of change in that chemical soup,

we're able to form such different experiences from moment to moment because even every single one of our 100 trillion synapses can possess so many states

that it's a functional equivalent of, I think people like to abstract the neuron away when they're thinking about neural networks.

Let's talk about the ionotropic for a brain for a second because ions are particles.

Now we have a massively parallel particle-based computer that sounds a lot like a quantum computer.

Imagine this, but with a massive amount of connections.

We're not even close to building something like that.

People are like, oh man, computers are so much faster.

Here's the other thing.

There's this event who's had some sort of brain injury, could have been hit by a car or just born that way,

but they can calculate numbers by seeing them and they see numbers.

He's got topological calculation abilities.

What I'm saying is that we're running programs that are dominating over other programs.

If we inhibited whatever our main program was, we might discover that we can do calculations far faster than a linear computer.

I think our brains just aren't built on needing to do those sort of things because we're so based on interactivity with our environment.

If you had to interact linearly in some way, look at even the children who use the abacuses.

They can do these insane calculations because they've developed a different tactile sense for how to interact with math.

I think that students should be learning tensor calculus before they learn algebra before they learn calculus because when you combine geometry,

which is very visual, with algebra, at the same time, I think you're giving the human brain an advantage because now we can understand math in multiple ways.

The brain is very much a multimodal system.

Having two eyes and two nostrils and two ears allows for a sensory confirmation.

Two receptors cluster together hundreds of millions of times on a single synapse with the two being not only far more unique,

but also forming their own unique signaling cascade versus the two existing in isolation.

Our very most basic signaling unit of this heterodimer or heterotrimer of two or three receptors cluster together

and sensing their neurochemical environment and engaging signaling cascades that are so specific that they can influence that very receptor.

Or gene expression of a range of things that relate to that thing.

It's like the information flow has evolved so well that molecular sensing on the cell surface can directly change the way that different genes are read

to influence the environment in the way that best favors survival and evolution and proliferation of that organism.

That is incredible. If you really think about it, that is completely mind-blowing.

There's no reason in principle why we can't vastly defeat the information complexities of computers

just by changing the program that's running up here in our heads.

We just might need a lot of help at the things that they just naturally are better at.

Let's say we can figure out the communication protocol of the brain.

We can have a web browser terminal that we can access our thoughts with,

but then we can also basically say,

I want to turn off a visual program and I want to run a math program instead.

Then we start doing some amazing calculations that are beyond what can be done on computers today.

It's because we've told the brain we want to run a different program.

Can we please not have ads in our brains? Can we pause to discuss that for a moment?

Do you want the actual pause?

No, I mean...

Oh, you want to talk about it?

Yeah.

I mean, I feel like we should just mention this.

Sure.

Do you want advertisements on your retina?

Or do you draw the line?

That's one of those...

What is an advertisement on the biological level?

Humans are...

There's mating.

There's all these ads.

All these signals between people.

That's the sort of advertising.

If we got rid of...

What would it mean to say, okay, there's no ads or something?

I guess it would be like...

To want to inhibit ads is, in a sense, kind of like an evolutionary impulse.

It's like, imagine a male gorilla wants to inhibit the ads of other male gorillas.

It's so annoying, those ads are so annoying.

Have you seen the Black Mirror episode?

Spoiler alert.

Plug your ears if you care about seeing Black Mirror episodes and you haven't and you don't

want the apostrophe spoiled.

We'll tell you when...

How are we going to tell them when?

You need to have a friend with you who's seen the Black Mirror episode and they'll

tap you on the shoulder.

Which episode is it?

I don't remember specifically the number, but there is this one episode where there is

a sort of utopia in the usual dystopian way of Black Mirror.

And in this environment, there are these credits that you earn from running on a treadmill.

You can use to buy food, drinks, toothpaste, and pay to not have ads go off.

The ads completely surround you.

When you are in your sleep pod, your room, the entire walls are this AR interface.

And you have the sound directly going to your ears.

And if you don't have enough credits, you have to watch the ads.

If you look away or plug your ears, it will tell you...

They're being on the bicycle or something.

Yeah.

If you look away or plug your ears, they'll keep making warning noises until you open them

and finish watching it.

And potentially fine you for not paying attention to the ads.

Exactly.

Yeah, that's very...

So if Republicans maintain control of Congress and we have these sort of technologies, that

very well could be our future.

Wow.

I mean...

I'm being somewhat facetious, but...

Maybe a little bit too...

You want to avoid a scenario in which you're forced to do something.

And you want to maintain a scenario in which you have the choice to define your reality

the way you want.

So I imagine that in terms of how the universe is structured...

My hypothesis is that you're going to have a United States of Neuroscience and then

you're going to have a North Korea of Neuroscience.

I'm just saying in terms of universes created by people, you're going to have a universe

like living in Germany in the year 2018 or you're going to have a Neurolysis universe

that someone creates that's like living in the year 1600 in Rome or where there's like

Muslims and Christians and people are afraid to...

They're afraid that God can hear their thoughts or they're afraid that the governor of their

state, like if you're in a totalitarian, they could potentially hear your thoughts.

And so your thoughts have to be true towards the dictator of your society at all times.

And the funny thing is that with Neurolysis, a dictator could actually in a sense monitor

somebody's thoughts.

Maybe that was the part of 1984 that we missed.

I would just have to say that it seems like the universe is like instead of deciding between

one possibility or another, it's like creating both at the same time.

So you end up where it seems like in a long enough timeline what could happen is inevitable.

Do you know what I mean?

So that's kind of...

People, we're going to create in our lives and we're going to create artificial brains

and people won't care because they'll be like, oh yeah, well it was inevitable and the universe

is fractal and it's all mathematics.

And there's this conference coming up but it's on the other side of the planet and I

wish I could go to it.

It's all about how the dendrites computer and it's a Nementa conference.

And dendrites are they're hugely important.

It's like by itself it's kind of a computer.

But we're kind of like just wrapping things up anyways.

It's kind of like maybe a future podcast.

We're going to dive deeper into dendrites and dendritic computation.

And one thing, I guess I'm closing out for this podcast.

We could talk about there's a GPU conference coming up in the NVIDIA GPU conference or

GTI conference and I'm planning to go there because there's many, many good talks on the

topic of artificial intelligence and the latest innovations that people are discovering.

And one of those is really interesting because they're discovering that because if you want

AI to take sensor data and recreate a 3D structure from that, it's actually a really hard problem.

What they found out was that if you give AI some basic 3D models first, then they're finding

out that it's able to recreate the 3D model from the sensor data.

So it's like giving a, I think of it as giving a child a toy to play with in order to catch

on to the concepts that are more fundamental to a human's existence.

And so they're giving this AI 3D models and it's more able to handle this.

So the idea there though is that could have to do with sensory confirmation.

Where if you have two eyes, let's say a crocodile has two eyes looking two different directions

and my arms are extended out and they're pointed in each direction.

So you have the crocodiles, let's say it's a deep learning program and like a neural network

just like we talked about earlier.

And one eye is trying to figure out the geometry of the world around it so we can notice some

animal passing that it wants to eat and the other eye is doing the same thing.

And I have to think about how a nerve has like two ends, right?

It's almost like a battery, like a north and a south, right?

And so the crocodile is getting to each eye has millions of sensors in it, light sensors,

and it's going through the neural network and it's creating like all these brainwaves

which are the sort of like a brainwave of four dimensional patterns.

It's like an electromagnetic tensor field moving with all these different parts moving

throughout this system and at some point the left eye and the right eye meet

and where they meet they're confirming each other's model

and the confirmation that each eye is getting is magnifying its ability.

So it's an argument for why two eyes have an evolutionary advantage.

There's sort of a sensory confirmation.

The first week of May, I think it's like May 7th, is about they're going to be talking about that.

And it's very interesting that would make a case for we could potentially build

how we potentially might build better AI by making it multimodal.

And I think it needs to be at the very baseline level

the more we can mimic the architecture of how single synapse functions

the closer we'll probably get to capturing the breadth and the richness of the human experience.