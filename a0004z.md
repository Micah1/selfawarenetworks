a0004z This note has low importance to the main arguments of the book.

Tag: Neural Rendering Map

3D Feed Forward Neural Networks for Super Resolution Example
Super resolution neural network deep learning
https://medium.com/@rawatashutosh1411/video-super-resolution-using-deep-learning-4fc9a39f8bcb

Really interesting thread about the difference between Gan Synthesis and Stable Diffusion
https://twitter.com/tomgoldsteincs/status/1560334207578161152?s=21&t=HFIXonVVMAB06ohIGzNDZA

Introduction to Diffusion Models for Machine Learning
https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/

What is interesting is that an image is reduced to noise in steps, is the neural network learning the image at each step as it is reduced to noise? Is that how it is able to reconstruct images from noise.

It is thought that brainwaves are gaussian like pink noise, in sync, but essentially not containing information, so the action potentials I argue define the information from the incoming synapses, and the noise is actually attractors driving oscillatory neural activity.

The tonic oscillatory noise I argue provides for the ground of being, awareness, raw experiential conscious expectation that new information from our senses and the content or patterns inside our mind arise from.

In that sense Stable Diffusion is a better analogy for how our minds create representations of reality, how our minds are capable of hallucinations, dreams, out of body experiences, drug induced altered states of mind, spiritual experiences, visions, and experiences that we might call episodes of in the zone creativity, inspiration, and or imagination.

Rephrasing:
As a signal train moves along a neural pathway goes from being a train of action potential spikes & chemical phase changes in temporal spatial patterns across the brain it's signal power is dissipated across the oscillating neural cell assemblies, absorbed into the tonic firing rate, while altering the tonic firing rate, but the tonic oscillation has been described as a noise pattern. In essence the high phasic waves are rare and in the context of information theory that means their information content is high, the tonic waves are extremely common place and so their information value is extremely low, but there is an analogy to Stable Diffusion AI because over time that high information signal pattern is being noised, with each iterative oscillation that turns what was a high phasic firing pattern into a tonic oscillation again. It is analogous to adding noise to an imagine over time, perhaps the high information pattern oscillates enough times to change the growth pattern of synapses (and perhaps it does not, such as in the case of seeing an illusion) and so the tonic brainwave oscillation remains trained & ready to conjure any sort of mental imagine based on the spike trains that push high phasic burstlets into it's oscillating matrix.