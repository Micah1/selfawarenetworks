a0004z

Tag: Neural Rendering Map

3D Feed Forward Neural Networks for Super Resolution Example
Super resolution neural network deep learning
https://medium.com/@rawatashutosh1411/video-super-resolution-using-deep-learning-4fc9a39f8bcb

Really interesting thread about the difference between Gan Synthesis and Stable Diffusion
https://twitter.com/tomgoldsteincs/status/1560334207578161152?s=21&t=HFIXonVVMAB06ohIGzNDZA

Introduction to Diffusion Models for Machine Learning
https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/

What is interesting is that an image is reduced to noise in steps, is the neural network learning the image at each step as it is reduced to noise? Is that how it is able to reconstruct images from noise.

It is thought that brainwaves are gaussian like pink noise, in sync, but essentially not containing information, so the action potentials I argue define the information from the incoming synapses, and the noise is actually attractors driving oscillatory neural activity.

The tonic oscillatory noise I argue provides for the ground of being, awareness, raw experiential conscious expectation that new information from our senses and the content or patterns inside our mind arise from.

In that sense Stable Diffusion is a better analogy for how our minds create representations of reality, how our minds are capable of hallucinations, dreams, out of body experiences, drug induced altered states of mind, spiritual experiences, visions, and experiences that we might call episodes of in the zone creativity, inspiration, and or imagination.

Rephrasing:
As a signal train moves along a neural pathway goes from being a train of action potential spikes & chemical phase changes in temporal spatial patterns across the brain it's signal power is dissipated across the oscillating neural cell assemblies, absorbed into the tonic firing rate, while altering the tonic firing rate, but the tonic oscillation has been described as a noise pattern. In essence the high phasic waves are rare and in the context of information theory that means their information content is high, the tonic waves are extremely common place and so their information value is extremely low, but there is an analogy to Stable Diffusion AI because over time that high information signal pattern is being noised, with each iterative oscillation that turns what was a high phasic firing pattern into a tonic oscillation again. It is analogous to adding noise to an imagine over time, perhaps the high information pattern oscillates enough times to change the growth pattern of synapses (and perhaps it does not, such as in the case of seeing an illusion) and so the tonic brainwave oscillation remains trained & ready to conjure any sort of mental imagine based on the spike trains that push high phasic burstlets into it's oscillating matrix.

Another great Stable Diffusion thread
https://twitter.com/ai__pub/status/1561362542487695360?s=21&t=HF9PLCaZAnc_g4uzE3uW7w
https://threadreaderapp.com/thread/1561362542487695360.html

another great diffusion thread
https://twitter.com/tomgoldsteincs/status/1562503814422630406?s=21&t=2PgerkKJpTGm-GudjButbQ
https://threadreaderapp.com/thread/1562503814422630406.html

# Theory of Redness

Redness is a distinct pattern phase wave differential from your base line tonic oscillating brainwave pattern.

Note a0306z further explores the question of Qualia: Internal Representation: ie What is the redness inside human experience? https://github.com/v5ma/selfawarenetworks/blob/main/a0306z.md

Stable Diffision as an example of a diffusion network is perhaps the best analogy yet for how your brain might be rendering redness and images

because the idea is that your grids of brain cells receive distinct signal patterns from your senses, and as those signals enter your brain they get noisier and noisier, the oscillatory dynamics gradually dissipate the high frequency phasic bursts from the outside world into lower frequency tonic bursts that have high magnitude area, essentially turning incoming sensory input into low information noise, but noise that drives an attractor state of readiness, the ground of awareness, the ground of being

along the way the neural networks of your brain are changed, physically changed by the incoming sensory patterns in a way that causes us, or our brains to make memories and predictions or beliefs of what is out there, memory-predictions, also referred to as predictive coding.

The predictive coding as synaptic connections & dendritic morphological specifics allows individual cells and oscillating cell assemblies to selectively react to patterns, and to ignore patterns for other cells to selectively react to.

This learning is like how in a Stable Diffusion network the neural network is learning how the image is decayed into noise, via oscillation, but this learning also allows the network to rapidly generate new images based on new inputs.

For this reason the Stable Diffusion class of neural network is perhaps the best analogy yet for how the brain makes the mind.

Palette: Image-to-Image Diffusion Models https://arxiv.org/abs/2111.05826

PeRFception
https://github.com/POSTECH-CVLab/PeRFception

# a0004z.reconstruct
Look up Sparse 3D reconstruction.
Sparse set of points from photos + camera positions
https://www.researchgate.net/figure/Main-steps-for-sparse-3D-reconstruction_fig1_4343313

In essence with NAPOT Neural Array Projection Oscillatory Tomography I'm arguing that the human brain is doing an operation similar in concept to Sparse 3D reconstruction. It is as if each neural array is rendering part of a photo, and the network of brain oscillations is binding the parts of a photo (or your model or parts of your model of reality that can consist of any sensory modality such as hearing, taste, smell, touch, feelings) into a whole experience across space & time that you are aware of (that your brain is aware of)

In addition to neural rendering there is another operation that needs to happen that is similar to 3D Semantic Segmentation, or the identification or mapping of different objects & concepts in your perceptual space, your field of awareness. So you can differentiate and attach valence or value to different forms (patterns) that are arising in your formless awareness (your tonic oscillation or ready state).

My conjecture is that the two streams hypothesis search v5ma/selfwarenetworks repo for a0018z.twostreams may allow the brain to independently focus on each type of operation (at least to differing degrees of focus). With the Parietal stream focused more on rendering (where), and the Temporal stream focused on semantics (what) and perhaps both streams are doing a little bit of both.