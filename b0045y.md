b0045y 7,804 words

Transcribed by OpenAI's Whisper.

Listen to the recording https://recorder.google.com/83fb25f3-2995-4910-8d43-334f790573ab

This was a clubhouse conversation.

Title: Neurons Photon Inputs (Dec 16, 2021)

Summary:

The conversation revolves around Dr. Spencer Smith discussing his work on advanced two-photon microscopy techniques for neuroscience research. He explains the development of a two-photon microscope equipped with two independent scan engines, enabling simultaneous imaging and optogenetic manipulation of neurons with micron-level resolution across a large field of view. The system utilizes resonant scanning for speed and adaptive optics to correct aberrations, enhancing image quality, especially at the edges of the field.

Dr. Smith elaborates on using genetically encoded calcium indicators (GECIs) to visualize neuronal activity by detecting changes in intracellular calcium concentrations during action potentials. He addresses challenges such as low photon detection rates in two-photon microscopy and the need for multiple samples to achieve a good signal-to-noise ratio. The conversation also touches on the limitations of intrinsic imaging techniques, the potential of multiphoton optogenetics for targeted neuronal stimulation, and the difficulties in mapping complex, distributed neuronal networks.

Participants inquire about integrating other imaging modalities to overcome depth limitations caused by tissue scattering and discuss the potential use of fluorescence lifetime imaging microscopy (FLIM) and other fluorescent reporters. Dr. Smith shares insights into his career path, emphasizing the importance of learning on the job and pursuing individual research interests.

Key Points:

Two-Photon Microscopy with Independent Scan Engines:

Development of a two-photon microscope featuring two independent scan engines.
Allows simultaneous imaging and optogenetic manipulation of neurons.
Use of Resonant Scanning for High-Speed Imaging:

Employs a resonant scanner operating at 8 kHz bidirectionally, achieving 16,000 lines per second.
Enables fast imaging necessary for capturing rapid neuronal activity.
Adaptive Optics for Aberration Correction:

Utilizes off-the-shelf deformable mirrors (from Boston Micro Machines and ALPAO) for adaptive optics.
Corrects optical aberrations, particularly at the edges of the field of view, improving image fidelity.
Calcium Imaging with Genetically Encoded Indicators:

Uses GECIs derived from green fluorescent protein and calmodulin.
Detects changes in intracellular calcium during neuronal firing to visualize activity.
Challenges in Photon Detection and Signal-to-Noise Ratio:

Low probability of two-photon events necessitates collecting multiple samples.
Extending dwell time per pixel and pooling data improve signal integrity.
Limitations of Intrinsic Imaging Techniques:

Intrinsic signals like cell swelling or birefringence are too weak for high-resolution imaging.
Calcium indicators provide a stronger signal suitable for cellular resolution.
Multiphoton Optogenetics for Targeted Stimulation:

Multiphoton excitation allows precise activation or inhibition of individual neurons.
Facilitates studies on how specific neurons influence network activity.
Difficulties in Mapping Distributed Neuronal Networks:

Neuronal inputs are widely distributed, making comprehensive mapping challenging.
Current tools are limited to observing small brain regions at a time.
Integrating Other Imaging Modalities:

Potential compatibility with techniques like ultrasound-guided light for deeper imaging.
Acknowledges benefits but notes they haven't been implemented yet.
Use of FLIM and Other Fluorescent Indicators:

FLIM-based indicators can be used to study various intracellular processes.
Equipment is compatible, requiring only appropriate biological specimens.
Applications in Behavioral Neuroscience:

Technology could help investigate neuronal circuits underlying behaviors like compulsivity.
Possibility of stimulating neurons in specific patterns to study behavioral outcomes.
Career Insights and Research Development:

Dr. Smith shares his path from physics and math to neuroscience and microscopy.
Emphasizes learning on the job and pursuing one's own research interests.
Technical Design of the Imaging System:

Detailed explanation of the optical setup, including polarization-based beam combining.
Temporal multiplexing allows simultaneous operation of dual scan engines.
Challenges with Imaging Depth Due to Tissue Scattering:

Biological tissue scattering limits penetration depth in imaging.
Discusses existing methods to image deeper but notes practical limitations.
Use of Commercial Adaptive Optics Components:

Employs commercially available deformable mirrors rather than custom-built MEMS devices.
Balances performance with practicality in system design.
Discussions on Signal Stability and Noise Reduction:

Addresses the importance of signal stability for accurate measurements.
Explains methods to mitigate noise, including extending dwell time and sampling.
Potential for Future Research and Collaboration:

Open to integrating new techniques and exploring additional applications.
Encourages others to consider how this technology can be applied in different contexts.

# Transcribed by OpenAI's Whisper.

...goes to a Y scanner, and then pivots in the other direction.

So, yeah, we used the resonant scanner to go fast, and then the slow X we used to impart an offset laterally along that same resonant axis, and then another low-speed Y mirror, Y scan.

And so the resonant is operated at eight-quarters to it, and it scans bidirectionally, so that's giving us 16,000 lines per second. And then those are divided into multiple frames.

And then the X galvo is not really moving most of the time. It's just a position, the field of view. And then the Y galvo is scanning at whatever our frame rate is, so, say, 30 or 60 hertz.

Wow, excellent. I'm sorry to hog bandwidth here, but this is a fascinating field. I'm so delighted to listen to your work. I'm just wondering, can you also do this as image, besides imaging, can you change it, let's say, to an NDAG and start using these for a focal ablation in your work?

Yeah, absolutely. And there have been experiments where they do photoablation of, say, dendrites or different components of a cell, and then see how that changes activity in the network. That is manipulation that's used. What's used even more often are optogenetics, which maybe some of you are familiar with. This is a way that you can genetically engineer neurons to express proteins that gate current flow across the membrane based by the presence or absence of light. And so, basically, you can use light to turn neurons on or off.

And those types of experiments, or exactly why we built this with two independent scan engines, the idea being that we could use one of those scan pathways to be turning neurons on and off with light using optogenetics, and the other pathway to be imaging neuronal activity and see how turning on and off individual neurons changes neuronal activity across this large length scale and still maintain that mind-arm resolution.

Holy shit. Well, can I interrupt? If you want, I'll give it a... What was that? May I interrupt, please? I had a few questions.

First of all, to both of you, your professors. So, I wanted to ask, how do you guys study in order to grow as a researcher? Because Professor Hiroshi, if I'm not butchering your name, I'm so sorry if I am, and Professor Spencer, both of you are doing research work, and I am interested in that, but I'm trying to understand how does one grow in that field. One, and two parts, and the second part is related—I got a tension shift because I was trying to understand the conversation that both of you were having, and I was having a hard time. Another part is... So, sorry, did I interrupt someone? Oh, no, go ahead, go ahead. You're doing fine.

Okay. Then, Professor, could you please comment on sensitivity, and as well as noise, as we know that it's, I mean, from the stability and the fluctuation point perspective? So, could you please comment on these two aspects, and then I would want to understand from signal integrity, and... I'm sorry, I'm having loss of thought. I was writing while you were speaking, so... It's okay.

So, let me answer a part of that, and then, if I miss a part, we can come back and pick that up. So, one part was my career trajectory, right? I studied physics and math for my undergrad degree, and then went to a neuroscience program for my PhD, and there was a—I did a small MEMS project while I was there—and then went through the tail end of my graduate school, and then my first postdoc started getting into multi-photon imaging and just sort of built what I needed to do the experiments that I wanted. Then, as I got grants and as the brand initiative came along, we elaborated that work. It's, you know, a lot of learning on the job, and not everything—I'm a big believer in people finding their own path. This is what worked for me. I'm not endorsing this particular pathway for anybody else, but that's what I did. It was about recognizing the moment that you're in, recognizing what works, what you're good at, and trying to capitalize on that—trying to do the things that you can get traction on doing. It's not always going to be what you want to do right off the bat.

So, that's one small comment on that part of your question about the stability of the signals. These pulses are coming at 80 megahertz, and I mentioned that the likelihood of a two-photodom event is very, very low, right? And then, even if one happens, you also have to detect that photon. It has to get caught by your objective, get caught in your collection pathway, and make it to whatever photodetector you're using. And that's a rare event.

Most of the time, in most people's two-photon microscopes, the average number of detected signal photons per excitation pulse is less than one. Oftentimes, it's much, much, much less than one, which is something that surprises some people. They don't—when they build these systems—they don't necessarily quantify that. But if you do, that's typically the fluxes that we're dealing with, particularly when imaging neural activity and EVO. And so, that's why we need multiples per time point in order to make a decent signal. You need, on the order of at least dozens of photons per sample point, to have something that has a decent signal-to-noise ratio. So, if you're limited by shot noise anyway, then the maximum signal-to-noise you're going to get is determined by the number of photons you detected. If you're only detecting a few photons, the signal's going to be so noisy, it's going to be hard to make sense out of.

And so, that's why we need to extend the dwell time per pixel, or have multiple samples per pixel—and have multiple samples per neuron—so that we can pool those together and have enough photons to have a signal with fidelity for our measurement.

That's great. Is this, um, so—is this what you call optical coherence, uh, tomography? So you're just doing tomography on lots of different light samples?

No, no—this is regular, uh, laser scanning two-potom microscopy. Actually, Roshi—who just spoke—he's doing OCT, or it's one of the things that you mentioned that he does.

Okay. Um, and what are you imaging exactly when you say you can image the brain's oscillation? You're talking about blood flow, right?

No, this is neuronal activity. Usually, what we do is we have genetically engineered mice that are expressing a calcium indicator—a protein that has a fluorescent component derived from green fluorescent protein (from aquaria, victoria jellyfish) and calmodulin, a calcium-binding protein. That protein fluoresces more when it is bound to calcium, and it turns out that neurons increase their intracellular calcium concentration by 10 to 1,000 fold during an action potential, very briefly. That's a big change, so that's a nice, big, meaty signal that these calcium indicators can pick up and give us a decent signal with microscopy.

Yeah, the other idea that I heard was that the neuron expands when it fires, and that would be another way to detect it, potentially?

Yeah, so those signals are really low. I've done experiments with this family of techniques where you're measuring neuronal or brain activity using these intrinsic signals—where you don't put any indicator in. We call it intrinsic imaging. There are lots of different signal sources: one, as you said, is cell swelling; there are changes in birefringence; you can also look at changes in blood oxygenation that are correlated, at a larger length scale, with neural activity.

Those signals are on the order of, you know, one part in 10,000—they're very weak signals—and typically you can't separate out individual neurons in vivo in dense neural tissue, so the calcium indicators let us do that. You're right that there are other optical signals there, but they're typically so weak that we can't really use them in intact tissue. And not for cellular resolution, anyway. We still do intrinsic imaging in my lab all the time, using hemodynamic signals around 700 nanometers, of course. Deoxygenated and oxygenated blood have fairly different absorbances of 700‑nanometer light, and we use that as a contrast mechanism for mapping out macroscopic brain activity, but that doesn't give us cells.

I had a micro question real quick. What did you say? Vib—uh, vibring, vibringence—what was that word?

Oh, birefringence. Birefringence. Could you spell that? Um, yeah, sure. Let me just check this one real quick. Okay, yeah: B-I-R-E-F-R-I-N-G-E-N-C-E. Thanks very much.

So, yeah, this is just—this is light that has a property that crystals have; typically, crystals have it, and any anisotropic material has it. It's the index of refraction that light experiences depending on its polarization. That's what that property refers to. So, as polarized light, people experience different indices of refraction. Thanks for that. Due to anisotropy in the material—so, thank you, Dr. Smith. I've been listening attentively—in fact, as an optics/biomedical engineering person who's also interested in neuroscience, it was very illuminating.

I had some few questions. First, I'm really surprised that you were able to implement adaptive optics at such a small scale using MEMS, which is quite a feat in itself. But, does that help you to increase the depth information? Because adaptive optics is more geared toward astrophysics. So does that increase your depth information, or address the lack of depth information that you clearly suffered from in, say, a two-foot-tall microscopy system?

So, first we're using an off-the-shelf deformable mirror—from Boston Micro Machines. I didn't build a novel MEMS deformable mirror for this; we bought what Boston Micro Machines already sells. We also have an Al Powell unit from a French company to provide a much larger stroke. They're not MEMS based, but they have a much larger stroke so that can give you more defocus.

For those who are not familiar with adaptive optics, really astronomers developed this because the atmosphere distorts imaging. You can shoot a laser into the upper atmosphere to make a guide star. Then you know that it should be a point source; you can measure the aberration of that point source and then make the opposite aberration on a mirror. All of a sudden, you get sharper pictures through your telescope.

You can make this whole thing closed-loop—measuring the aberration and correcting it immediately—or have an open-loop where you step through an orthogonal basis set to figure out how to deform your mirror to correct for the aberrations.

In our system, we're using the deformable mirror in the middle of the field of view for most of the Z range. It doesn’t make much difference where it is until we image a sample that has some aberration—sometimes caused by the tissue itself, or the way the cover slip is placed on the brain. The deformable mirror helps a lot with that. Another benefit is at the edge of the field of view.

All microscope objectives are optimized to work well on axis, and their performance typically falls off as you go off axis. One of the things we did in designing both this system and the Trepin 2P was to optimize all of the optics so they work as well at the extreme edge as they do on axis, which usually isn't done. If you're using Zeiss, Olympus, Nikon, or similar, you want it to work well on axis even though performance degrades off axis. We tried to get it as good as we could, though there is still degradation as you move toward the edge.

Once you start building with precision optics, there are limits to how precisely you can position them. When we're at the very edge of the field of view—even outside of our expected range—we were up like three and a half; this is a 5 mm by 5 mm field, so off in the corner we're about 3.5 mm off from the center. We had some pretty bad aberrations—regular optical aberrations well characterized by Zernike coefficients—and we were able to step through those coefficients to find a command to send to the deformable mirror to cancel out that aberration and recover high-resolution imaging at the edge of the field.

That's what we typically use the deformable mirror for—it squeezes out a bit more resolution, a bit higher fidelity, and a bit more brightness when imaging conditions are not ideal. We can also use fast Z translation, but in practice we don't typically need to do that.

Yeah. Um, great.

So my other question is: have you experimented with some kind of exogenous fluorophores as opposed to calcium imaging? Calcium imaging, as we know, is a well-established imaging technique, but I've seen research papers where they boost the amount of intracellular calcium—although that may trade off with cell toxicity. Do you think that implementing your two-photon technique would work well with endogenous or exogenous fluorophores, and have you explored that route?

I've done a little bit with endogenous autofluorescence (some of which is coupled to metabolism) and tried imaging that before, but the endogenous fluorescence is really weak. We have done some work with second harmonic generation. I don't know if that is of interest to you, but that's something we've done.

We've also imaged fluorescent proteins that are not calcium indicators—we've done plain GFP—and, as far as labeling animals to look at very fine structure (submicron dendritic spines), that approach works. But as far as endogenous fluorescence goes, it's typically so weak that we haven't spent a lot of time on it.

This system was really built for calcium imaging. What's special is that it has 25 square millimeters over which we have micron resolution and we can capture things simultaneously. We've got multiple beams for sampling. Most of the time, you don't need that. If you're imaging dead tissue or something happening much more slowly on a multiple-second timescale, you can use other instruments. We had to build this because we needed sub-second resolution over a large field of view with high resolution, and that particular constellation of parameters wasn't met by anything we could buy.

So, the other difficulty when imaging tissue is the scattering effect. Human tissue in general has a large scattering coefficient (or reduced scattering coefficient). Do you think you can achieve better resolutions by implementing other imaging modalities along with the two-photon microscopy you just developed? For example, I've seen applications where acoustics are used to guide the light into deeper tissue for both deeper imaging and stimulation.

Yeah. I know some of that work actually—I know some of the people who do that work. That's really cool. Using ultrasound to make a guide star deeper, modulate fluorescence, and have that tagged so that they can image deeper in scattering tissue. Some of those techniques, to briefly answer your question, are compatible with our system. Not all of them, but some are. We haven't done much implementing them; we've been doing mostly vanilla two-photon imaging, where it's fairly easy to see five, six, 700 microns down. For our neuroscience work, that gets us the data we need. We haven't done much with three-photon imaging (although we have a published three-photon version of this system that we've recently fabricated and are still testing). We haven't yet explored the more exotic photoacoustic techniques for imaging even deeper in tissue—but I like that work. It's fascinating.

Yeah. Yeah.

This will be my last question for now. Do you think that one can actually achieve, as far as we know, the optogenetics requirement of having an optical fiber guided into a transgenic (or whichever) model? Basically, you need some kind of light source guided in right now. I think we have diodes that are tuned to that specific wavelength so that opsins can be stimulated. But do you think you can achieve this using two-photon (as opposed to imaging) so that you can just stimulate opsins in a more directed way?

Well, yeah—I mean, the field has been doing multi-photon excitation of opsins for a while now. It's challenging, but you can do it. There are challenges in activating them. I've mentioned before that you're clearly sophisticated about this, but for others who are listening: optogenetics is a way to genetically engineer neurons to express proteins that gate ion flow across the membrane when stimulated by light. Some proteins suppress neural activity; some activate it. Most experiments use one-photon excitation—genetically engineering some neurons in the brain and then flooding the area with light via a fiber optic. In a smaller number of studies, multi-photon excitation has been used. The advantage is that you can target individual cells—say, turn on or off three cells while leaving the rest untouched. That level of precision is very powerful.

I think the field is still figuring out how best to use that and gain insight from it. Most experiments I've seen so far have been fairly basic in their theoretical framework. But that's what we built the system for: we have two scan engines—one dedicated to stimulating or suppressing individual neurons, and the other to imaging general activity in the same population.

Thank you. If anybody else has questions, please do ask.

Thank you for your questions. This is fun. It is really cool to be able to stimulate one neuron—especially when you have different inputs coming in. I injected different inputs into the striatum, but I couldn't stimulate them separately very well. Of course, you can use TTX and such, but it would be very useful if you could inject different opsins and different inputs, excitable at different wavelengths, so that you can detangle them apart and be sure you're only stimulating that neuron and not another.

Maybe in the future again.

You know, back in 2007—when some of this stuff was just coming out—Michael Heuser and I wrote a little news and views piece for the first paper that had direction control from Diceroth's lab (Veng Zhang and colleagues, and Carl Diceroth). Our minds were racing: as soon as this technology was developed, we wanted to play the brain like a piano—really orchestrate neuronal activity and test theories of coding.

What we, not only Michael and I but the whole field, have realized is that it’s much easier to daydream about that than to actually develop experiments and execute them to gain insight. One difficulty is that any neuron you look at is receiving input not only from the local area but from millimeters away—much of it subcortical. It’s really tough to encapsulate what makes a particular neuron fire when the underlying circuitry for complex behavior is so widely distributed. Most of our tools are designed to look at one small part of the brain at a time.

In recognition of that, we wanted to build a system that could capture dynamics across a larger field of view. It’s an improvement—it helps—but it still only captures cortical activity over a large area. It doesn’t capture subcortical activity. I like that it gives us high-fidelity imaging of individual cells, but it’s extremely frustrating that it’s basically limited to cortex. We can also image through grand lenses to look at subcortical structures, but then you’re looking through a tunnel at a small population of neurons. It’s still very difficult to reconstruct the large-scale neuronal activity underlying complex behavior.

Yeah. So, could you—under anesthesia, I don't know—is it different? Is it easier than in anesthesia? I was referring mostly to slices or cultures, where you can, if you wished, stimulate one or two neurons separately and know exactly which one you're stimulating.

Yeah. And then look at the network in the slice—that I'll explain briefly. I did experiments where I injected two regions and then looked at which two regions combined could generate an upstate more easily in spiny projection neurons. I saw in vivo that when I combined behaviors (with sensor and motor inputs, or with genetic stimulation like LTP or LTD protocols), I could, with just a few seconds a day, trigger compulsive behavior. Then in the slice I repeated two-input stimulation. I saw that two different inputs—like from the amygdala and the sensory motor input—would generate much higher upstates than any other combination of two inputs I injected.

Okay. But I could never dissect out which input I was stimulating because I injected two, and I could never time the stimulation precisely (for example, one millisecond later, stimulating another at that frequency). This timing is what gives me upstates and such. I was thinking about those experiments. It would be cool to stimulate one, two, three, etc., until you reach the threshold to induce compulsive behavior.

You're right. I think you've outlined a good experiment. I’ve seen mechanistic experiments in cortex where they stimulate one, two, three, or four neurons until an avalanche of activity occurs, just to see where the threshold lies. But that’s in a cortical region—not necessarily tied to behavior in the same way you're talking about. It’s a great example where someone might use an optical cannula or a grand lens to ask that question in vivo in a subcortical structure with single-photon resolution. I don't recall anyone doing single-neuron resolution optogenetics with multi-photon excitation using a grand lens and demo. On first principles, it seems possible, but I can’t recall a case where it’s been done.

Well, I haven't done it yet either. But I think it would be really interesting—especially since there's a paper from my lab showing that cortical regions influence compulsive behavior. It’s a good model because it starts as a regular behavior and then develops into a specific system. One could repeat those experiments, check how many neurons are involved, their timing, and maybe even do some retrograde labeling to see how much is labeled and where. I’ll let others comment further, but this is Suzanne Tamari's paper—is that everything?

Yes. Yeah, she's great.

Hi, this is Roche again—sorry, I'm immensely enjoying this conversation. Let me make a quick comment regarding Katarina's work that may be applicable: she's doing a lot of LTP in the traditional way (for example, looking at calcium influxes, NMDA receptor work, etc.). I actually built a career studying nitric oxide synthase—we were the first to knock out those genes, about 20 years ago. One thing I have to say, relevant to Spencer's technology that looks at fluorescence, is that you can use reporters—say, FURA‑2 or other reporters—to look at nitric oxide activity. There are many ways to use different reporters or excitable reinforcement proteins that can take advantage of fast scanning and functional imaging. That’s something OCT cannot do because it cannot respond to fluorescence.

A quick comment about autofluorescence: sometimes, if you look at different organs, autofluorescence is highly relevant (for example, in gastroenterology when examining eosinophils, which autofluoresce very well). With confocal endomicroscopy, we can use that to enumerate diseases like eosinophilic esophagitis. So sometimes what you see as a problem (e.g., scatter) can actually be used as a tool. For instance, in our endoscopy unit we use elastic scatter spectroscopy because the major scatter comes from the nucleus, which can help detect dysplasia, disease, and early cancer.

And one quick addition—could you also use that, for rent, actually, for modulating? Yeah, you asked for a rent—what the hell? Can you use a rent?
Yes, there are rent-based indicators. There are rent-based calcium indicators and rent-based indicators for other intercellular processes as well. Most of our work to date hasn’t used them much, but they have their place and can be extremely important. Riohei Yasuda is one name that comes to mind—he’s gotten a lot of use out of various reporters for different biochemical cascades inside cells, especially neurons around synaptic changes. We haven't done projects on that yet, but it's all the same equipment—we just need to get a mouse, put it on, and image it. It’s going to work the same way.

Yeah, that's right. I worked during August and November—I did this too. I don't know, I've got an eye on it. And it would probably be cool to see inhibition spread throughout the brain. I think inhibitionists—I've studied them—it would really be cool to see. What we did with inhibition worked, obviously.

Yeah, I agree. There have been many calcium indicators inside inhibitory neurons, particularly in genetically targeted subpopulations. That has been hard to synthesize across multiple studies with varying results. Another approach is looking at chloride signaling inside individual cells—examining the pattern of inhibitory input inside a single cell. I think there's a deeper aspect there that requires more exploration.

I don't want to press too hard on developing that further now, but we try to enhance it by tagging to different markers. There's been some work on that, though I'm also working on disability-related projects. It would be interesting to see.

Yeah, I agree.
Rush, do you want to ask a question?
You need to cover the chat—yeah.
Yeah, Rush, we can't hear you.
Maybe he'll be back soon, because all of you are here. We couldn't hear you earlier, so if you want to ask a question, please do.

Yeah, thanks—okay, I think I'm audible now. I just want to understand the independent scan engines. I followed the paper, but is there something like using two independent signals to generate an interference pattern?

No, no—sorry, not an interference pattern. Basically, you're measuring two independent variables at once and using both sets of results to extrapolate what you're actually looking at. Is that correct?

Uh, not quite.

Right, so basically each scan engine acts like a single scan engine in a conventional laser scanning microscope. The laser is scanned in raster patterns, line by line across the tissue, to measure changes in calcium indicator dynamics. The second pathway can do the exact same thing and is completely independent. We're doing temporal multiplexing with tiny 6.25‑nanosecond time windows that switch between the two pathways so they can scan simultaneously while remaining independent. One scan engine can be imaging a few cells while the other images a completely different part of the brain.

That’s what we meant by independent scan engines. We’re not trying to create any interference pattern between them—they don’t need to cooperate at all. They are completely independent samples within the same field of view. They both have access to the same optical volume and can measure neuronal activity in whatever neurons are present in that volume.

Now, we’ve been talking a lot about optogenetics and manipulating neuronal activity. There’s spectral separation involved. For example, one pathway can activate neurons while the other images activity in all those neurons. In the past, people combined both lasers into one scan engine and gated one or the other. For example, you could quickly activate a few neurons and then switch back to the imaging wavelength.

I didn’t mention this at the beginning, but the beams are combined via polarization, not wavelength. You can actually set up an experiment where you have an optogenetic laser for manipulating neural activity and an imaging laser going into both pathways. You could have four lasers go into this system to manipulate neural activity in two different brain areas at the same time. That's really amazing—it's always been a problem in my experience. There are two ways to get the cutoff signal (because of transition delays, etc.), so it's really cool.

Yeah, I've experimented with different ways to do multi-photon optogenetics. The biggest thing is that you don't have to keep the PNT; you do one-photon optogenetics plus 2% of the PNT. You need a shutter in front of the PNT, or some fast-switching mechanism. I did build a system based on switchable PNT, but there was a big compromise on the calcium imaging, so doing everything in multi-photon mode helps a little.

And you mentioned taking advantage of fluorescence—specifically with calcium. Just to clarify, you're measuring mostly photons; you're capturing an image of the fluorescent photons emitted by the calcium markers. Is that correct, or is there anything else being sensed?

I think that's basically it. There's a calcium indicator protein that is a fusion between green fluorescent protein and calmodulin—a calcium-binding protein—which fluoresces more when bound to calcium, thus reporting changes in calcium concentrations. It may use a diode, but yeah—that's what we're talking about.

Okay, awesome—thank you. One last question: Clarissa signed us out. So, calcium deposits—in my understanding, when the brain successfully carries out a pathway, it reinforces that pathway with calcium, saying that “this worked last time, so let's use it more actively next time.” Is that correct? Whenever we have brain activity, we generally have calcium deposits along the pathways that were successfully triggered. It sounds like you're talking about synaptic plasticity—the reconfiguration of circuitry, memory, and so on—with calcium playing a major role. It’s not the same process in every neuron, and not every pathway uses calcium repeatedly, so it’s complicated. But the initial answer is: calcium is a huge player.