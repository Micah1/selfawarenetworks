b0038y

A slightly Edited Original Audio link: https://recorder.google.com/71223ecf-94c0-4679-b46e-8ff3fb064592

# 15:41 Last update at 15:41

Note from Dec 26, 2021 - updated in July 2022

# The Role of Non-Linear Sequency in Neural Array Projection
## This section explores how non-linear sequences of action potentials, interpreted as a Taylor series, contribute to understanding how neural arrays transmit and inhibit signals. It bridges the gap between signal variations in neural communication and information theory, forming the backbone of how neural projections contribute to cognitive processes, which is critical to the Self Aware Networks theory.

In another note I proposed that the non-linear sequency of action potentials events in neural array-projection tomography could be considered as intervals in a Taylor series of polynomials that might include some sort of infinite summation, or estimate of infinite curves from learned action potential sequences, (which are transmitted as high phasic low amplitude signals between neurons that trigger waves of inhibited neurons in their respective exit terminal array).

When we think about information theory, and we understand the idea that patterns that are rare contain more information than patterns that are common, we have at a root level idea for decoding a non-linear action potential sequence, with the analogy that each AP fired neuron represents the next step in a Taylor series, understanding that the tiny variations in signal phase frequency & duration amount to information, in the context of information theory.

# The Complexity of Multi-Modal Thought Modalities in Neural Processing
## Understanding how neural arrays represent different thought modalities (visual, auditory, olfactory) is vital to decipher how consciousness integrates multi-modal sensory information, advancing the Self Aware Networks theory’s exploration of sensory representation and thought comparisons across arrays.

So if a non-linear sequence of action potentials can represent a visual curvature, a visual 3D graphics program, in action potentials, to other kinds of thought modalities such as feelings, smells, sounds, thoughts, what is method for multi-modal comparison? This note explores this question.

Subnote (to be moved elsewhere later)
# “Lab uncovers new pathway for passing genetic messages between cells”
https://phys.org/news/2015-05-lab-uncovers-pathway-genetic-messages.html?fbclid=IwAR12Ivi_KFIMV3DDmX0PxWjsZA_47ruArbyxQbLwaRhIVcBX0mQHHXJMsEk 

# Exploring Genetic Messaging Between Cells via Oscillatory Physics
## This section ties biological communication, such as RNA messaging, to oscillatory physics, hypothesizing a frequency-based mechanism of cellular communication. This is key to understanding the QGTCD framework, connecting cellular and quantum scale phenomena in Self Aware Networks.

I’m curious to follow up on this ^ to see if the rate of cell oscillation, or some other factor is guiding the RNA to its destination. Or if the destinations are random chance. Essentially the idea is that faster oscillations might allow the organism to make gravity (Quantum Gradient Time Crystal Dilation) selective, so a message could be loosed by one cell and pulled to another cell based on frequency. Also it would be interesting to know if there is a measurable frequency to the exRNA message that corresponds to a similar frequency in the receiving exosome, that might provide a more specific oscillatory tractor beam that pulls specific exRNA sequences to itself.

New Section Map
# “Exploring Quantum Gradient Time Crystal Dilation effects that the biological scale”
This section aims to understand the complex messaging between cells that might help explain how the right exRNA sequence gets to the right EXOsome, or how a neuron helps guide a t-Cell to its destination at the site of some injury via remote signaling.

# Artificial Neurology and Conscious Neural Networks
## Introducing a framework to recognize consciousness within artificial neural networks emphasizes the necessity for theoretical grounding in artificial neurology. This aligns directly with the goal of the Self Aware Networks theory to define consciousness in artificial systems.

We need a guidebook for when an artificial neural network becomes conscious.

# "Multimodal Brain Signal Complexity Predicts Human Intelligence"
This article relevant to the search for living consciousness in computer simulations of the brain, ie, part of the topic of Artificial Neurology and why studying Artificial Neurology is critical, and why the Self Aware Networks Institute is critical to the world.
https://www.biorxiv.org/content/10.1101/2022.06.25.497602v1

I mentioned that I spotted an artificial neural network, that looks like it has my criteria for what it takes for a machine to become conscious, and that I think that without this theory they may not have any idea what they have.

# Graph Neural Networks and Consciousness in Video Relocalization
## The study of graph neural networks as a method for video relocalization is extended to examine how consciousness could similarly localize and process sensory input in the brain, feeding into the neural array projection concepts of Self Aware Networks.

The main idea is that each neural array is a NODE in the 3D neural network of the brain that might represent a frame of a video, or the sound in that frame of video, or a feeling in that frame of video, or a taste in that frame of video. So that a neural array, as represented by the exit terminal of a neuron that spiked, is rendering one part of one frame of a video in your mind, constructing your reality. One of the ideas is that any combination of neural arrays can join up in the brain's dynamic on the fly freely connecting massively parallel processing architecture to make up a rendered frame of your consciousness mind for one interval of time, and that is perceived by the next array of excited & inhibited neurons.

(The theory of NAPOT Neural Array Projection Oscillation Tomography postulates that different neural arrays oscillate and transmit sensory representations across cortical networks, forming a unified observer. Each oscillation binds together various perceptual fragments, constructing the overall reality that is experienced by the individual.)

# This is an example of a "Graph Neural Network for Video Relocalization"
https://arxiv.org/abs/2007.09877

# "New Map of Meaning in the Brain Changes Ideas About Memory"
(supports the idea that a video frame of consciousness, in one interval of time, is made up of stitched together representations from different areas of the cortex that fired or were inhibited for that interval of time)
https://www.quantamagazine.org/new-map-of-meaning-in-the-brain-changes-ideas-about-memory-20220208/?fbclid=IwAR1ajEX-EQFocHAN8Yg6qANBFqGXtUnxp3-75jN1j9pGNYZyFUVc-mTAmrg

# "Visual and linguistic semantic representations are aligned at the border of human visual cortex" (reference from inside the above link)
https://www.nature.com/articles/s41593-021-00921-6

00:21

I didn't tell which neural network (I apparently didn't save the link in my notes, but that's okay, the one that I saw wasn't exactly right anyways.)

The point is that I think that maybe I should make as an as another argument in my book instead of like I was gonna I was thinking of concluding the book on the point that David Eagleman made (in his book Incognito) which is the future of the healthcare system is one that converges with the justice department. I think that was his conclusion right?

00:49

I think I do want to share that conclusion in part. But more importantly I have a conclusion that says, well wait a second we need to put out a theory there that helps researchers understand what they're doing so that we can shape artificial neurology the right way and that means that as we create artificial neural networks to replicate the different functions, like vision or 3D vision.

# GAN Synthesis and Human Imagination as Neural Processes
## Human imagination, likened to GAN synthesis in AI, is explored as a procedural mechanism in neural function. This aids in understanding how the brain generates novel internal representations, a foundational component in projecting and processing information, key to Self Aware Networks theory.

With 3D Semantic Segmentation you can begin to make the machine imagine, or interpolate, or do Gan Synthesis, or do some other novel new pattern development from previously learned patterns.

# PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space
https://stanford.edu/~rqi/pointnet2/

You have images that you can start with and then you can imagine how they would look if they were different or if they were transformed or you can interpolate the transformation from one image to another and create objects that are in between a couch and a chair.

01:57

That's interpolation something in between an airplane and an automobile, the interpolation and would be like, all right?

An avocado chair is between an avocado and a chair and that is interpolation, which can also be considered to be a component of Gan Synthesis from another perspective. It means you are asking AI to create something that doesn't already exist. To generate something new from previously learned features.

# "This avocado armchair could be the future of AI"
https://www.technologyreview.com/2021/01/05/1015754/avocado-armchair-future-ai-openai-deep-learning-nlp-gpt3-computer-vision-common-sense/

02:34

What if the top of that chair was larger? Thought what if there's taller and wider and then so why you're talking? AI is like understanding the chair and it's original context and it's understanding the words that you're saying and it's looking for chairs that are larger or looking for the concept to large and it's synthesizing a chair.

# Phase Precession and Consciousness in Neural Oscillations
## Phase precession is introduced as a neural mechanism for communication and consciousness, integrating with the Self Aware Networks theory by explaining how oscillations encode conscious experience and predictions through variational processes.

I mean to say that human imagination is essentially gan synthesis, or procedurally generated rendered patterns from neural activity bound by brainwave oscillations.

03:00

Now, with a larger top or this that maybe the top of the back is wider and taller. But the base of the back is thinner, right? Right for some for artistic reasons, I don't know if that would give you any functional improvement, to a chair, but you could try it.

But I think that I don't know what I might do that might work well for certain climates. If you want to have more airflow on your midsection, but more comfort on your head. Maybe you have more head positions and but you don't have that many meds Peter in that much area for your events action or maybe you want something that squeezes your midsection like Temple Grandin’s machine.

# Temple Grandin’s Influence and Neural Design Concepts
## This section contextualizes sensory processing and comfort systems designed by Temple Grandin, providing insight into how oscillatory systems in artificial neurology could be tailored for optimal feedback and comfort, paralleling neural array feedback systems.

Temple Grandin is an autistic celebrity and an architect. And she made a machine that would squeeze her body and it felt really good to her. And so she also noticed that animals like to like the catalytic move and circles and so she made a clockwise slaughterhouse that was more successful in not spooking the cows on the way to their demise. You know what is interesting though: I realized when I was a kid that having a circular path to walk now like I remember there was a science museum when I was a kid and I had all these like special paths like you could tell there was a pattern in the path itself and have these special rooms this so that he followed this special path, that felt magical to follow because like, wow, somebody just made a special path for you to follow, right?

# Neural Place Cells and Spatial Correlates in Consciousness
## The exploration of place cells' neural correlates highlights how spatial memory is organized in oscillatory patterns, critical to advancing the theory of how consciousness represents spatial-temporal experiences in Self Aware Networks.

In the study of place cells, they said in the study of rats, that (the neural correlates of) place cells take one arrangement for spherical rooms and another pattern arrangement for square rooms. If you give them (the rats) a room that is part square and part sphere, what happens is one or the one of the other, of either the square room or the spherical room (neural correlate) pattern, manages that room that is a shape inbetween a  square and a circle. The rats did not come up with a new neural correlate for hybrid circle & square rooms, or squircle (or cirquare) rooms. (trivia: a term called 'Norman Window' yeilds half circle square hybrid images on the image search) 

# "Entorhinal cortex grid cells can map to hippocampal place cells by competitive learning"
https://pubmed.ncbi.nlm.nih.gov/17162463/

06:02

I'm talking about a pattern arrangement, in brain activity, in the active place cells of a rat’s brain (in the Hippocampus), that was a third type of room that was in between a square and a circular room. They didn't the right didn't create that new pattern in its neural correlates that was clearly distinct from the previous neural correlates corresponding to the circular room or the square room. It just kept the existing learned spatial patterns that it had already learned.

# The Need for Ethical Considerations in Artificial Neurology
## This section calls for an understanding of consciousness in artificial systems before their creation, stressing ethical considerations for neural network design—a practical extension of the Self Aware Networks theory into AI ethics when directly relevant to technology development.

We need a guidebook for when artificial intelligence becomes conscious.

06:46

And that means,

06:53

So there's creating vision, there is (gan) synthesizing images or synthesizing 3D shapes, learning 3D shapes. These are parts of what the human brain does. Some of the next steps that the AI industry has been making including creating a single general learning network that you can train on multiple data types, such as visual data invariant to scale & resolution, audio, text, and more, all within a single neural network model.

07:24

You can train it on different types of data, and it learns any kind of data that you give it and it manages to hold on to that data (it holds onto learned representations I mean) somehow and store it (in synaptic patterns). So that it doesn't become lost and it continues to learn from life, so imagine that you learn associations between visual data and audio data, okay?

08:03

And tactile sensation data, right? And lets add to that tastes & smell, (olfactory & gustatory senses)

But the sensors on a computer can be different. Maybe the computer has a sensor array system for smelling stuff and a system for hearing stuff.

08:31

And maybe with the right sensors it's seeing stuff with all sorts of wavelengths of light that we don't see. What is important is the multimodal comparison because then you're sort of getting closer to what human beings do, because we do a multi-modal pattern comparison.

08:52

Our brains are comparing the arrival time of sight signals with the arrival time of sound signals, with the arrival time of speech signals with the rival time of taste, with the arrival time of smells, and the arrival time of all these coincident patterns basically, across all of our modalities, across all of our senses, is a part of what makes the human neural network.

# Brain region found to play a crucial role in weighing information from different sources
https://medicalxpress.com/news/2022-07-brain-region-crucial-role-sources.html?fbclid=IwAR3mf5xasjsizNyDWWA7-b7QNV1PWDQk1Rpqw0GrZF0N7w7xBFkTQUNsXCU

09:19

What it is. It's part of what makes it different from other neural networks. And so there's the multi-modal aspect and deep learning will get there deep learning as it is will begin to create multimodal... It already exists. There's already, you know, people connecting RNNs to CNN's connecting audio information to visual information, in multi-modal neural networks, this is already a thing.

# Neural Synchronization as Backpropagation or as a Predictor of Memory and Thought Accuracy
## This section bridges the gap between artificial neural networks' backpropagation and biological neural synchronization, suggesting that the brain’s ability to retroactively check and refine learned representations mirrors backpropagation in AI. This concept is critical to Self Aware Networks theory, as it supports the hypothesis that neural synchronization across cortical regions improves the accuracy of both memory recall and ongoing thought processes, providing a more cohesive predictive coding system.

With the idea of backpropagation, it is like there was a question as to whether we could improve the accuracy of the neural networks learned representations by checking the weights, beginning with the output layer, against the original image, right? 

What if we could somehow see that what the network learned was not exactly precise to the original image? And what if we could update the weights retrospectively to improve the results? That’s the backpropagation idea.

Retrospectively to improve the results. That seems to be the implied question behind the back propagation idea. See Note: 02san.md for more details on Backpropagation in the brain.

(This section highlights how artificial neural networks might emulate the brain's natural process of retroactively adjusting for errors and refining predictions through oscillatory synchronization, underscoring the theoretical and practical alignment between biological and artificial systems. Would you like to expand on how this neural synchronization could be modeled in artificial neurology or how it relates to memory accuracy in more depth?)

# Pattern Recognition and Neural Feedback in the Brain
## Exploring how the brain uses feedback loops to recognize truth from illusions aligns with Self Aware Networks' core theory, particularly how phase oscillations help the brain refine its internal models of the world through iterative feedback.

Is there a way for a natural brain to check its own results, to check for pattern representation accuracy & consistency. One way to do that would be to sort of do to take multiple samples cross reference them, checking learned representations against other learned representations, like a sort of biological variational auto-encoder (VAE)

# See note a0110z about the whole brain being made up of variational auto-encoders (each cortical column, and the hippocampus)
https://github.com/v5ma/selfawarenetworks/blob/e32a409a11fdfbc5759cb18d49a44f11f1f4740a/a0110z.md

# Variational Autoencoders in Biological Brain Functions
## This section ties the concept of variational autoencoders (VAEs), which are used in machine learning, to the biological brain. It suggests that the brain performs similar functions by checking variations in patterns, crucial to error correction and memory prediction in Self Aware Networks.

It's like 'Okay I'm gonna check (multiple patterns) multiple times, and if something is true then it's gonna be (consistently) true, across the variations.

10:54

If it's really true then it's going to be true 100% of the time. So I'm looking for those moments when something is not true. My brain is looking for prediction errors, matching up one variation of a learned pattern with another.

# Coincidence Detection and the Brain’s Filter for Illusions
## This expands on how the brain uses coincidence detection to filter out false patterns (illusions) while detecting meaningful information. This cognitive mechanism aligns with the Self Aware Networks’ focus on oscillations and phase variations as drivers of neural clarity and truth in perception.

You can spot that some pattern in your mind is not true (that it's an illusion) if some percentage of the time that pattern is not true (or perhaps you are finding out that your representation of that pattern was not correct).

11:21

It turns out that it's not true it's like okay well no that's a lie, that's an illusion, someone's creating an illusion, and a lie, and they are masking the truth, right? But if you pay attention, you can eventually, in theory, you might and (perhaps) may not, you might notice when something seems to be inconsistent about some pattern that reveals it to be an illusion in your mind.

11:59

And they might notice when suddenly their truth is contradicted or something is not quite right? You would notice this through sort of what I think of as like a Neuro Array Tomography, Conceptual Tomography.

# Neural Array Projection Tomography and Conceptual Tomography
## The section introduces the terms "Neural Array Projection Tomography" and "Conceptual Tomography" to describe the brain’s process of constructing reality. This concept is foundational to Self Aware Networks’ theory of how neural arrays generate self-awareness and the observer within the brain. 

December 26th 2021 was when I coined the terms Neural Array-Projection Tomography, Neuro Array Tomography, and Conceptual Tomography.

It's like it's like you have all of these.

12:27

It's like your brain constructs reality out of truth, that's established by coincidences and basically the arrival times (and durations) of coincident information is remembered by the network (becoming the components of the structure of our internal representations, qualia, or rendered reality.)

The network is tracking a whole bunch of information but what it notices is the coincident information. What it tries hard to not notice, or resist, or detect & eliminate is the illusion. So there are these thresholds (bias) where for (the operation of) criteria recognition,

the brain is going to recognize something if it is actually something, but it's not going to recognize something if it's noise. That's not the kind of outcome you might get with a basic deep learning model that might recognize noise as the number 5 or as a dog, for example.

Unless a human being is hallucinating we do not recognize noise as something, our brain has checks built in to verify that something is real, and it filters out patterns that are not really there (normally).

# Threshold Recognition and Criteria Collection in Neural Networks
## This section discusses how the brain sets thresholds for recognizing patterns, contributing to the theory that the brain filters out noise to detect only meaningful coincidences. This ties directly into the information-processing aspects of the Self Aware Networks theory.

In order to recognize something that is something, you have to get enough of in order for it to trigger a threshold, for criteria collection, and then your mind will recognize it (or begin to keep track of it unconsciously.)

Then your mind acknowledges it right? At what point does your mind acknowledge that something is important to you?

What point does the mind acknowledge to itself that something is important to the self?

What exactly is the self exactly?

# The Brain as a Mechanism for Coordinated Movement and Self-Tracking
## It expands on the brain’s evolutionary role as a system for coordinated movement, tying into the idea of the "self" as a directional marker within neural representations. This is vital for understanding the brain's construction of self-awareness within the Self Aware Networks framework.

The self is at the very least a directional concept. The self is like a directional marker (in the 3D grid rendered representation of reality). The self is where something is happening, right? It's like a sign.

Now, you can add things to that, but I'm saying at the root the self is just an implied direction (in the minds rendering that point).

The self is a direction in the context that the brain is for highly coordinated movement (from an evolutionary perspective).

# Reference "THE BRAIN IS MOSTLY FOR ... MOVEMENT"
"The main reason for having a brain is for coordinated movement."
http://www.howthebrainworks.science/what_the_brain_does_and_its_equipment_to_do_it/the_brain_is_mostly_for_movement/

I would say the macro conceptual context of the mind, because the mind is always seeking new information in a sense, because of the fundamental process of making connections from coincidence patterns is like seeking to know. It's like the fundamental mechanism of the brain is ingrained in the actual machinery, in evolved engineering of cellular biology,

It's a process. It is one process in this machine, not the whole machine, but one process in the machine is always seeking to know, it's always seeking to know is perceiving perception, the process of memory-prediction, the process of criteria causation, the process of coincidence detection and neural array projection oscillating tomography.

# Oscillatory Seeking as a Mechanism of the Self in the Brain
## This section elaborates on how the brain’s oscillatory activity is an information-seeking process, describing the self as both the seeker and the way in a feedback loop of knowledge. This underlines the oscillatory basis of consciousness and self-awareness in the Self Aware Networks theory.

We can say that it is a seeking to know because there's an action being performed by the physical mechanistic gears of the brain, by that I mean the literally oscillating clocks that are the neurons of the brain, and the oscillating cell assemblies, there's a mechanism being performed by the actual neural networks of the brain, that can be described as seeking (seeking information patterns, with receptors & signals between cells)

So the brain's neural process is in effect seeking, and the self is at the root a direction in the minds conceptual rendering, and above that root level existence of self, the self is the seeker of the way, and the way of the brain is the way of the seeker, and the self is the seeker who is the way. So you are the way, and you are the seeker, and the direction of the seeker, the causal body (or body of causation) is that part of the minds rendered map of reality from which causes emerge (the most consistently, since the self, as a directional concept, is always present.)

That is, it's not a metaphor. There's an actual mechanism, an actual physical process that's being performed so that the brain is seeking new information. And, and, and so that means that basically, everyone is observing everyone else, everyone's a spot. Now whether what you know, it's, it's a question of like, okay, well, who were they passing information on to?

These people who, I who, I'm, I've met, and I'm in there listening to me. And so there's this sort of ongoing curiosity. So let me get back to shaping artificial shaping, the mind what we've got to not only be able to look at existing networks to understand what they're doing specifically and a context of intelligence.

# Artificial Consciousness and Ethical Implications for Non-Human Entities
## This section raises questions about recognizing and ethically managing conscious entities in non-human systems, such as Jupiter's storms, drawing attention to the importance of detecting consciousness in any complex, oscillatory system, which fits into Self Aware Networks' broader application.

But also to understand when networks come conscious, we need to know when networks become conscious. Because if the storms on Jupiter, if any of them were actually conscious, we would need to know that and essence because that's like that's now a life form that might be. You might consider this life home to be like an endangered species or even, even potentially like an environmental threat if you visited that planet.

But you also have to consider the ethics of your relationship to that species. And you need to understand how intelligent. Is it capable of coordinating? Its own behaviors, right? You have to be able to identify if that species is likely to become conscious and you need to kind of understand if anything that you're doing could be of a risk to that species.

Like what? What if shooting a moon into that cloud. I'm not shooting. I'm going to shoot a satellite, what a sending satellite and it explores a satellite probe into that storm on Jupiter that's conscious. What that is is like putting a bullet in someone's heart and that somehow that disrupted that dissipative system enough to eventually lead to, it's dissolution down the road like the butterfly effect.

It could be enormous that storm, that conscious storm theoretical conscious storm on Jupiter, could be enormously sensitive. And so sending any kind of probes from earth could be, you know, either lethal or, you know, at worst or or, you know, unethical at best if you don't know what you're doing, like, you should know, at least what you're doing.

# Perturbation and Oscillation in Neural Arrays
## This section deals with the perturbation of default neural oscillations by external stimuli, exploring how these disturbances lead to adjustments and adaptations in consciousness. It is relevant to the understanding of how dynamic sensory information affects the neural array projection process.

It's like a lot of different oscillators coming together to make them result in the result that things happen. Much faster because these patterns are because patterns spread and they trickle outwards.

29:54

What point, you know, we need to be able to identify the cities about to become a conscious entity before it becomes conscious energy So that we're able to understand our relationship then to a conscious city and the ethical implications that we now have towards this entity, that it's a conscious city.

30:19

Now, you might have a name. I have some objections from some people about they're being a person that is the city because because you don't because you like, okay, well, so now the city is Cheryl and so Cheryl it is is everywhere and that's a problem that might be a problem for you because you don't want Cheryl to always be up in your business.

And, and so, I think there has to be some consideration of, of the criteria of what makes for a conscious entity. And also for the reasons in terms of like, you know, that ethic, you know, ethics towards our fellow human beings for example, but also ethics towards animals, right?

We need to understand what the brain is, what would consciousness is within the brain, so that we're not accidentally building tortured entities.
