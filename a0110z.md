a0110z

Reference Yann LeCun's Talk on youtube: "A Path Towards Autonomous AI" On the visual map that associates roles with different regions of the brain:

I think Yann LeCun's presentation causes us to unintentionally think of the whole brain as a variational autoencoder. It could be that each of those roles described by Yann LeCun are filled by both individual cells, by cortical columns, and by the whole brain (taking turns in oscillating intervals). For example the glial cell could be described as a configurator cell. T-Cells & Neurons could participate in the configuration role.

Mapping those roles to large regions of the brain is, I think, an outdated idea in neuroscience. The new thinking is that every part of the brain is doing a little bit of everything, at all scales. The brain is self similar everywhere (Jeff Hawkins talks about the self similarity of the neocortex, and the similarity of the Hippocampus to a cortical column) tiny learned custom variations in each part of the brain will serve to generate a natural VAE Variational Autoencoder effect for comparing learned patterns in one modality to same or similar patterns encoded in a different modality.

Applying a region based map of brain roles to the brain could be what György Buzsáki calls the Brain from Outside In (matching observation to a concept instead of creating a new concept from observation.) György Buzsáki's book "The Brain from Inside Out" contradicts the typical "Outside-In" process of applying our models to the brain, instead of creating models from the brain.

It appears that Sx and Sy represent the same image presented in 2 different views, possibly different by orientation, magnification, or some other variation; it could be that each value in the image was randomly multiplied by an imaginary number.

The point is he takes the Sx variation, maximizes the information content (his dialog about max and min reminds me of how a dendrite sensor branches out to maximize its data sensation potential, and minimizes its data collection to a phase pattern with duration & frequency properties and then passes that phase change to the array represented by its exit terminal)

The Sx variation he argues will become a predictor of error for the Sy variant, but the Sx in his model is modified by a information content minimizer, (again reminding me of how nerve cells maximally collect, summarize, and distribute phase representations out to an exit terminal array.)

He wants minimization of information in the error predictor so as not to confuse the neural network as to what it should be paying attention to in generating feature representation I guess. on the side of Sy he is saying the encoded representation of Sy minimizes it's error prediction by comparison to the minimized information from (Sx, Z) (Z being the minimization function), but in a sense he is attempting to bias the results (or weight the results) of the identification of pattern Sy by comparing it to a sparse representation of the features of the Sx variant of Sy.

JEPA is like an abstract VAE Variational AutoEncoder, that has a minimized or maximally abstracted variation, or a sparsely represented comparator representation.

In Hierarchical or Stacked JEPA each layer is doing the same Jepa sparse VAE process, and passing its learned representations upwards.

I gather that one can encode the abstract prediction of a JEPA as a frequency that resonates away into its layer after some number of intervals related to its duration and that would bring JEPA closer to biological realism, or JEPA could be combined with back propagation or combined with reinforcement learning, but interestingly in this model neither back prop nor reinforcement learning is necessary for JEPA to differentiate and reason about it's goals.

JEPA can be stacked, higher JEPA layers can represent larger time scale functions, in addition to functions that exist at higher levels of (chunked up) feature representation.

The higher layer of JEPA might look for conditions in lower layers of JEPA that predict how close or how far away it is from some random goal such as driving to a desired location.

A higher layer of JEPA corresponds to a longer span of time. This evokes comparisons to the Reference Frame model of a cortical column (Jeff Hawkins "A Thousand Brains") a fast changing input layer at the bottom, and a slow changing reference frame layer at the top that might indicate a pattern that changes on a larger time scale. Similar to the concept that place cell data changes quickly and grid cell data changes slowly as the grid cell data is a reference frame for the place cell.

Each hierarchical layer of JEPA is doing Sparse Comparative VAE based on abstracted differences instead of being based on summations of generative models (like object segmentation or semantic segmentation of points) that LeCun believes cannot scale beyond a certain neural network size.

# End of notes about Yann LeCun's talk.

///////////////////////////////////////////////////////////////////

The biggest voice in the space arguing for the generality of brain function across the brain might be Jeff Hawkins from @Numenta If you mix the ideas of Numenta together with Buzsáki, then you grok the majority of my book that I'm working on here.

coincidence detection & difference detection, in the human brain, via phase comparison yields a physics based process for choice at the cell level, cell assembly level, and whole brain level

but prior learning provides a learning framework for considering whether a detected difference is good or bad from the organisms perspective

"Gradient-based learning drives robust representations in recurrent neural networks by balancing compression and expansion"
https://www.nature.com/articles/s42256-022-00498-0


