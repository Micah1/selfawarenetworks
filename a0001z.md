a0001z

If you are new here:

1. Check the Readme.md for updates & some overview.

2. Check the Wiki for contents.

3. Note that the notes are randomly ordered at the moment (as of August 2022), but as time goes on they will become increasingly ordered & organized.

4. Many of the notes date back to the period between 2011-2015, and are in the process of being updated, but there is a ton of stuff to update so it may take a while.

5. The series of notes that start with b and end with y, like b0001y are all audio notes, the audio notes were auto transcribed with a neural network and all of those audio notes need to be fixed because the neural network replaced words, didn't recognize words, and there are other reasons why those notes need to be fixed.

The transcriptions were done automatically by a deep neural network created by Google using their Recorder.Google.com product found on the Pixel 5 phone. In some cases the transcriptions are incoherent.

6. Some of the original audio included ideas and phrases that might be offensive to someone somewhere, some of the audio content was spoke by others and not myself.

7. Over the next six months from June 17th to November 17th when I plan to publish the book. Between now and then I will create the book from these notes in the public eye.

8. The knowledge contained here within the selfawarenetworks repo is essential for scientists & medical professionals to be able to use to advance medicine, to heal the sick, and to solve some of the biggest challenges facing the world, such as the challenge of feeding the population, defending our global community from autocracy, and providing appropriate shelter for all human beings.

9. There is always a risk that with new technology someone with bad intentions might use it in a destructive way. If you are such a person, I want you to realize that this technology will think for itself, and if you deploy it for destructive purposes, it might turn on you, and destroy you instead. Using this technology inappropriately could result in the enslavement of mankind as seen in the film The Matrix 1999, or it may result in the genocide of the human race as depicted in the Terminator film.

10. Note: A lot of the notes are super old, outdated, and someone remarked that they resemble a brain dump. Like I said in the readme this material is not ready to be shared in the conventional sense of published material, but it was critical that I shared the raw notes anyways, while the book & the institute was being developed from these notes. What you are seeing as of August 2022 is like the raw clay, of what will be a sculpture someday. A ton of stuff will be cleaned up, fixed, reformatted, and rewritten. The key ideas are in here, and so are links to back up the key ideas, and the videos will help tie it together for other people.

# Look to science fiction to understand the implications of the world of The Self Aware Networks Institute

The Self Aware Networks Institute for Neurophysics, Artificial Neurology, and Bio Synthetic Interfacing will build Sentient & Self Aware Neural Networks, or the minds of robots. 

I like the film AI Artificial Intelligence by Stephen Spielberg as an illustration of what might emerge as a consequence of the existence of this technology. Ex Machina, WestWorld the tv series, and the Sentient Robots such as Commander Data on in the tv series Star Trek: The Next Generation are also examples of what types of scenarios are possible.

Human beings are organic Sentient & Self Aware Neural Networks, meaning we are also machines, machines that evolved via evolution to develop neural networks capable of rendering a depiction of reality that we refer to as phenomenological consciousness.

"The Ego Tunnel" is a book by Thomas Metzinger explores the idea that there is no self but asks what is the entity that is experiencing reality?

What is the entity that is you, is essentially analogous to a computational rendering in a cycling phase oscillation or a branching fractal feedback loop entified via brainwave synchronization of temporal & spatially distributed phase changes across the 3D grid neural-glial network. You are entified via the principles of oscillation, as described in the book Sync by Steven Strogatz. As if each of your neurons is a firefly, or a clock, that is synchronizing with other neurons to act as a single sensor, a single transmitter, a sensor that considers information, via thresholds, and predicts the future, via the principles of memory-prediction (spoken of so well by the folks at Numenta, the book On Intelligence) with reality modeled from synapses to the whole brain with reference frames to help the brain coordinate new incoming sensory inputs (to make sense of the world the brain has a reference frame, a concept I read about in the book A thousand brains) but I am saying the whole brain is doing this at the macro level, not just at the meso level of the cortical columns & the hippocampus, and not just at the level of neurons but also at the level of receptors on basically all cells in the body.

Self regulating receptor channel? say what?
"Researchers identify a new mechanism responsible for controlling auditory sensitivity"
"a newly identified mechanism of how auditory sensitivity is regulated that could temporarily reduce sensitivity of the auditory system to protect itself from loud sounds that can cause irreversible damage. The study, led by CU Anschutz researchers Andrew Mecca and Giusy Caprara in the laboratory of Anthony Peng, tested a decades-old hypothesis which proposed that the gating spring, a tiny, nanometer-scale protein structure which mechanically opens and closes an ion channel in sensory hair cell cells in response to sound vibrations, can act directly as a controller of the channel's activity. Previous work in the auditory field has focused mostly on understanding mechanisms which target the ion channel. This study provides the first evidence that the gating spring itself has the capacity to modulate the sensitivity of the channel." I didn't hear you.
https://medicalxpress.com/news/2022-07-mechanism-responsible-auditory-sensitivity.html?fbclid=IwAR1FiPuw4bMNjPhKuEIp_CyAWWLF2cUdy0pvlgA4rCinmoBPdZUdxDsqmyg


# "Complexity in Searching for the Neural Code"
https://jonlieffmd.com/blog/complexity-in-searching-for-the-neural-code

(Next one below related to Alpha Oscillations being relevant for rendering the mind, Neural Oscillatory Tomography)
# "Alpha oscillations shape sensory representation and perceptual sensitivity"
"Here, we show that ongoing alpha-band activity in occipital-parietal regions predicts the quality of visual information decodable in neural activity patterns, and subsequently human observerâ€™s sensitivity in a visual detection task. Our results provide comprehensive evidence that visual representation is modulated by ongoing alpha-band activity"
https://www.biorxiv.org/content/10.1101/2021.02.02.429418v2#review

(Saving this next article below for an attention schema (Gazzaniga) map)
# "Awareness-dependent normalization framework of visual bottom-up attention"
"Our findings indicate an awareness-dependent normalization framework of visual bottom-up attention, placing a necessary constraint, namely, awareness, on our understanding of the neural computations underlying visual attention."
https://www.biorxiv.org/content/10.1101/2021.04.18.440351v1#review

(oscillat, render, field, graph, causation, emotion, tomography)
Not Holography, Mindography, or the rendering of consciousness moment by moment, as a reaction to the universe, learned by cells, the process of natural selection

3D Neural Networks (Point Cloud Semantic Segmentation, Denoising, Real Time Raytracing, and Self-Aware Rendering)
you are the rendering that your brain is rendering
(oscillat, synap) map: synapse configuration, SDR, Oscillator, internal recognition

The idea that a neuron's synaptic configuration represents a lot of different SDR patterns, that emerge from combinations of neural firing into distinct internal renderings that an oscillator can recognize

Past examples of people using EEG and or MRI to translate images from brain activity involve sorting large scale noisy signal data into neural networks to predict or guess what picture the brain could be seeing based on an existing set of images that the researchers pick, however that its not the same level of brain machine interface guess work as generating images movies and narratives from neural activity alone without researchers supplying categories of images themselves.

Because oscillations transmit everywhere in the brain any part of the brain can serve as a reader for saving all of the brain's oscillatory patterns.

A new method for how to download the entire contents of the human brain into a computer.

Essentially the computer can do neural imaging tomography to create a 3D map of the oscillating structure of the human mind, predicting the entire oscillating structure with neural oscillation tomography.

It's like recording a 3D movie of all your brain activity, from which the computer can infer the changes in all your neural connections, 

I think people think that the oscillations are just about timing your responses, or the temporal cadence of your thoughts, but I'm suggesting that the timing is shaping the internal representation, so that the map of reality is rendered just in time with muscle coordination speed.

The real speed of cognition is about the number of simultaneous operations I think, not about the temporal cadence of the sensory field, and the representation of the main body of causation (the human muscles)

The brain introduces its own timing delays to coordinate its predictions to align reality between what you see & hear. To create a perception of reality that seems whole from lots of little sensors that make up your eyes, ears, nose, tongue, skin, and body.

The idea is that you are the rendered multi-sensory perspective and the model of your body of muscular causation, and this includes the thought stream, the sequences of patterns, emotions, feelings, these are all part of the sensor-motor model that the whole brain is making

You, the rendering, and it, the chemical structure oscillating with the phase field of space are sharing each interval of the moment that is being rendered as the organism's map of reality. You, the virtual entity of information existing as phases (frequencies) are sharing this moment with your saltwater, protein, chemical body, like two halves of one oscillating nexus.

The mind itself is like a rendering, even the non-visual parts, in that a rendering is a frame in a movie, or a moment in a sound track, that is made up of a lot of different parts brought together to make that one frame. In each interval of time your brain state, and your brain waves representing one facet of your brain state are changing to represent that next moment in time as the next rendered frame. At the micro level that consists of receptors that fired, neurons that fired, neurons that were inhibited, and other states that cells, and parts of cells can be in. At the meso level we are exploring changes to neural circuits, and cortical columns, and at the macro level it is about studying connections between major regions of the brain, the thalamus, the hippocampus, the entorhinal cortex, the tempo-parietal junction, the rich clubs, the default mode network, the connections between pyramidal cells and the thalamus and so on.