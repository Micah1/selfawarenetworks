Neural Lace Podcast 2 

Apr 13, 2017

Original Audio here: https://youtu.be/UpOzHjKGa0g

Audio Transcription by OpenAI's Whisper

So, welcome to the NeuroLace podcast.

I'm here with Blaise Sanders, right?

Correct, yep.

He's the CTO of SpaceVR.

I understand SpaceVR is a company that makes satellites.

Yeah.

Which is like a super cool thing to do.

My grandpa made satellites.

He made the first GPS satellite.

He actually, sorry, he led the team that designed the specifications for the first one.

So, I very much admire companies that make satellites.

It's a really cool thing.

SpaceVR is a dream to allow all of us to go up and see what it's like to be in space via virtual reality.

In a real way.

There's a lot of CGI space experiences out there,

but we're going to capture a full 20k resolution imagery of the space station as we fall away from it,

and just the beautiful Earth.

Wow.

So, the goal is to give every person on Earth the overview effect.

Would it be possible at some point to put the 20k camera on the rocket itself as it's going up into space?

I can.

I guess the biggest problem there would be like the aerodynamics.

Like where do you place the camera?

We did talk to Blue Origin about strapping it on the outside of the new Shepherd,

but couldn't quite figure out how to do it and not have it like break off.

Oh, yeah.

And aerodynamics at the velocity are pretty rough.

We had some really cool renders of like aerodynamic shields for the cameras, but never quite worked out.

It would be cool though.

And then, so recently I was at NVIDIA event and I ran into your friend Ryan,

who also works at SpaceVR, and he had just been awarded an NVIDIA processor for robots.

TX2, is there twice the AIs, what they say?

Yeah.

And so now you guys are really excited, or maybe happened for, since before that probably,

about building a robot for telepathy on the satellite.

Exactly.

It's a full humanoid robot about one and a half meters tall and is controlled by a VR suit, remote control.

Wow.

So how is that, what are the practical applications of that, like what would you be doing if you had to, like, hands?

I mean, you could repair the satellite, I imagine.

Yep, that's one of the use cases.

It's a little farther down the line because satellite companies need to figure out how to repair satellites.

So we're going for some Earth-based use cases in the labor market that we think we can solve.

Okay, so this is like, this is something NASA did where they started coming up with a, NASA is not just a space company,

they also have a bunch of, you know, Earth-based projects, underwater projects.

So that kind of makes sense.

You want to put everything in space, but there's a lot of verticals where you can take what you're working on for SpaceVR

and then apply them to the Earth in very valuable ways.

Exactly.

NASA has the Robonaut 2 right on the space station now, so we're going to use some of their tech for the space.

But right now we're focused on ground-based robotics and the neural lace has an important part to play in that.

Wonderful.

So let's talk about connecting neural lace to SpaceVR or neural lace to telepressants.

What are some of the, I mean, what that would mean is you have a robot that responds to your nervous system

to how your hands actually move and what your hands touch and you feel it.

So you have a true sense of presence, remote presence, as if you're actually there,

but then you'd have a different body if you'd have to get used to that.

It'd be amazing.

Right now there's a lot of gloves that you can wear for VR that give you a little bit of haptic feeling

and there's other input methods that let you move your arms around.

But with the neural lace you could think about doing something or if you were making a video game,

think about turning on your shields and they would turn on.

So in the previous podcast I laid out what I think are the two steps we need to achieve in our lace.

I'll just recap this real quick.

So one of them is we need to take a computer that's this computer vision that, you know, like the self-driving clock

or like mixed reality concept where the computer is learning the concepts of everything around it.

It says this is a cup and this is a car and this is a person and the car is moving really fast.

The car needs to know if there's not a space in front of it.

So it's categorizing objects around it and we need to apply that to neuroscience

so that we can have this neural network that's doing computer vision.

That's part A and then part B is you need to have another neural network applied to live medical imaging

and then you need a live medical imaging.

It could be a chip that's implanted in your, close to your mid-brain and it's for several chips

and we just want to focus on that.

It's medical imaging even if you do it with another type of medical imaging.

That's part B because now you have a neural network dedicated to what's going on inside your brain.

And then you have a third neural network that's at the apex of the two of my side.

So above A and B which is computer vision of objects and neural networks of brain life data.

You have a third neural network that is looking for the similarities between the world that you're seeing

and the activity of the brain.

So that means that if you're seeing a car and the computer vision is seeing the car

and the computer vision is seeing the neural cortex of your brain activity while you're seeing the car

and then the third neural network is going to figure out what that pattern is

and that pattern in terms, not just in terms of, you know, I mean really for neural life

we really have to go beyond EEG and beyond the fusion tensor imaging of MRI.

It's about, it is about getting chips to focus on the data in the mid-brain

and the reason for that is because all of our incoming senses, you know from our eyes or ears

they collide at the mid-brain first before they connect with the rest of the cortex.

So that's like the point when our senses converge in the center of the brain.

I'm making these like hand gestures which you can't see on the radio but yeah,

so just imagine that I have hand gesture for your eyes and hand gesture for your ears

and then I move my hands together and where they come together is like at the thalamus

or somewhere in the mid-brain and then they connect with the rest of the cortex

which is, you know, for the eyes they're going to go to the occipital lobes and the prideal lobes

and then you've got a whole bunch of information coming back at the same time back towards the thalamus

which is, anyway, so the point is if we, so the idea is if you tried to study from EEG

which is on top of your head, at that point everything is scattered.

It's all over the place. I mean you have, there are maps of the brain that have been done

in places like Berkeley where they say, you know, you're a concept of a cat and a dog

has neuro correlates over in this region of the brain which I'm doing another hand gesture.

So it's like I'm pointing to one part of my head and then you have another concept of a house and a motorcycle

which is going to be in a different region of the head completely.

It's all scattered and distributed, sparse and distributed representations

and somehow when you're perceiving them they come together like you can perceive a dog at a house

in one picture, in one photo and that's like different parts of your brain sort of like lighting up

and then coming together and maybe they're coming together back, you know, maybe that's the back propagation

when it comes back together to the center of your brain, to the midbrain, to the thalamus

where your senses are coming in, maybe that information is coming together there.

When it's in the neocortex it's all over the place.

So the place we want to put our sensors is in the midbrain and if we do that then hopefully we can capture

a photo when it's coming together before it scatters across the neocortex or the sensor image

and the sensor image that we want to capture is electromagnetic.

Brainwaves, we'll see there's neurons that have electrical synapses and neurons that have chemical synapses

but they're all generating a lot of brain activity and the cells of the neurons have,

the cell body has all this metal that has calcium ions, positive ions outside the cell body

and it has potassium ions, negative ions on the inside of the cell body

and those, you know, the classic example in any neuroscience or computational neuroscience textbook

is these charges are separating through the activity and then what happens is they separate enough,

the cell has to depolarize this separation between positive and negative charges.

It's the same principle of lightning.

The positive and negative charges separate in the sky and all of a sudden you have lightning bolts

and in the brain you have an action potential but unlike the sky there's a path of least resistance

that is the axon body itself, the middle of the cell body.

And unlike, you know, the standard neuroscience or computational neuroscience textbook

the action potential doesn't travel directly between two neurons.

It's not, it's actually, it goes along the body of the cell and you can see this in the illustration

but then it goes to the axon terminal or the post-synapse and inside the post-synapse

the synapse is so complex, it's like a little micro-computer

and so we used to say in computational neuroscience that you have to summarize whatever goes along the axon terminal

and you can't look into like a 1 or a 0.

But now scientists have woken up to the idea that wait a second, what's being sent is a lot more complex than that

because you can't just summarize it as a 1 or a 0.

It has a wave, it has an amplitude, it has, you know, it has the charges count

that there's information in the voltage in terms of like its difference between like it could be,

that's greater amplitude, that's information, right?

And then so that is sent across the, it's sent to the axon terminal

and then if it's a chemical synapse, I mean if it's an electric synapse it does transfer immediately to the next neuron

but if it's a chemical synapse what happens is it triggers a bunch of neurotransmitters, ions to pass through

but what's really changing is, see all the neurotransmitters have charges

like charges in terms of like atomic charges, positive and negative charges

and this synapse is like a computer and it's, and the dendrite itself, so is, here's the real question, okay?

So this is like one of those things, because I study like the dynamics of neural circuits, for example.

The real question is if you have, see a neuron now sending its neurotransmitters to the next neuron

but there are a finite number of neurotransmitters

and each neuron is connected to somewhere between 10,000 and 200,000 other neurons.

So when you see a neural circuit in the brain, which means the same group of neurons light up in a sequence

but it's also a feedback loop, like it's a repeating sequence,

how is it that sequence ever repeats more than once?

And the weird thing is that the neurons in a feedback loop are not necessarily directly connected

so you'll see a neuron that lights up, let's say we call that point A

and then there's darkness for several connections

and then a neuron somewhere further down lights up in terms of the brain neuroimaging

and then, and then, so I'm making another illustration with my hands

so then bear with me audio listener.

So then there's a third point, now imagine a circle and there's six points around the circle

and each of those six points is a neuron that's lighting up

and they're not necessarily directly connected

but they keep lighting up in that same circle over and over again

and that's what we call the neural circuit.

But why would that ever happen? And so there's a lot of different network theories about why that might happen

but the most obvious possible solution to that is it's fundamentally about electromagnetism

and it could be that the dendrite, which is the receiving terminal of the synapse

it could be that the dendrite is, dendrites are, you know, like more than 80% of the brain

I mean they've just taken up a lot of space and they're really complex

and they're like, it's like a tree but it has like a tree with all these like notches

or these hairs on the axon fibers

and so the dendrite could be doing a lot of interesting computations

and we'll really analyze this. The dendrite itself could be like a sort of mini-computer or a micro-trip.

It's very fascinating and so, but the dendrite

does that whole feedback loop a discrete step then in some sense

or is it still analog in that feedback loop as well?

It could be a discrete step.

Each part of it could be a discrete step where the dendrite itself

could be like, so imagine you have a bunch of dendrites that are competing

like 10,000 or 100,000 dendrites that are competing for the signal that's coming from the neuron

that's in all the text books, right?

Well, it could be that the dendrite that receives it is the one that has the most negative charge in summary

and all the other ones have a slightly more positive charge

so it's creating a situation where you have like the lightning strike

where you have a separation of positive and negative charges

so the dendrite on the past, the post terminal is receiving

is actually setting up to, it's like saying,

okay, I need to receive the next call from this neuron

and it's achieving that with the polarization of electroactive

and so that's a hypothesis about how we have neural circuits

so if the brain is operating sort of like in terms of electromagnetism

that would make sense because we capture all these brain waves

so what is a brain wave?

A brain wave is a wave of ions that's flowing throughout the entire brain

and it has all these interesting properties

it has an angle, it has an amplitude, it has a velocity

but what does it mean to...

so we measure, we can see these with EEG caps

we can capture them escaping our scalp

like the solar flares escaping the sun's corona

I'm wearing a couple of those

yeah, the EEG, I had an EEG business once

and it's school technology, you kind of have to be still

because your muscle movement will create a ton of noise

and then the chip processor has to work overtime

to eliminate that noise from...

anyway, so EEG still hasn't even reached its full potential

especially when you start applying the power of a supercomputer

that goes in a self-driving car to your EEG analysis data

I mean that just hasn't done yet

so there's a lot of exciting things for EEG and for MRI and DTI

and for new brain computer interfaces

things that could possibly, potentially revolutionize medical neuroscience

but one of the great... there's a lot of great new concepts around EEG

is that you don't have to only study EEG

you can also study the eye movement

or what they call it, you know, it's eye tracking

but also pupil dilation tracking and heart tracking

you can put all of these on a single sheet

there's a software called Narrow Pipe, it's open source

created by Tim Mullen and there's other software

I think NVIDIA has it around now, Microsoft has it around now

but it allows you to take multiple kinds of sensor data

and unless they're using the open source one

they're running out for a while

it allows you to combine multiple kinds of sensors

any kind of sensors into a single sheet

so it's sort of time lock

and it's time lock in the data so that you can run AI process

so the deep learning can, you know, it's great for observing

you know, like, it's great for monitoring things

like for electric companies, for monitoring power distribution over time

and predicting where that power is going to go

so you could easily imagine that as a way to monitor

like, let's say that someone, you're wearing augmented reality glasses

and you've got EEG and you've got a heart rate monitor

and you've got eye tracking of pupil dilation stuff

and all of this is, and maybe you have a watch

and the watch has like all these biocentures too

and it's all going into one sheet and, you know, enough of the heart pendant

and like all these great biotrackers

and you've got motion controllers and you've got your head tracking

and you at the same time, you've got all the computer vision stuff

going on as categorizing objects

and so then you have deep learning

it's noticing that when you see a virtual box

and a kitten jumps out of it

and maybe it'll notice your heart rate had a spike

at the same time your brain wave had a spike in some region

and then your pupils widen slightly

and then someone, a new person walks into the room

and you have another kind of reaction

between the heart and the eye and the brain and the watch

and so that's a way of, you know, when we do medical imaging

it doesn't, it should be multimodal, it's not

let's only do EEG or let's only do MRI

and this is already the trend that we're seeing in science

scientists are already combining like, okay well what can we stick

because you know the MRI machine obviously is magnetic

so you're limited in terms of, you know, what you can design to mix with that

but there are cool things that people are coming up with

and so getting back to the brain is magnetic

and that means if we can figure out

so if we're setting your brain while we're setting your environment

and let's say that you decide to build a, say that you're working on your computer

and you're working on creating, like you're just implementing

a voice recognition API for your robot

and then the computer is watching you do that

and it's watching you at the neural correlates

and the neural correlates is also, it's not only your brainwave activity

but it's also your eye tracking and pupil dilation

and the computer is figuring out, okay, so this pattern

of working on the voice recognition API for your robot

is exactly, is exactly matching, we've found the brainwave pattern

that's matching what Blaze is doing on his computer

or maybe it's, and we've isolated that from the computer itself

like we're getting very distinct, this brainwave pattern is for the computer

and this is for what he's working on specifically

and so then the computer could tell you at some point, this network

because it has these concepts of how all these signals meet together

the computer can tell you, if you turn off, if you like

put a curtain in front of the computer's cameras

so it can no longer see what you're doing

it can only see your neural correlates

it should be able to tell you from your neural correlates

that you're working on the computer

and you're working on the application

and that means that we have, you know, the voice recognition application

that means we have now identified the tempo spatial ionic brainwave pattern

of Blaze working on the computer on voice recognition for his robot

that'd be sweet

I think some of the first use cases for the neural lace

will definitely be in the medical field like solving Parkinson's disease

like that seems like a great first use for it

absolutely, we have to, so the first step to solving neural lace

is to identify those brainwave patterns of decode

what brainwriters mean, the second step

is to identify the communication protocol

like a network communication protocol

so imagine if our brain was organized like a network or like the internet

which is a very popular idea

I mean packets, like packets, yeah

so is it more like TCP or more like UDP

the transmission control protocol or the user data grant protocol

in TCP it's like, you know, you need a connection

you need almost, TCP is like a feedback loop

UDP is like, you just throw packets of data

it's faster, it's great for mass and multiplayer

and then those are the top two network protocols

and below that there are many other network protocols

like HTTP, right

so the question is, if we can figure out the network protocol of electromagnetism

and we can create artificial neurons or chips

that can send and receive electromagnetic information

that's your brain for it

once we have the knowledge of how to communicate with a brain

you're right, there's a lot of practical medical applications

and one of those is reconnecting the spines

because what happens is the spine is severed

and so the neurons between two points are no longer communicating

and if we know how that works

if we know how neurons talk to each other

we can reconnect the spines, it's very practical

we're not in the realm of science fiction anymore

this is just bridging a physical gap

and then also the same idea applies to artificial limbs

so if you had your arm chopped off

and now someone gives you this really great artificial limb

you can physically connect it to your nervous system

so you can move the arm as intuitively as your original arm

the artificial arm

it's like Luke Skywalker's arm from Return of the Empire Strikes Back

five

so yeah, that's exactly what we want to do at SpaceVR

is let people with Parkinson's go back to work

by working through a robot

and also like vets that have had an arm blown off

like letting them go back to work through a VR robot

so what your telepresence robot at SpaceVR means

is that when we have a brain port that allows us to convert electromagnetic waves

into something the computer understands

that means someone who's sitting in a bed who can't physically move

can teleport into your robot and have the presence to walk around

and sort of like, you know, do business through that robot

and their brain would function as if it was their body

close to the movie surrogate like

the movie surrogate, yeah

it's a little scary, hopefully we don't go in that direction 100%

but there's definitely that direction

like letting people be themselves and control their own lives

another thing is we're really talking about neural life

it's not just brain-computer interface

it's also, I mean it's brain-computer interface

but it's bi-directional or what that means

it's not only can you read information

but also write information

so in the medical application

positive medical application for being able to write to the brain

like if someone had some really traumatic memories

or if they, you know, I'm talking about like

you can actually, what I believe is realistic

and so, you know, memories are, again, scattered over

the whole neocortex potentially

that's what many people believe

so that might be a little bit hard to edit

but what you might be able to, through a brain port

that is connected to your thalamus

or pointed at your thalamus from somewhere outside of you

like with wireless, e.g.

with, you know, there are ways to non-evasively stimulate

like with ultrasonic sound

they're using that to do surgery

for women who

and so that you don't have to actually cut into

the womb area

and you could apply this to the brain as well

to stimulate that core part of a person

the mid-brain

and instead of actually putting a chip on there

and so now we have non-evasive possibility

in fact I tried a wireless e.g. device

the first one I've ever heard of

at CES 2017

so that technology is coming

so like the idea that you need to have a chip implanted is just

I think we're going to do it for research purposes

but this will become a commercial product

and when it becomes a commercial product

there won't be any chips that need to be installed

Elon hopes that you can just inject it into your bloodstream

not even necessary

not even necessary

you could have it completely external

and it would still work just the same

like wireless

I guess some people might experiment with

injecting robots into their bloodstream

there's so much cool things robots can do

there's a lot of blood that goes through your brain

so it'll go right there

and another thing is

potentially you could live longer

if you have robots that are concerned about your health

but one comment was

if your robots get hacked

if you're wearing a baseball cap

or if you're wearing a brand computer interface

under your nose or something that's pointed at your balance

but it's not actually

you can just pull it off if there's a problem

but if the robots are in your bloodstream

it's like how do you get them out

maybe like a residence frequency

that destroys them all instantly

and doesn't hopefully hurt any of your body cells

any EMP pulse

you press the button and it disables all your electronics

stuff

yeah well I mean some of the artificial cells

we're building them out of DNA

so

that's kind of even harder to shut down

it's even harder to shut down

because now they're built out of the same material

Thanks for watching!