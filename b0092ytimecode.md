b0092y Transcribed by OpenAI Whisper + time codes

Listen to the original audio here https://recorder.google.com/7e976dcd-1c8e-4124-8dc9-8f54c364fd86

(audio transcription needs editing.)
My critique of Integrated information theory
Phi is pattern resolution consciousness brain

Summary: In b0092y I start out saying category theory when I meant to say Integrated Information Theory. I do that more than once. This note is largely my criticism of Integrated Information Theory. Attention, Consciousness, and Intelligence are three different things. I talk about AQAL & Spiral Dynamics including lines & stages & levels of development. This one I describes the value proposition of desynchronization process of inhibitory interneuron networks toward the facilitation of novel representations of information patterns in the brain at scale across the network and I contrast that with value of synchronization for muscle in the heart and cerebellum. Desynchronization is important for consideration, and synchronization is important for movement. I propose that Phi, from IIT, might be used to predict the resolution of consciousness but not consciousness itself, I share my thoughts on Buddhism, bigmind big heart, and the way as a religious concept. Lots of comparisons between neuroscience and eastern religious mind concepts. I argue that the tempo-spatial frequency of the circuit that interlaces patterns, a dog or a child should have lower resolution patterns. I compare the resolution of consciousness at different development stages of the mind to videogames from earlier eras which is a neat comparison. Lets imagine that an adult dogs mind is rendering a version of reality that is as complex as Streets of Rage 2 Sega Genesis, but the puppy is rendering a version of reality like Paperboy 1985 Atari.

Transcribed by OpenAI Whisper + time codes

[00:00.000 --> 00:12.000]  One of the problems with category theory that people quickly point out, even people who've never read it, is that it does seem kind of vague.

[00:12.000 --> 00:24.000]  It's like integrated information is so vague that, I mean, if you think about your reality, right, it's like, okay, so if you've ever seen the Matrix film,

[00:24.000 --> 00:36.000]  and you see that scene when Neo sees everything as basically numbers, like he sees the walls as numbers, he sees the hallway as numbers,

[00:36.000 --> 00:40.000]  he even sees the agents as numbers.

[00:40.000 --> 01:01.000]  And these are specifically numbers that are flowing in such a way that they retain the outline of the body of the agents and the outline of the body of the walls.

[01:01.000 --> 01:12.000]  So you can still, in the rendering that's shown in the movie, you can still see that it's really both the physical structures with numbers running on top of them at the same time.

[01:12.000 --> 01:27.000]  Sort of, I had an experience with LSD ones where I experienced San Francisco basically like the Matrix, like it was made out of numbers.

[01:27.000 --> 01:37.000]  And that I could see through it, transparently, and see the entirety.

[01:37.000 --> 01:47.000]  Well, from a perspective, I was down by the coast.

[01:47.000 --> 01:58.000]  The problem with category theory, though, is like, okay, so at some point, people thought that attention and conscious and awareness were the same thing.

[01:58.000 --> 02:16.000]  And then through experimentation and observation and careful analysis, they realized that you're including, and this combines, you know, imaging, medical imaging.

[02:16.000 --> 02:28.000]  It turns out that your brain is able to track and be aware of things that you're not conscious of.

[02:28.000 --> 02:39.000]  Your attention, what you're paying attention to is different from what your eye is detecting.

[02:39.000 --> 02:49.000]  There's a famous video that continues to trick me when I see it, which is where you're watching some people play basketball,

[02:49.000 --> 03:01.000]  and if you get involved in watching how they're passing the ball being passed around in the game, then you miss the gorilla walking across the court.

[03:01.000 --> 03:11.000]  It still gets me every time. I'm like, wait, there's a gorilla that just walked through here.

[03:11.000 --> 03:23.000]  But with medical imaging, it can be seen that, yeah, your brain is still tracking the gorilla, you're just not paying attention to it.

[03:23.000 --> 03:34.000]  So the idea that people once confused, you know, attention and consciousness as being the same thing,

[03:34.000 --> 03:47.000]  sort of, and by consciousness I mean like the awareness of being, the awareness of, I mean, not the awareness of being,

[03:47.000 --> 03:55.000]  so now I'm using the word to distinguish it from the other word, right?

[03:55.000 --> 04:07.000]  The awareness is not necessarily correlated one to one with attention.

[04:07.000 --> 04:24.000]  You can have attention happening without awareness, and there could be awareness without attention. That's the idea.

[04:24.000 --> 04:35.000]  But then if we get to integrated information theory, there could be other ways to divide up what consciousness is.

[04:35.000 --> 04:46.000]  And one of those things is to say, well, what if the, because integrated information theory is like, yeah,

[04:46.000 --> 04:57.000]  so if there's more information and it's integrated in a certain way and there's enough complexity and there's enough operations,

[04:57.000 --> 05:03.000]  then intelligence will just naturally emerge, something like that, right?

[05:03.000 --> 05:10.000]  And I don't know if I might be misdating integrated information theory, but it's something like that.

[05:10.000 --> 05:21.000]  And they think that if we just put enough information together, like if we just synergize it, if we just synchronize it,

[05:21.000 --> 05:36.000]  and I think following that, someone came out with this, they call it the resonant, resonating process for sure.

[05:36.000 --> 05:40.000]  But it's kind of like, so it's a map of reality.

[05:40.000 --> 05:52.000]  So Buddhism, for example, you know, from the tradition of Buddhism, or actually maybe I should say spin-off traditions,

[05:52.000 --> 05:58.000]  because what is the original tradition of Buddhism? We just have all these spin-offs of Buddhism nowadays.

[05:58.000 --> 06:07.000]  Some of them official and some of them unofficial, and most of what I've been exposed to, probably unofficial versions of Buddhism.

[06:07.000 --> 06:17.000]  But I've heard, you know, and so like I'm really thinking about spiral dynamics, and I know some people are,

[06:17.000 --> 06:24.000]  they don't want to hear anyone talk about Ken Wilber because he's a controversial figure in spiral dynamics, right?

[06:24.000 --> 06:34.000]  He's got his own branch of spiral dynamics, and the people who are not in Ken Wilber's branch don't like it.

[06:34.000 --> 06:44.000]  So there's some sectarian differences between the Ken Wilber sectarian branch of spiral dynamics

[06:44.000 --> 06:50.000]  and the other rival church of spiral dynamics.

[06:50.000 --> 07:00.000]  And they hate each other, but it's a little bit of humor, but there's something to what I'm saying.

[07:00.000 --> 07:08.000]  You know, it's humor because these are the people who write about the maps of reality, the map of reality, right?

[07:08.000 --> 07:25.000]  The lines of development, that of cognitive development as a human being grows and matures through time, how their mind might develop.

[07:25.000 --> 07:33.000]  But it's also about the development of the human psyche over the course of history and the development.

[07:33.000 --> 07:49.000]  And I guess the main thing that I... there's a lot of things to take away from Ken Wilber, but it's that...

[07:49.000 --> 07:56.000]  Okay, let me just see if I can wrap this up.

[07:56.000 --> 08:18.000]  It's that observation and the complexity, self-awareness and the complexity of your brain might be, once again, completely different things.

[08:18.000 --> 08:25.000]  And I think that... not completely different, but I mean, like, it's the way awareness...

[08:25.000 --> 08:32.000]  Awareness and... so Phi is this measurement of... is an attempt to measure consciousness by measuring the...

[08:32.000 --> 08:38.000]  not just the structure of your brain, but the activity of your brain.

[08:38.000 --> 08:54.000]  Like, for example, if you're using what Christoph Koch used, which was to use a TMS pulse and to use medical imaging to track the TMS pulse as it ricocheted...

[08:54.000 --> 08:59.000]  as the pulse's reverberations ricocheted around the brain.

[08:59.000 --> 09:09.000]  And so that... the idea is just to sort of like... just to look at the aggregate complexity of brain activity...

[09:09.000 --> 09:16.000]  of active brain activity within the complex network of the brain that has a certain sort of, like, structure.

[09:16.000 --> 09:24.000]  Like, Kochwick in his book, that he's... you know, there's 80 billion neurons in the cerebellum.

[09:24.000 --> 09:31.000]  But obviously cerebellums have been disconnected from human beings and human beings continue to be conscious.

[09:31.000 --> 09:37.000]  And so what is it? 80% of 86 billion neurons.

[09:37.000 --> 09:44.000]  And the cerebellum, and scientists don't think it's conscious because you can cut it off and people are still conscious.

[09:44.000 --> 09:49.000]  And so what they look at is they say, well, the configuration is too straight.

[09:49.000 --> 09:52.000]  The neurons are just lined up too straight. They're lined up in a row.

[09:52.000 --> 10:01.000]  There's not enough lateral connection to support a conscious state.

[10:01.000 --> 10:09.000]  But I don't know of an experiment where the... I mean, it looks like just an excitatory network.

[10:09.000 --> 10:17.000]  You know, like a heart instead of something that's capable of a lot of patterns, a lot of inhibitory patterns.

[10:17.000 --> 10:28.000]  So it's purpose is a bit of a mystery if it's not for consciousness.

[10:28.000 --> 10:38.000]  You know, it's not a total mystery. Supposedly it helps a great deal with balance, you know, with helping you to find your balance.

[10:38.000 --> 10:47.000]  People who don't have one, they seem to move a little bit more like a drunk person.

[10:47.000 --> 10:51.000]  Their movements are not as smooth.

[10:51.000 --> 11:12.000]  So maybe it's the oscillatory value of the sort of cerebellum. It's like a magnetic weight that helps you balance.

[11:12.000 --> 11:22.000]  Maybe it's like an... I don't know. I don't know. But if it's not... It's like, okay, it's like, well, you know what's interesting is when you come...

[11:22.000 --> 11:31.000]  When you have lots of neurons that are... have coordinated synchrony, that's really good for moving muscle.

[11:31.000 --> 11:37.000]  Like your heart, for example, it has a lot of neurons that are just... they just always fire in synchrony.

[11:37.000 --> 11:50.000]  It's not like the... it's not the way the neurons behave in the brain where the neurons sort of have novel pattern, novel firing patterns in your brain.

[11:50.000 --> 12:00.000]  There's lots of... like you see different patterns, almost chaotic patterns about you in the brain all the time.

[12:00.000 --> 12:07.000]  But in the heart, the neurons are like, we're always the same. We never change. Regular, the regular, the regular, the regular.

[12:07.000 --> 12:18.000]  And then the next day, we're always the same. We never change. You know, it's... there is this... there aren't inhibitory internal networks in the heart.

[12:18.000 --> 12:35.000]  It's not... it's not that there are... sensory patterns are not being reflected across the structure of the heart, but they are being reflected across the structure of the brain.

[12:35.000 --> 12:41.000]  And they're being represented by the structure of the brain because the brain is changing in response to incoming sensory patterns.

[12:41.000 --> 12:54.000]  The heart is not changing at all in response to patterns from the world. You know, those patterns aren't being sent to the heart, but if they were, the heart would just ignore them.

[12:54.000 --> 13:05.000]  It doesn't change in response to patterns from... I guess it could evolve to do so over a long time, but it doesn't do that.

[13:05.000 --> 13:20.000]  And it's not connected that way. But getting back to integrated information theory is... I think that with this hypothesis that I'm describing, something as small as a bug...

[13:20.000 --> 13:37.000]  And this is not, you know, I guess in Kristoff Cox, but, you know, he was saying that fish could be conscious. Could be. They could be. Because they might... because even though they have far fewer neurons and far smaller brains,

[13:37.000 --> 13:54.000]  they might have the arrangement or the structure for basic consciousness. And so he's like making an argument, but the fish doesn't have the quantity of the complexity of the human brain.

[13:54.000 --> 14:11.000]  It doesn't have the same phi. It doesn't have the quantity of interconnected complexity that matches sort of the kinds of operations, the scale of the operation. It doesn't have the scale of the operations that the human brain has.

[14:11.000 --> 14:35.000]  And therefore consciousness for a fish must be in some way like less than, such as it might be smaller, or it might be just less complex, or their fish's interpretation of reality must be reduced in some way.

[14:35.000 --> 14:54.000]  I want to say that I think that, well, okay, if... it could be, though, that from the fish's perspective, their perspective is very grand.

[14:54.000 --> 15:12.000]  And because the fish doesn't know what it's missing, right? So the fish's perspective could be... I'm just saying, like, imagine this beautiful ocean picture, right?

[15:12.000 --> 15:39.000]  And I don't know. I don't know. Okay, here's the thing. I think that maybe phi, or the complexity of the patterns that are... I think of phi, like, phi, P-H-I, I think of it as like, maybe it could be an indicator of the resolution of the patterns

[15:39.000 --> 16:01.000]  that the brain is incorporating into memory at each interval, right? The resolution, though. I think that phi could be a way to measure the resolution of consciousness, or the resolution of our internal patterns that form the walls and fabric of consciousness.

[16:01.000 --> 16:14.000]  And that's different from... but that's different from saying that it is consciousness. No, I think that phi represents the resolution of consciousness, like, how much detail exists in consciousness, potentially.

[16:14.000 --> 16:42.000]  How detailed the patterns are. Because you could also, you know, potentially do that TMS experiment that combined with medical imaging with... you could combine that with... what is it called?

[16:42.000 --> 16:52.000]  With someone on... on ayahuasca, or DMT, and they may have... they may have... or someone in a sensory deprivation tent.

[16:52.000 --> 17:01.000]  And in their brain could be altered in a way that they don't have normal consciousness, or they're not, like, on this plane of existence from their own perspective.

[17:01.000 --> 17:19.000]  They're not aware of their real surroundings. They're in an altered mental state. And that person might even be dreaming. And what are you measuring? What are you... what's... what's... I don't know, I want to see what that looks like.

[17:19.000 --> 17:34.000]  But if you have... so the dreaming state, okay, the dreaming is different because their brain is going to sleep. But the person with, you know, ayahuasca or DMT, their brain... I would expect the brain to be, like, overly excited.

[17:34.000 --> 17:49.000]  And you think that that would be a good measure of consciousness, but maybe they're not... maybe they're... they're not with us. But their brains are really at you.

[17:49.000 --> 18:09.000]  And so they're not really... they're not really conscious of the real environment that they're in, but they're experiencing some alteration, some alternate reality. That's... that's... let's call it a hallucination.

[18:09.000 --> 18:29.000]  And... but the... but maybe the resolution of their hallucination could be defined with five. Right? Not the... not... not... not... whether they're... don't consider it a quantity of consciousness, but...

[18:29.000 --> 18:40.000]  but instead the res... so it's going back to, yeah, the fact that, you know, it's clear now through many experiments and careful analysis that awareness and attention are two different things.

[18:40.000 --> 18:58.000]  And I think that with integrated information that we have a situation where the measure of consciousness is not a measure of consciousness. It's a measure of the resolution of the patterns inside a self-aware network.

[18:58.000 --> 19:25.000]  And the self-awareness is about the cyclic configuration of the network. In other words, self-awareness is the result of patterns learned over time in which the outside world and the inside world are... are learned.

[19:25.000 --> 19:39.000]  And the connections between your muscle movements and your body and your form are connected to your incoming senses and what you're doing and what you're experiencing and where you are and who you're with.

[19:39.000 --> 19:53.000]  And so your brain is learning a model and it's not the... the model itself is not consciousness. The complexity of the model is not consciousness because you can have a really complex model on a computer that's not conscious.

[19:53.000 --> 20:08.000]  It's the learned... it's the feedback loop described by Douglas Hofstadler, the feedback loop in his books, Godel Ascherbach, and then also the follow-up book, I'm a Strange Loop.

[20:08.000 --> 20:30.000]  That... that... the data of your brain waves causing changes to your muscle movements which cause changes to your... the sense that you're... the positions of your eyes and the positions of your ears and the things you're sensing and hearing.

[20:30.000 --> 20:50.000]  And... and all your... all your senses combined when... when they are learned, when you're learning the sort of neurofeedback of your own body through experience, that's... that's when sort of like the self-awareness...

[20:50.000 --> 21:09.000]  the patterns... the patterns of self-awareness begin to formulate in the cortex. It's through the feedback loop of lived experiences, of patterns forming connections that map.

[21:09.000 --> 21:25.000]  Basically, it's your map of reality. And so, yeah, so I'm arguing that Phi is the resolution of... of the patterns of... of... of consciousness, but that consciousness is the looping of... of pattern.

[21:25.000 --> 21:43.000]  The feet... the neuro... the strange loop, like a feedback loop of patterns, or neurofeedback. Consciousness comes from basically neurofeedback through the resolution of the pattern matrix that your brain is putting together.

[21:43.000 --> 21:58.000]  So... so cyclic brain activity, when information oscillates through circuits that... that incorporates new information from the world, like that is where consciousness emerges.

[21:58.000 --> 22:26.000]  And I think Phi is... is a useful measurement for measuring the potential resolution of consciousness, but I think that any organism with a brain, or a piece of brain, like an organoid, a tiny piece of brain, that's in a learning feedback loop is going to gain some... some sort of self-awareness, but the resolution of that self-awareness is what's going to vary.

[22:26.000 --> 22:42.000]  And so, you could say, well, a fish is going to have... through the interaction with this environment, it's going to have a very extremely low resolution of self-awareness, comparatively.

[22:42.000 --> 23:05.000]  If you compare just the complexity of its neural network to the complexity of an elephant, an elephant's resolution of... its pattern resolution should be significantly larger scale in terms of the density of patterns an elephant can hold into memory.

[23:05.000 --> 23:30.000]  And that's not... that's not just... that's not only about the... sorry, image resolution, but that's also about the temporal resolution, like how much time can... over what period of time can an elephant conceptualize reality?

[23:30.000 --> 23:40.000]  Can memories be linked together so an elephant can remember memories across a lifetime and put them together temporally?

[23:40.000 --> 23:46.000]  Oh, that's when I was a kid elephant. Do you remember being a kid elephant? Now we have kids.

[23:46.000 --> 24:12.000]  Like, those sort of like long-term memories might be more likely to happen in larger brains. Perhaps the fish is... by comparison, the fish is like... you know, the only remember... like, reality started last week and...

[24:12.000 --> 24:25.000]  and the only thing the fish remembers is what happened this week. You know, maybe it's like that, or the only thing... or it could be the only thing the fish remembers is really, it's like what happened this day.

[24:25.000 --> 24:47.000]  And maybe the longest memory that the fish has is like... or can put together is like a month ago. And it doesn't mean the fish is forgetting its very old memories. It's the idea that the pattern resolution of the complexity of its mind might limit, like, how far it can conceptualize time.

[24:47.000 --> 25:06.000]  And I don't know, there could be... it could be possible for a creature with a smaller brain to have a glimpse of what it's like to have a larger brain.

[25:06.000 --> 25:27.000]  To... you know, what if... it's like, yeah, what if you suddenly woke up and you suddenly had this conception of reality when with... about... you know, on the scale of like 10,000 years.

[25:27.000 --> 25:42.000]  Like, what if you just, like, really were such a history junkie and an anthropologist and you just always walked around with, like, this window of maybe 10,000 years into the past and 10,000 years into the future.

[25:42.000 --> 25:55.000]  You know, I guess some archaeologists are really thinking in terms of 500 million years, or 13.7 billion years, whatever it is, the age of the universe.

[25:55.000 --> 26:09.000]  And some people are really in the long now by comparison to what's happening with... you know, there are people who are in the month... like, in the month, like, they're... they don't remember what happened last month.

[26:09.000 --> 26:19.000]  They're just here in this month. And there are people who are... you know, their heads are in the 13.7 billion years span of history.

[26:19.000 --> 26:34.000]  Sorry, of the evolution of the cosmos, 13.7 billion years of the natural... of physics-based natural selection, natural selection of the cosmos.

[26:34.000 --> 26:45.000]  Right. How patterns... how patterns develop from the beginning... alleged beginning of time.

[26:45.000 --> 26:56.000]  But in short, I'm arguing that pi is a pattern resolution and measurement, and it doesn't have to do with self-awareness for consciousness fundamentally.

[26:56.000 --> 27:02.000]  It's not the amount of consciousness that you have. It's the resolution of your patterns.

[27:02.000 --> 27:23.000]  And what consciousness comes about when your patterns are... when your pattern learning system is entered into a feedback loop, or when your phase field is breathing and learning its phase field.

[27:23.000 --> 27:33.000]  Which is the ecosystem your brain is in, or your environment. And that's sort of how I picture it.

[27:33.000 --> 27:46.000]  It's like, all of our incoming senses, it's... it's like, our brain does a lot to... you know, our brain has the sensor arrays.

[27:46.000 --> 27:57.000]  All of our senses are sensor arrays, actually. And our brain does a lot to reduce... reduce them.

[27:57.000 --> 28:07.000]  Sorry, to just select... it does a lot to just take some amount of information and then reduce that information to a usable amount.

[28:07.000 --> 28:22.000]  It's... if we had a way to augment our minds to have a lot more simultaneous pattern recognition, we could increase the resolution of our minds.

[28:22.000 --> 28:38.000]  It wouldn't... I would say it might deepen the experience of awareness, I guess, to have more deeply integrated patterns.

[28:38.000 --> 28:49.000]  But then again, it's like, you know, going back to descriptions of Ken Wilbur and the maps of reality, it's like the...

[28:49.000 --> 28:54.000]  you know, there's a description of, like, there's a ground of being, which is just awareness.

[28:54.000 --> 29:03.000]  And in this ground of being, that's where all forms arise. And this is... this is from, like... I think it's from Buddhism.

[29:03.000 --> 29:09.000]  But it's like, if you experience just the, like, space of being this, in which all forms arise.

[29:09.000 --> 29:17.000]  That is a map of reality that is just as unclear as integrated information theory, but far older.

[29:17.000 --> 29:24.000]  And I feel like, yeah, well, integrated information theory, it's like to say that, you know, the brain is just integrated information.

[29:24.000 --> 29:32.000]  It's like, well, it's also sort of like saying, well, the brain has information. We're just hardly saying anything at all.

[29:32.000 --> 29:36.000]  And it's not really saying anything more than, you know, the brain has just...

[29:36.000 --> 29:42.000]  and consciousness has a ground of being and then forms arise within that ground of being.

[29:42.000 --> 29:48.000]  It's just... it's just as fake, right? It's just as fake, but it's also really new.

[29:48.000 --> 29:59.000]  Like, you didn't give any credit to Buddhism for coming up with its mental models that you're obviously, like, not that far away from.

[29:59.000 --> 30:07.000]  Right? Integrated information, right? It's like, it's not an innovation in human history.

[30:07.000 --> 30:14.000]  Buddhism was an innovation in human history, you know, the ground of being, non-dualism.

[30:14.000 --> 30:20.000]  The idea that basically that every thought is a distinction from holism.

[30:20.000 --> 30:27.000]  And that's where I'm coming from. It's like, yeah, yo.

[30:27.000 --> 30:39.000]  And so at the time that I was looking at Ken Wilbur's work, he was working with Gempo Roshi, who was an abbot, who I think retired.

[30:39.000 --> 30:44.000]  But Gempo Roshi created Big Mind and Big Heart.

[30:44.000 --> 30:55.000]  And I purchased also the Ken Wilbur's Integral Life Practice Kit.

[30:55.000 --> 31:08.000]  And they walked you through a number of basically mind-expanding perspectives where, like, the one, two, three of God where you tried on the first person and second person and third person perspectives.

[31:08.000 --> 31:13.000]  The first person you were one with God, the second person you were in a relationship with God,

[31:13.000 --> 31:23.000]  and the third person you were considering other people's relationships through each other and their relationships to God or something, I forget, but... something like that.

[31:23.000 --> 31:31.000]  And the idea was, and then with Big Mind and Big Heart, you got to take on...

[31:31.000 --> 31:36.000]  So when you're the voice of Big Mind, you like, you shift in your seat and you become this voice.

[31:36.000 --> 31:43.000]  So Big Mind is like, I, you know, you realize, wow, if you're Big Mind, you're everywhere.

[31:43.000 --> 31:46.000]  And there's nowhere you need to go because you're everywhere.

[31:46.000 --> 31:55.000]  And when you're Big Heart, you're, you're, you know, it's like, there's, your heart is everywhere.

[31:55.000 --> 31:58.000]  And you're, you love everything.

[31:58.000 --> 32:07.000]  And then when you're, when you're Big Joy, you know, it's like, these are great, you know, it's like this great, joyful feeling that has nothing to do and nothing to get.

[32:07.000 --> 32:11.000]  And, um, an even great, even great doubt.

[32:11.000 --> 32:18.000]  It's like, well, if you doubt everything and there's nothing, there's, there's really, um, there's no reason to hope.

[32:18.000 --> 32:22.000]  And if there's no reason to hope, that is a very liberating feeling.

[32:22.000 --> 32:23.000]  It can be.

[32:23.000 --> 32:32.000]  If you get to, like, truly, like, truly hope, if you're truly hopeless, that feels pretty good because you don't, there's no burdens on you.

[32:32.000 --> 32:36.000]  It's like, there's no reason to hope about anything, so you can just relax now.

[32:36.000 --> 32:41.000]  It's a, it's all uncertain, so you can just chill out.

[32:41.000 --> 32:46.000]  Wait, are you sure about that though?

[32:46.000 --> 32:51.000]  It's like, um, like great, great, great doubt, great hopelessness.

[32:51.000 --> 32:58.000]  These are, these sound scary, but when you get really to the bottom of them, um, they're all celebrating.

[32:58.000 --> 33:02.000]  And, um, so he would walk you through it with big mind, big heart.

[33:02.000 --> 33:09.000]  They would walk you through the protector, the voice of the protector, which, which, um, what do you do when you're with the protector?

[33:09.000 --> 33:11.000]  Well, that's a self-explanatory job.

[33:11.000 --> 33:15.000]  You protect, you protect the self, you protect the body.

[33:15.000 --> 33:17.000]  And it's like, so you ask yourself these questions.

[33:17.000 --> 33:20.000]  Okay, so it asks this voice, what do you do?

[33:20.000 --> 33:29.000]  Um, if we've got the function, the job is the function is you're the protector or you're the, um, controller.

[33:29.000 --> 33:33.000]  What does a controller do? Well, it takes the function and applies this function to everything.

[33:33.000 --> 33:41.000]  Like, like the, like the, like the, um, the person who tries to hammer, who thinks everything is a nail.

[33:41.000 --> 33:53.000]  So when you're taking on the perspective of the protector or the controller or the, or the, um, the, the, uh, innocent,

[33:53.000 --> 34:02.000]  then you are basically playing that role towards everyone and everything and in your imagination.

[34:02.000 --> 34:04.000]  So you're basically like exploring this voice.

[34:04.000 --> 34:12.000]  Okay, so if I'm, if I'm the protector, I protect everyone else and I protect myself and I protect everything.

[34:12.000 --> 34:25.000]  And, and, um, it's, um, it's, uh, it's also useful to sort of like take on like, I mean, I didn't see him do this,

[34:25.000 --> 34:29.000]  but I imagine it would be useful to take on archetypes, mythological archetypes.

[34:29.000 --> 34:46.000]  If I am the, the, uh, uh, and, and, um, you know, you could take on, um, also, uh, voices from, from Hinduism and from,

[34:46.000 --> 34:55.000]  you know, from, from, you could take, you could take on voices from, from Marvel, Marvel Comics or from, uh, from Greek mythology

[34:55.000 --> 35:02.000]  or from basically from any tradition, you could take, you could sit on, you could, you could sit in the character that you want,

[35:02.000 --> 35:12.000]  take it on and explore it for your own, for the, for almost like the development of your own psychological patterns

[35:12.000 --> 35:26.000]  that, that, um, that connect to these different characters and, um, and I think even that you could, you could have an experiment where people,

[35:26.000 --> 35:35.000]  uh, sort of like, uh, take on other people that they're, they become other people in, in a guided meditation,

[35:35.000 --> 35:40.000]  they become other people that they've been having conflict with, they become those people.

[35:40.000 --> 35:50.000]  So it's like, it's like you're embodying the pattern that, that you've been using to, um, to understand someone else's mind,

[35:50.000 --> 35:56.000]  your own mind's model of someone else's mind and you embody their pattern and you become them so you can,

[35:56.000 --> 36:05.000]  but the purpose is not so you can become them, it's so that you can develop your, your, your pattern for their under,

[36:05.000 --> 36:11.000]  for understanding who they are. You want to develop your pattern for understanding who they are,

[36:11.000 --> 36:24.000]  um, so you can understand how to, um, more successfully, um, either avoid them or interact with them or to resolve conflicts that you have with them,

[36:24.000 --> 36:31.000]  whether it, in terms of, in terms of like your model, in terms of resolving your model of reality,

[36:31.000 --> 36:37.000]  this, this is separate from resolving your real world conflicts with them, you know, actually,

[36:37.000 --> 36:44.000]  but like resolving your inner conflicts with them so that you, so that if you encounter them, you, you would have a strategy,

[36:44.000 --> 36:52.000]  uh, ready because you, because you are not conflicted anymore. So if you encounter them again, you'd have a strategy ready.

[36:52.000 --> 36:58.000]  It's like you're developing your, your own patterns through this, through this practice called big mind, big heart,

[36:58.000 --> 37:07.000]  your own mental patterns. Um, and, and I think that, that had value for, for me, for a lot of people, like mind expanding value,

[37:07.000 --> 37:17.000]  because you could become the way, the way that is everywhere and everything, right? The way is, is something that, that, uh, um,

[37:17.000 --> 37:24.000]  uh, has been spoken of in religious by many, by multiple, like religious leaders across traditions.

[37:24.000 --> 37:37.000]  Like the way is, um, like the way things are, it's like the way of the cosmos, the way is, um, everywhere and everything.

[37:37.000 --> 37:43.000]  It is another version of big mind and big heart. It is this sort of like omnipresent way.

[37:43.000 --> 37:50.000]  And it's the polarity of the seeker, like you understand that the seeker is the one that's striving and the seeker,

[37:50.000 --> 37:54.000]  when you say, I am the seeker, I'm the one who's always thirsty for more information.

[37:54.000 --> 37:58.000]  The brain is always seeking and it's never satisfied.

[37:58.000 --> 38:02.000]  Like once you get something and you want something else, you can never be totally satisfied.

[38:02.000 --> 38:06.000]  But, but the seeker is also the polar viewpoint of the way.

[38:06.000 --> 38:16.000]  So the seeker is this sort of like high frequency, basic seeking, this pattern that's always like, um, incomplete and always hungry

[38:16.000 --> 38:25.000]  and always wants and always desires and always leads to suffering, but also always leads to life.

[38:25.000 --> 38:33.000]  And, um, and then so when you alternate, say, well, the seeker is also the way, so I'm also the way, the way that is everywhere and everything.

[38:33.000 --> 38:41.000]  I'm entropy. I'm entropy, serving entropy, you know, or whatever.

[38:41.000 --> 38:48.000]  You're the process of the cosmos, basically.

[38:48.000 --> 39:02.000]  You're the atoms shooting out of the star and now tumbling together into knots.

[39:02.000 --> 39:07.000]  It's a gravitational knot. You're the way.

[39:07.000 --> 39:13.000]  And, um, so being the way is being everyone everywhere.

[39:13.000 --> 39:27.000]  And, um, but the way we are the way is by also embodying the seeker or the seeker is, you know, the path seeker because we couldn't find the path unless we were also seeking it.

[39:27.000 --> 39:34.000]  So the way is the path and the seeker finds the path and the seeker finds the self.

[39:34.000 --> 40:03.000]  And so the observer, I guess you could say, well, the observer is the way and the neural, the neural phasic firing pattern is the path of the seeker charting through the charting through the bed of the array of the oscillating field, oscillating phase field, charting the patterns through it.

[40:03.000 --> 40:32.000]  And, um, so, um, so that's why, so that's how I connect yet, um, like Buddhism and spiral dynamics and Ken Wilbur, but also Douglas Hofstahler, and then, um, and then I use that sort of say to make an argument that, you know, that integrated information

[40:32.000 --> 40:46.000]  theory is undifferentiated between the resolution of, of the textures in your consciousness, uh, and, and your consciousness itself.

[40:46.000 --> 41:15.000]  So my argument is, yeah, is that is, is that your graphical awareness, um, is, um, has a resolution and that resolution would be defined by, would be, could be defined by five, but that self-awareness has no resolution in, in, um, and is, it is about the design of, self-awareness is about the design of the circuit.

[41:15.000 --> 41:22.000]  And so, um, you say, well, what self-driven car has a feedback loop?

[41:22.000 --> 41:24.000]  It does, it does.

[41:24.000 --> 41:28.000]  So isn't it self-awareness and self-driven car?

[41:28.000 --> 41:33.000]  It's not, it's not, let's just say it's not human-like, so it's not human-like.

[41:33.000 --> 41:57.000]  Um, that a, uh, and it's not, let's just say that it's not, um, because, because you could have a car that has its own rendering of reality and it has, it has an, it's not, um, you could even render tactile sensations.

[41:57.000 --> 42:03.000]  You could render patterns associated with feelings, you could render them.

[42:03.000 --> 42:12.000]  Um, but it's the, it's, it's not just the, the patterns looping together in a feedback loop, it's also the frequency.

[42:12.000 --> 42:30.000]  It's the, it's the, it's, no, it's specifically the temple, what makes us human-like, what makes our minds human-like is the temporal spatial, um, frequency of the oscillations of these patterns.

[42:30.000 --> 42:37.000]  Um, uh, of these, the oscillations of these matrices of patterns.

[42:37.000 --> 43:03.000]  It's the temporal spatial frequency, so you could have, um, or the, as you say more than that, it's the temporal spatial frequency of the, um, of the circuit that interlaces different sets of, of patterns together.

[43:03.000 --> 43:23.000]  Um, and, um, so you could have lower resolution patterns that would, you know, so, and, and, and I suspect that, you know, so for example, if my hypothesis is right, then a dog should have lower resolution patterns, right?

[43:23.000 --> 43:44.000]  And, but also a child should have lower resolution patterns, because they haven't had enough time to develop the resolution. And so, so you could say, well, maybe at some point, um, the reality for a dog is like, so maybe for human being, reality is like, like, um, if we were to say, um, let's just point to two video games, okay?

[43:44.000 --> 43:59.000]  So, um, we've got this old video game from, you know, 1985 called Streets of Rage 2. It was Streets of Rage 3, Streets of Rage 2, or another one is Street Fighter 2.

[43:59.000 --> 44:07.000]  Street Fighter 2 was another fun game. Mortal Kombat was another game. But these are old, these are old games that came out in the 1980s.

[44:07.000 --> 44:24.000]  And, uh, in the modern, the modern games, uh, you know, there's like Grand Theft Auto 5, um, there is Counter Strike, and these are, these are much more 3D, the graphics are better.

[44:24.000 --> 44:50.000]  Um, uh, what is Fortnite? Fortnite is a modern video game. Uh, people play a lot of, um, uh, there's this new VR version of, of, uh, uh, of the game, um, Resident Evil 4, and, um, Resident Evil 4.

[44:50.000 --> 45:15.000]  Number 4. Um, and the, um, the thing is that, um, let's imagine that the, um, the dog's mind is able to render reality as, as, as mentally complex as, as a game from 1988.

[45:15.000 --> 45:26.000]  Like, you know, like the Ninja Turtles game, or the Shinobi game, you know, like, let's say, let's say that when the dog is a puppy, it's just rendering.

[45:26.000 --> 45:41.000]  And the same thing is like when a child is, is just, just, just a child. That the reality that the rendering has, like, the rendering complexity of something like Pac-Man, or, uh, or Paperboy,

[45:41.000 --> 45:47.000]  just a really simple 2-bit, you know, not 2-bit, but, you know, like an 8-bit video game.

[45:47.000 --> 46:08.000]  And, and then the complexity, um, increases, uh, by interval until, like, you know, at some point, the, the, the child was just had the complexity of, of their, their knowledge of, of, in, in, in terms of, like, if you think of the video game as not just graphics,

[46:08.000 --> 46:18.000]  but also the knowledge of, uh, functions, like, um, there are video games like Super Mario that involve very few buttons.

[46:18.000 --> 46:27.000]  Just lots of, you know, jumping and running, jumping and running and pressing forward, right? Pressing forward, that's what you need, basically.

[46:27.000 --> 46:35.000]  Jumping and running and pressing forward. You can, I think you can press backwards, but it's not really necessary, um, in Mario.

[46:35.000 --> 46:45.000]  You could just run all the time, um, and, you know, but the, but the functional complexity is not, is not very great.

[46:45.000 --> 46:56.000]  And then you have games where, like, an RPG where there's, like, you have to, you have to go through all these steps of, of equipping your character and buying, you know, items for your character

[46:56.000 --> 47:09.000]  and killing bowl-level monsters to get money to buy things for your character and to build up, like, um, you basically, your character has to work to get things

[47:09.000 --> 47:18.000]  so that it can, so that it can go, so that it can then go and battle bigger monsters and then get even more things.

[47:18.000 --> 47:31.000]  And then eventually, your character, um, might, uh, save the world or, or die, or, you know, you never know with, with, with, um, with RPGs where the story is going to go.

[47:31.000 --> 47:36.000]  You know, it is, sometimes they make your favorite character die.

[47:36.000 --> 47:54.000]  Like, oh man, it was that one, one girl who, who, who, one girl in the entire universe who, who spoke, before spoke, before being spoken to, and she died.

[47:54.000 --> 48:00.000]  Like, there's, there's only one girl who's ever been the first person to speak to a guy.

[48:00.000 --> 48:06.000]  And that was Eris. Don't you know how rare and precious she was?

[48:06.000 --> 48:10.000]  And then you killed her. That's what they did.

[48:10.000 --> 48:31.000]  And, uh, Final Fantasy VII, first time. So tragic. It's like, there's, there's never been a girl like Eris before, who spoke first before spoke being spoken to.