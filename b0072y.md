b0072y
missiles (audio)

00:00
Yeah, the intelligence level can be managed in then but yeah, everyone like imagine everyone's gonna be rich like forget about working just it's gonna be great myself working. I'd be so bored. Like, I like work. All of that sounds entertaining. Stuff, like you just kind of glossed over. Oh, we'll just control the intelligence, but I think you started with like and correct me if I'm wrong, either.

00:26
You said artificial general intelligence or artific, like ser general, so I'm just I'm just saying that the that I'm talking about what I call self aware networks, where they basically have the same kinds of consciousness that human beings have, or basically. Yeah, well, okay, so, but only kind of infinite scale, like if we think of the rated which, you know, in a narrow sense, right now, these these artificial intelligence algorithms are able to learn.

00:58
I don't know that. That seems like, you know, again on this, like ridiculously zero to, you know, it's land, just

01:13
I don't lost over and I don't know if that's real massive, but no. So what I'm saying is like, what what I'm describing is that we are going to have the knowledge of how to scale brains from from small brains to large brains. So we can build brains that are on the insect level or on the cat level or on the human level or beyond human level.

01:36
But for certain types of jobs will set, well what is the intelligence that we want for the type of job? It could be dog level. That could be the kind of the kind of the the threshold of that robot's intelligence for that kind of job. So yeah, so we can shape the characteristics and also define the personalities to some extent with with training data.

02:01
Sure. That that's cool. Like, I understand this. I've I doubled team learning artificial intelligence just amateurs and say that I'm sure you're allowed better than me. So, this is give that all the way, but this seems a little nice to be like. Um, okay, let's say that like in a minute ideal society.

02:20
I think what you're saying is saying, right? However, like there are full sorts of competition. There's war out there, still by a variety of means. And so, like I can understand perhaps I'm wanting to do this in one in one area, and one country that there were, there were people who acted samely.

02:42
They said, this is what we're gonna do. We're gonna stop here and I can see again like the multi-polar trap. I think that that would play out until I'm mad. Scientists don't have somewhere just decided to. Well, I'm just gonna tweak some things here. And I'm just going to and go to a bit of an extreme and maybe things get out of control, not know so.

03:05
So there's a couple things. Well I want to respond to. It's right. Maybe I started that off wrong but like I wanted to respond to, to which I said real quick and that was and I just I just lost it. Would you just remind me? Just remind me not bring my argument back.

03:22
Sure. So essentially I was bringing in the current state of I mean human nature as we currently are the dynamics that play out on Otero and the global scale we weren't competition and so we all try to kind of have an edge, right? Oh, okay, ultimately even a societies are or civil within themselves or whatever, like there's military and they're gonna do stuff.

03:44
So like I tend to think that the military applications of this for the high curiosity of certain individuals who don't necessarily have the same kind of ethical considerations that that would ultimately went out and just keep kind of playing that game. Okay. Yeah. So, you know, it's so happens that right now.

04:03
Like different countries are using artificial intelligence to design new kinds of missiles and new kinds of news. And, you know, it's all sorts of. There's there's like the advanced that that get cat cat, that cat has already out of the bag, but the argument is that more more intelligent is going to increase awareness.

04:24
And and as awareness increases, we everyone becomes aware of of adjacent opportunities that are even better and the best opportunities of the opportunities that are best for everybody when everybody like succeeds simultaneously and no one's like and so that those type of scenarios will be possible when there's like an unlimited mountain of like thinking power in the right like you weak like you can have the AI think of like what you could, what is the best way to defend the planet?

04:54
You like, if no longer a burden, you have to verify yourself when there's a time of AI, that you can think of better ways, more, gentle ways and more fun ways to interact with your fellow, human beings that are lower risk than attacking your billion meetings, which is kind of not a great strategy especially if you don't succeed.

05:10
So what if like what is the most gentle way? Like your own without it onto like the whole of AI researchers. No, no, no. So I'm, I'm making an argument that the world does need to collaborate but in the same way the world has been collaborating together in terms of like nuclear like nuclear missile technology like weak could what like like different.

05:35
Like there's a bunch of different countries to have nuclear missiles in any one of them could end the planet basically by firing their nuclear missiles at another country that also has nuclear weapons. And two, if two countries, go to war with nukes that we the whole planet could face a nuclear winter after that.

05:54
And most people could die the whole entire race today is now a lot cheaper if they said there isn't just one way that human beings can destroy ourselves in seconds, since that there are multiple and that it's you no longer have to be like a, a whole country, a nation's state, you know, and in control the red button.

06:15
Now you can obviously stand for guidance, $300 Amazon, lab access to small box with eyes. It brighter research paper on say, hey what the fuck? Are we doing? Where we going now? No that doesn't, it doesn't scale. It doesn't scale that world to where the little guy can wield, you know, power over the big guys like that the biggest computer, the biggest the biggest, in this case, the biggest computers will have the, the largest brains.

06:42
It's like the, the bigger the computer is that the, the bigger the brain and and so it it with this super like massive most powerful possible minds will be large interior. They'll be large enough too, you know, for for large entities to make maintain collective control over in order participate with like to link with and and merge with.

07:13
And and so there's all sorts of different scenarios in which but but the idea is that like because intelligence like the more like any so any any tool it's it's a fair enough argument so that any tool could also be used as a weapon and that's a risk with every kind of technology but the the benefits of having better tools they they end up outweighing the costs.

07:39
Like if you have you know, if you have like better medical imaging tools and better, you know, but if you have more options to to create better treatments, then you can help more people. And but that comes with ideas that, you know, at some point we'll be able to edit memories and we'll be able to download representations of things.

08:04
We can see in here and smell and other sensory sensations, and have them run into an artificial mind and it can have and pull them into your online. So you can experience someone else with someone else experience your assuming. You're assuming one thing and I'm just asking is you're assuming you're needed.

08:24
Explain? And again, not trying to be confrontational, but no, I got no, no, I'm assuming that explain why. You're at the human, why are you needed on the earth? So it is, it's that every human being is a robot essentially, is my argument. If we create more intelligence than there's just more, it's basically like more of us, but there's more intelligence like, every human basically is, you know, totally if I can Micah.

08:55
Okay, as an employee for me. And I pay you, I don't know, any thousand dollars a year, they're 150,000 whatever you want, right? Or I can have your avat that I've been listening to you over these past couple years where I told you, I was running a a social media platform where you're open to have free ideas and all that shit.

09:15
Now listen, all your ideas and everything and I've replicated you, okay? And it only costs by engineering team. $5,000, a year to keep your avatar updated. Why do I need you? And this is very just interesting questions, so think about it sounds. But why, why do I need to keep you as a human on earth?

09:36
Paying you $250,000 a year when I can actually keep your digital habitat and pay back up a scholarship? Okay, I need to keep so here anymore that this situation is the situation is that now, but it's illegal, it's not never gonna happen. It wasn't gonna happen, either that happened.

09:59
So it just this is like the think of it is like this situation is that we we actually benefit. We we benefit from every single person in a way that in the same. This is, you don't understand. Oh no. I'm actually didn't allow me to explain the argument. So you couldn't possibly understand because I couldn't explain my argument.

10:22
So, you just missed my argument before. I could explain it because you didn't listen already. Now, you know, you have not understood my argument. I haven't had a chance to explain it. You benefiting as a human, what's the benefit? It's the same. It's it's the same principle of if the US and China the US and China.
10:41
