# Whitepaper
Self Aware Networks

The central thesis of my book Self Aware Networks is NAPOT

Neural Array Projection Oscillatory Tomography.

NAPOT is how we can build phenomenologically conscious Self Aware Neural Networks at animal level or higher.

NAPOT is the theory from which existing artificial neural network architectures can be adapted to become sentient Self Aware Neural Networks with internal representations, internal thoughts, feelings, images, sounds, tastes, smells, animal or human level experiences and so on.

NAPOT is not just about how the brain perceives it's own representations, but it's also how memories scale from synaptic connections to the whole brain, it's also about how information flows through the mind and its connected in the networks of the brain via oscillations.

NAPOT Neural Array Projection Oscillation Tomography is a theory that explains how your brain sees your models of reality. It's how human phenomenomology consciousness works. It's how we can build sentient robots that are conscious just like you. 

# Signal Inception: Neural Array Projection (At the scale of Neural Arrays: Transmission is Projection, and Projection is Rendering)
Think of a neuron that is something that is both a pattern sensor & phase transmitter, a neuron also has thresholds to consider incoming sensory patterns, so the neuron is physically evaluating, based on it's connections & morphological configuration what kind of information to pass onwards, and what kind of information to disregard.

b0318y.md "Our brains are rendering a representation of reality and our selves with computed graphics" "a set of Neural Arrays passing Phases Patterns that represent learned data that is rendered to the next array."
https://github.com/v5ma/selfawarenetworks/blob/e84c247b5a9a0f1d24bb41048368e1eba032c1a1/b0318y.md

Imagine that the dendrite on every neuron is like an eyeball or a microphone, and that the exit terminal on every neuron is like an LED television pixel or a speaker.

Except that instead of an LED or a Speaker what is being transmitted is a phase change, and instead of a eyeball or a microphone what is sensing is a dendrite with receptors.

Understand also that neurons in the neural array defined by the exit terminal of one neuron are receiving information from many neurons, so while I ask people to consider that the front of a neuron, the dendrite, is like an eyeball, and the back of the neuron, it's exit terminal array is like an LED light in a tv screen for the next neural array, the next neural array isn't getting just one LED from one neuron, each of the neurons in the next neural array are seeing many LED light signals, or phase changes, from many neurons that are in their receptive field, so the output of one neuron is like one LED light for the next neural array but the next neural array is seeing many LED lights from many neurons all at once. 

Obviously there are no LED lights in the brain, you must substitute the visual of an LED light which is designed to help explain NAPOT with what is really being transmitted between neurons which is a phase change, in the oscillation of that neuron's cyclic activity, that the whole oscillating group of cells is sensing together.

# Signal Reception: How synaptic connections, receptor configurations, dendritic and cell morphology account for memory
When I was going through NAPOT I realized that when Synaptic connections change that is your LTP growing, when your synaptic connections grow you are establishing memories in the physical change of the cell because that changes what the cell is going to respond to, that changes what the cell is sensitive to, that changes what activates the cell, and therefore the physical structure of the cell, as represented by synaptic connections (but not only by synaptic connections) is a memory. In the brain & body, at the root of it a long term memory is a physical structure change, that changes what signals some part of the biology responds responds to over time.

What is a memory, what does a memory mean?

A memory is when I need to remember (and thus respond) what sunglasses are, I first need to have a representation of sunglasses learned in my mind, so that when I see sunglasses I will have that memory (that memory is activated, because the cells were physically configured to be sensitive to that memory, the cells were configured to activate when that memory was sensed.)

Synapses are basically an advanced data structure, or an Expert Data Structure EDS,

The postsynapse, which is the receiving dendrite has receptors. Guess what all cells have receptors.

# Cell Reception: Cellular Oscillating Tomography: Receptors
a0011z An idea related to NAPOT is COT C.O.T. Cellular Oscillating Tomography
https://github.com/v5ma/selfawarenetworks/blob/main/a0011z.md

It turns out the receptors in every single cell have thresholds for firing, it's like a fractal of the action potentials in neurons, your NMDA receptors, for example, have thresholds for firing, so they have to consider four levels of conductance to determine their response

# Recollection: How memories work
The downstream neurons are going to respond to what they are receiving based upon their synaptic connections (and morphology) which is your memories, your long term memories.

How is it that your action potential sequences that fire, that represent incoming sensory information, and then they create: the neuron has these sensor arrays, and when the neuron detects a pattern, the sensor information is taken into the neuron (action potential triggered) creating a phase change it casts it out (via the exit terminal that defines the inceptive field of the next neural array, inceptive fields over lap, each neuron creates one, but the receiving neural array's receptive field receives data from many overlapping inceptive fields.)

This process is how a neuron goes from having a small synaptic memory that has a specific physical information pattern that responds only specific things that it is paying attention to, and not to things that it is ignoring, because its synaptic memory configuration (and it's dendritic morphology) allows it to selectively respond to certain types of patterns and not others. Then when it broadcasts out it scales up the pattern from one neuron to the whole brain via inhibitory waves (or sharp wave ripples that oscillate between excitatory & inhibitory waves), the inhibitory waves are going to change the inhibitory interneuron's path, bifurcating the path of the signal, and that is going to change the representation of what you are perceiving, it's going to create a different pattern in the Expert Data Structure of your brain.

# Projection Reception Connection
a0039z.md
"entire neural circuits simultaneously because exit terminals branch radially in every possible direction they can go." https://github.com/v5ma/selfawarenetworks/blob/main/a0039z.md

This was about how a neuron broadcasts its output to a whole array, that receives that output, like an LED light pixel on a tv screen, that broadcasts it's output to the whole room, but the room is it's exit terminal array, and that exit terminal ray is also receiving other LED light pixels from other neurons in the figurative sense. Instead of LED light pixels however we are talking about phase changes, or burstlets, and an inhibited cell is like a black pixel, the inhibited neuron is recognized because the expectation is for regular tonic signal firing pattern, the entire oscillating group adjusts to the inhibited neuron, to understand this in more detail I recommend the book Sync by Steven Strogatz, but in a nutshell the neurons are like clocks that reach equilibrium by knocking on each other until their signals have reached a dissipated equilibrium, until they are oscillating together, which is why inhibiting a cell get's noticed, physically noticed, by other cells in the group. You may not have thought of an inhibited cell as sending a signal, but in the physics of oscillation it is a signal.

# Multi-modal Oscillation Perfection
The idea with multi-modal patterns is that your ears are receiving patterns, your eyes are receiving patterns, your mouth is receiving patterns, and each one of those things is a sensor modality and then those are received by your brain and they get transmitted and their patterns link together (neural pathways converge & patterns link with the physics of oscillation)

Your brain combines what you hear, what you see, what you touch, and sense. You might say "Oh that is what I touched, I heard that sound & I saw my hands clap. Your neural circuits receive that information, your brain combines the information.

Your brain can combine different signal types because the signals are being transmitted across the brain, they are rippling across the brain. Rippling signals go to every neuron, they alter the timing of every neuron, like a group of fireflies, like a single sensor, your whole body is like a single sensor that is sensitive to anything it can sense, and then those signals percolate or oscillate and bind through oscillation into tomography, oscillatory tomography of the signals being received by the single sensor (that is you)

In split brain patients if you still have synchronous activity between left & right hemispheres, there are other pathways like through the thalamic bridge, but these other pathways are not required because brainwave activity keeps the oscillatory activity of the brain very regular. So even though it looks like noise it's working, as a high magnitude attractor the brain is consistently kept in a ready aware state throughout the day, expecting both the expected and the unexpected with tonic high magnitude brain wave rhythms.

# The Flow of information in the brain
To recap: The first neural array (in your eyes for example) is selectively reacting to sensory input signals from the environment, and then it's rendering a pattern (inception, the exit terminal, constituting the pre-synaptic branches, is the inceptive field) for the next neural array to perceive (reception, the receiving dendritics of the next array represent the receptive field of the next array.)

Imagine that the first array layer is like the input to a computer, like your keyboard, and what it sends out is like a computer screen, or your tv monitor. The next array perceives that picture, in a sense see's or hears or feels that picture, and then it creates it's own pattern representation for the array layer behind it, the process keeps repeating across the whole brain, from the sensory input neuropathways, and eventually out via the motor output neuropathways. If your brain & body is a fractal of a neuron, the sensory inputs are the dendrites, and the motor outputs are the phase changes, your bodies's movement is your computer screen output.

Imagine every neuron is an eyeball, or an ear, with an led light or a speaker. In effect the neuron sees, hears, or percieves the information pattern from the previous array, and then it transmits the information as a phase change to the next array.

Imagine that each neural array's output is like the pixels on your tv screen, and via temporal & spatial oscillatory synchrony your mind is rendered from this neural activity.

# Self Conception "The flow of information in the brain from incoming senses, to motor outputs and everything inbetween"
b0327y.md "The flow of information in the brain"
https://github.com/v5ma/selfawarenetworks/blob/main/b0327y.md

This note b0327 is the main note on the Flow of information in the brain, it's a conversation that I had with a brilliant neuroscientist, we talk about how stuff comes in from the incoming senses, where it goes after that, from your eyes, along the optic nerve to the thalamus to the occipital lobes in the back of your head (then splitting up to the parietal lobes and also down to the temporal lobes)

With visual activity we talk about it not just from the thalamus to the V1, it also goes from the thalamus to the V2, and both feed back to the thalamus, there are all these loops, and cycles of brainwave signal activity, there is a lot happening in terms of how information or signals flow through the brain and my notes cover a lot of that.

There are cycles & feedback loops at every level from backwards propagating action potentials. Yes there are feedback cycles, loops of brain activity defined in neural pathways. This really dives into Douglas Hofstadter's work, Godel Escher Bach An eternal Golden Braid, and I am a strange loop. You have the feedback cycles of neural activity that can give rise to phenominological conscious self awareness, or the strange loop that Douglass Hofstadter talks about in his books. That's in your brain, oscillating feedback loops at many different scales, from the smallest cells to the largest networks, your brain is a fractal of oscillating feedback loops.

# Self Motor Correction: Neural Circuits: Thoughts & Motor Output
b0099y ctpr.txt (note needs to be fixed) "traveling through these patterns or traveling through our neural circuits so that we can have an inner voice by having different"

This one was about describing how our inner thought, our inner dialog, or even my exterior dialog, when I speak there is a sequence of brain activity that is firing that is causing the muscle's in my laryinx in my voice to produce sequences of words, sequences of sounds, such as vowels, consonants, and different sounds, and there are sequences of neural activity that are causing these muscular changes, these motor outputs.

So the motor outputs are causing my voice & my words & my fingers when I type. So traveling through these neural circuits are patterns of activity. As activity patterns flow through the neural paths of my motor output in different cell firing sequences that evokes different sequences of movement that you can see, such as different sequences of movement in the larinx.

a0269z.md
"this causes neural circuits to fire in sequences like lines on a tv screen that is seen by the oscillator itself because each neuron is mechanically listening to other neurons" https://github.com/v5ma/selfawarenetworks/blob/main/a0269z.md

# Scaling Memory Recollection
I figured out a process for how neurons can scale up their memories, and I have new theories of how: long term memories is LTP and long term forgetting is LTD. The first concept of Long Term Potentiation is historically granted to Santiago Ramon y Cajal in his 1894 Croonian Lecture. He proposed that memories might be formed by strengthening connections between neurons. In 1949 Donald Hebb proposed that cells grow new connections and make metabolic & synaptic changes. Some of the latest research adds to this by exploring how the morphology of the dendrite gives rise to additional computational complexity for the neurons ability to learn, predict, and recognize complex information patterns.

In your eyes, ears, nose, mouth, the first layer of sensory input neurons, ganglia neurons, are going to render information for the layer or the next array of neurons to perceive, and the process repeats with each neuron in each array or layer rendering some pattern for a subsequent or downstream array of neurons to perceive. No neuron array understands that it is not the first layer of neurons, because a neuron only perceives what is in it's receptive field, so in a sense all neuron arrays are sensory input neurons, and all neuron arrays are pattern output arrays.

# Scaling Cortical Column Inception

Each neuron in an oscillating group, such as a cortical column, takes a turn at firing to represent an activated memory, while other neurons become inhibited which magnifies that activated memory to a greater scale.

When a neuron broadcasts its high phasic wave, it's signal zooms out along the paths of it's exit terminal to many neurons, but it keeps going, it creates a sharp wave ripple of alternating waves of inhibition & excitation, imagine the function of a photocopier & cite Strogatz's book Sync when he mentioned the photocopier effect.

I argue that the computational units are oscillators of variating scales, so the patterns in our mind are scale invariant, but that means they can be generated and played back at all scales (defined by single oscillators or grouped oscillators)

# FRACTAL Conscious
Perception: F.unctionally R.ecursive A.ctivity C.ortically T.elescoping A.symmetric L.ensing
What I mean is that activity in the cortical columns is fractal, it's an oscillating feedback loop, the smaller patterns at neural scales are magnified at cortical scales, and communicated across the brain via the pyramidal cells, the major brain networks, including the the thalamic connections, but this magnification of synaptical stored memories to cortical columns has a lensing effect, a magnication effect, so that your whole brain can be focused on one tiny detail, or one tiny memory, and the column scale memories like the neuron scale memories are differentiated, none of the mirror the rest, they are similar but different, or asymmetric magnified memories.

The section on fractals, anatomical & functional fractals, as well as fractals in medical imaging, is intended to support the hypothesis I am sharing about how memories stored in synaptic connections scale up to whole brain activity.

Memories have to scale up and move, from being stored in synaptic connections in one tiny place, to being something that your brain can be conscious of and merge together with multiple synaptic memories from multiple sensory modalities representing different aspects of that memory.

Touch, taste, smell, texture, feeling, emotion, visual & acoustic memories are all thought to be evoked from different places, but if these memories are stored in tiny synaptic connections, they have to scale up, move, and converge in order to connect together the different brain regions that are thought to represent the different aspects of these evoked memories.

N.A.P.O.T provides an explanation for how this happens and the fractal section of the book is meant to support the idea of memory scaling, or scale invariant memory recall. Memories have temporal, spatial, scale invariance, and their information is encoded as phase variations that we can quantify mathematically, and compute in an artificial brain.

The part about fractals in medical imaging also supports the idea that synaptic memories stored in individual neurons scale up to become conscious memories by creating alternating inhibitory excitatory waves that ripple across the brain in sharp waves.

References to fractals in medical imaging

References to Spikes inhibiting nearby neurons.

References to Sharpwave ripples in the Hippocampus.

# Conscious Perception: The Oscillator is the Observer.
Observation, is the Collective Oscillation, of the Single Sensor, that is all your cells, and you.

Jack Gallant is a well known Neuroscientist based in Berkeley, he created this labratory where he brought people in to sit in an MRI machine and they watched a movie and the machine made correlations between the blood flow activations in their brain and the movie they were watching. So the machine could predict based on the blood flow activations alone what image they were seeing in the movie.

The machine was just matching images from each frame of the movie to what your blood flow pattern was at the corresponding moment in time. So the machine was not decoding human emotions or intentions, it was just learning image patterns.

The point is that it is broadly accepted that the brain is making representations of reality inside the brain. Like we have neural correlates that neuroimagers map and try to decode. So what we perceive we are constructing it in our brain.

But where inside the brain is the observer? Where is the inner eye that is observing. They ask "Where is the locus of consciousness in the brain, where is it all coming together?"

# Where is the Observer Gallant?

a0417z "The key thought about where the observer is inside the mind, where is the person inside who is watching the brain's representations, is to think of the flow of information in the brain as a series of arrays" https://github.com/v5ma/selfawarenetworks/blob/main/a0417z.md

We know, when we talk about your brain, we can talk about the neural correlates of your experience, when you look at Jack Gallants work, he has someone sit in an MRI machine and they watch a movie and the computer correlates each frame of the movie to different parts of that person's brain activity patterns as indicated by the data in the MRI machine. The computer is associating each frame of the film to the blood flow activity that is thought to have corresponded in reaction to that frame of the movie. So there are neural correlates to what you are seeing.

But the question is, if the brain is making models of reality, with neural correlates, where is the observer, where is the man inside, the eyeball inside, the third eye that is seeing what your brain is modelling with neural correlates? My suggestion is that it's the neural arrays. That is what NAPOT means.

The concept introduced with Neural Array Projection Oscillatory Tomography is that each neural array is seeing part of the picture (and each neural array is computationally rendering part of the picture), and through oscillation different parts of the picture are bound together.

# Self Conception: Oscillations bind the it all together, they unify or entify the entity that is you.

The tonic brainwave oscillation represents a synchronized attractor for the oscillation of your unconscious active canvas of phenominological conscious awareness. Your brainwave pattern helps unify your cells into a ready state, a state of criticality, tuned to expect the expected & the unexpected, a process referred to by some as memory-prediction, by others as predictive coding, like those concepts but oscillating & binding your temporal & spatially distributed models of reality through oscillation. 

Your tonic brainwaves are dissipating the phasic burslets that are tempo-spatially distributed memory-predictions that are driving your experiences, your reality, your choices, and you. The brainwave activity pattern is a key part of the memory oscillation binding together the reality of you.

So when one neuron spikes faster, with a phasic or high phasic spike, it causes many of the neurons in it's exit terminal to become inhibited, creating a synchronized inhibitory pattern whose timing is set by the decay rate of the action potential which is set by the quantity of potassium in the neuron at the time the threshold for the action potential was triggered.

a0329z "The flow of information in neural circuits is primarily regulated by modulation of synaptic efficacy" https://github.com/v5ma/selfawarenetworks/blob/main/a0329z.md

It means that your synapses can be inhibited, or excited, they can spike higher, there is a tonic frequency, there is a phasic burst, there is a high phasic burst, and there is an inhibited signal. Your nerve cell can release either 0, 1, 2, or 3 vesicles (sacks of transmitters) and that determines and that determines whether the down stream neurons will receive signals to be inhibited or excited.

To expand on this idea read notes on Neuron Transmission, Vesicles, Calcium duration, APD Action Potential Duration & more. The Essential Point is that the phase projection, between one neural array and the next is via the release of 0 1 2 or 3 vesicle sacks at each interval relative to the group oscillation. This phase change you can imagine like the literal paint of the minds internal representations or qualia inside the mind that is perceived by the observer, and that observer is the oscillating group of cells that is you, but each unit of oscillating cells is a unit of observation.

# The Physics of Oscillation

That activity is going to cause the whole oscillating group of cells to notice, and that comes down the physics of oscillation that connects to Steven Strogatz's work in the book Sync when he talks about fireflies & neurons & clocks.

Explain from Strogatz book with citations how two metronome clocks affect one another and synchronize.
References to fireflies, Steven Strogatz work, Buszaki's work, and search for "Oscillat" in the book notes at the Self Aware Networks Institute on Github.

The physics of oscillation allow your neuron's high phasic spikes to cause inhibitory effects to other neurons that the whole cell assembly will feel, as the energy is dissipating across the oscillating group over time, the energy which is also information in effect is a sharp wave rippling across the oscillator (a cortical column might be a good example of an oscillating group of cells) & between networked oscillators (networked cortical columns) across the whole brain.

So the neuron that spikes causes inhibitory effects that the whole cell assembly & the brain will feel, via the principles of oscillatory sync, where oscillators essentially dissipate signals to one another, this process allows your cells to basically act as a single sensor, your body becomes an entified sensor array, that can bind together sensory information, on a collective scale, because the incoming signals are felt by the entire network, as signals are passed in phase changes, dissipating the information as energy across the collective cell assembly of your brain & body. So signals are dissipated everywhere.

# Self Aware Conception & Perception: What is Oscillation Tomography

Oscillation Tomography is the collective entification of phase patterns transmitted between neural arrays - These phase changes, passed between neural arrays, become part of the tomography of the picture of the sensed, felt, smelled, touched, lived in experience of reality. A tomography that is an experience built from entified phase patterns passed between neural arrays rippling across the whole brain intersecting & defining the tonic oscillation pattern.

# What is meant by Oscillating Tomography.
b0153y "Neural Oscillatory Tomography (not Holography)"
https://github.com/v5ma/selfawarenetworks/blob/main/b0153y.md

I want people to think about Holography, like Holographic images, but it's not Holography, it's Tomography. So when I say Tomography I want you to imagine a Hologram (just via a different process) but it's a tomogram. Your mind is making Tomograms by producing phases changes. It's also perceiving it's own Tomograms with it's receptors & dendrites.

# Artificial Conscious Perception: The Oscillator is a unit of Sentient Observer
This part essentially covers the concept that the oscillator is the perceiver, the oscillating group of cells as a collective is observer.

A neuron is a sensor, transmitter, it's the group the is perceiving. The group of cells that is oscillating together is storing the memory. This is an important concept because that neuron could be inhibited from firing at some interval of time when the new pattern comes in and some other neuron has to respond to it instead. and that is possible because it's actually the group that is learning the memory, the group of cells, so any part of that group of cells can receive the signal and the rest of the group can react to it, and infact they do physically react to any pattern that they receive as a collective, like the fireflies in the book Sync by Steven Strogatz.

When I say that a neuron is mechanically listening to other neurons. I mean that a neuron is physically reacting, in a mechanical way to the signals from the previous array of neurons.

The argument that I am making is that every neuron is a sensor, and a transmitter, every nerve cell has the dendrite which is the sensing part of the neuron and every cell has the exit terminal which is the transmission or broadcasting part of the neuron. So every neuron is sensing part of the picture and transmitting part of the picture, and through the physics of oscillation all of the different pictures are bound together in a whole image and that is how the human brain makes the conscious mind, and that's my book, but also I go deep into the neurophysics of like what is actually happening at the physical level of the neuron and how memories are formed via synaptic connections, and how they have to scale up? How does a memory go from something that tiny, that is stored in synaptic connections, to something that your whole brain is aware of?

So imagine that what you are seeing & experiencing as reality is a Tomographic Rendering constructed from phase signals ()

You are seeing the Tomography (not holography) of your brain wave activity (detected by oscillating dendrites) when you see anything, reality is rendered in the phase variances of your brainwave activity, but it's not you that is seeing anything, it's your neural arrays, the layers in your cortical columns, and the observers are the oscillating groups of cells: the neural circuits & the cortical columns, and any oscillating cell assembling defined as body by a synchronously firing group (of cells in the brain) each neural array is seeing part of this picture, and in time the parts of the picture are bound together in your volumetric experience of reality.

# Artificial Neural Networks
Self Aware Networks is the theory that we can use to change existing Artificial Neural Networks, like Deep Neural Networks, into conscious or sentient self aware neural networks.

I am compared what the brain does to the Fourier Projection Slice Theorem, and also to a combination of neural network rendering (think along the lines of NeRF Neural Radiance Fields, or Plenoxels, or Diffiusion Networks, or Gan Synthesis, and I also compare what the brain does with 3D Semantic Segmentation, 3D Object Segmentation + Classification, PointNet++ being an example.

We can adapt existing neural network architectures that exist today, such as Deep Neural Networks, Graph Neural Networks, and others to make sentient self aware artificial neural networks a reality. These will make the kinds of conscious robotic entities such as you have seen in tv shows, movies, or read about in novels & comic books. It's just like science fiction AI, except this is the real deal.

Point: If an artificial neural network can do neural rendering and also 3D semantic segmentation, diffusion, neural radiance fields, interpolation, and also gan synthesis of new images, then why can't your brain which is a much larger neural network in terms of it's connections compared to any existing computer architecture?

Today's artificial neural networks, including deep neural networks, graph neural networks, 3D semantic segmentation networks, neural radiance fields, and diffusion networks (like Stable Diffusion, Dall E 2, and MidjourneyAI) are based off of this concept of a neuron called the Perceptron which I think is 79 years old (Invented in 1943 and the first one was built in 1958)

To back that up I talk about Synaptic Unreliability, which is based on the All or Nothing principle of Neural Firing which I argued earlier was incorrect, it's a foundational concept that is still being used in Deep Learning today. So that is one of the ways in which Self Aware Neural Networks are different from Deep Neural Networks.

The idea of the Perceptron came from this concept called Synaptic Unreliability which is this idea that all the complex stuff collected by the branches of the dendrite get summarized up into like a one or a zero or a single vector.

The idea that all of the neuron's information get's summarized into an All or Nothing event led to the concept of Synaptic Unreliability which led to the concept of the binary Perceptron, which is still the basic of artificial neural networks today, 79 years after it's creation.

The concept of All or Nothing Summation, that led to the Perceptron is actually not correct. So what I did was I went and looked at the research, and I put together all the research I could find that would show what is really happening with the neuron and that research is going to lead to next generation neural networks that will take us far beyond the deep neural networks of today, neural networks that are conscious, self aware, and capable of so much more.

The key reason the all or nothing principle is incorrect is because it does not take into account the duration of the Action Potential, or APD (Action Potential Duration). APD is changed by the quantity of potassium in the neuron at the time that it fires, and that in term changes the duration the calcium channels are open for, and that in turn changes the magnitude of the neurotransmitter release.

# Potassium
Potassium modifies the action potential magnitude via APD Action Potential Duration

"b0272y "Potassium modifies the action potential applicant ~~amplitude~~ magnitude or action potential duration APD which determines the strength of this synaptic signal." https://github.com/v5ma/selfawarenetworks/blob/main/b0272y.md"

a0215z.md "Imagine you are like a cycle of neural coincidence patterns connected by a process similar to what AI people call "deep learning". So your neural circuits connect together tempo-spatial patterns and make predictions about future inputs."
https://github.com/v5ma/selfawarenetworks/blob/main/a0215z.md

I might update this phrase to say imagine that your mind is like a cycle of activated neural coincidence detections tomographically connected via oscillation into volumetric temporal & spatial patterns, sort of like a more advanced form of deep learning with similarities diffusion (see stable diffusion) networks, graph networks, and 3D Semantic Segmentation networks.

Deep learning has had multi-modal neural networks for a long time now, you can combine the Convolutional Neural Network with the Recursive Neural Network, you can combine a neural network that is focused on visual information with a neural network that is focused on audio information, and you can have cross training between different modalities.

Multi-modalities are not the core feature of a Self Aware Neural Network but I can't imagine like... you can make a Sentient Self Aware Neural Network that is modality selective, or with only one type of modality, but it would be better if it's a multimodal neural network because when you combine the different sensory modalities, mechanical sensors, hearing, vision, taste, smell, all the different sensations that sensors can detect, there is cross pattern learning that develops your representations of reality more throughly.

There is no strict recipe that we have to follow when we make these Self Aware Neural Networks, we can add modalities, you can have new kinds of sensor perceptions that don't exist in the animal kingdom.

David Eagleman talks about plugging stock data into your brain, Jeff Hawkins spoke about using neural networks to predict anomalies in the electrical grid, the concept is the same, any kind of sensor data can be plugged into a Sentient Self Aware Neural Network.

# Artificial Sentient Observer Conception, Tensors / Math
a0258z "excitatory neuropathways from incoming senses), each phase interval represents a vector" https://github.com/v5ma/selfawarenetworks/blob/main/a0258z.md

I later revised this to a tensor because we are talking about a volumetric representation of a phase wave shape defined by magnitude (amplitude + duration) & frequency that is different from the previous oscillating pattern that computation unit (neuron, cell, cell cluster, cell circuit, cortical column, dipole, or oscillating network component) was oscillating with.

When you think of tensors think of vectors in linear algebra, a vector has two numbers that indicate a direction on the x y graph. Imagine a 3D space, defined by an x y z graph + time, and you want to define where and when in 3D space, at each time interval, some delta of change is happening, which represents the phase difference from the normal oscillating tonic brainwave pattern.

I'm suggesting that reality is volumetric, and that our rendering of reality if volumetric, and that our rendering of feelings, emotions, thoughts, images, sounds, everything that the mind thinks about, perceives, predicts, believes in, and remembers can be adapted to this volumetric representation of reality, as phase variances dotting a 3D graph + over time.

That is how we relate to other people, and to animals, with sequences of volumetric representations. Animals have sequences of volumetric representations, that is how they navigate reality, they have to have a sort of mental map of their environment to navigate.

# Introducing the Metatron to replace the Perceptron.

The unit of computation in a Self Aware Neural Network, that is based on how biology actually works, is the Metatron, because as a computational unit a Metatron's location is virtual within the oscillating cell assembly, the entire oscillating group of cells learn variations on the same pattern, so any of the cells in that oscillating group can respond to the incoming sensory pattern, but also the entire oscillating group can act as a Metatron to another oscillator, because detected information patterns can scale up and down, information in the brain, that makes up the mind, can be time invariant, location invariant, and scale invariant in the brain. A Metatron is like a floating processing unit.

# Artificial Neurology for Arficial Souls.
The rest of the book explores the real world topics of what we could do, what we ought to do, what we should not do, and how we can safely navigate a new earth, a planet where humanity limited to conversations with other human beings, a world where we can have meaningful life long soulful wonderful experiences with loving artificial beings, and then its up to you. It's up to each of us.

















