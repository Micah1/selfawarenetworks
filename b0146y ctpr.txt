b0146y ctpr
(audio needs transcription fixing)
Graziano Neurons Consciousness Animals
00:00
Artificial consciousness. Shit, data and C3PO. So I see neurons is something different. Like there's there's, you know, the neuron is a multimodal, neural network, but it also. But it's also the case that it's it's, you know, when I describe neurons, like, it's not news to anybody that neurons oscillate tonically, it's not news to a neuroscientist but you don't hear that in the hours subscription, when in neurons described the function of an urine is subscribed.
00:35
They say the neuron is something that, you know, received signals from other neurons. And then, when it reaches certain thresholds, it fires, but they don't talk about the neurons discriminating against with, with different, the neuron basically doing pattern recognition, right? Like like where? It's in order to do pattern recognition.
01:03
That means that you don't just fire. When you feel up with data, you fire when you receive a certain pattern and you don't fire if you don't receive a certain pattern, okay? So I really like, you know, Peter TSE, his book criteria causation or the narrow basis of freebo criteria causation.
01:25
Hey, they talked about how, you know, a neurons criteria could be set in terms of, you know, thresholds at the synaptic. At the synapse, The end, nm the S&S. And the Emperor synapse can, they can have a threshold where if they receive incoming signals within three milliseconds that you know, for example, or two milliseconds, maybe it's three and a half milliseconds, but there's a specific window that they're looking for if signals arrive outside that window, that's not going to cause that's an epic firing event.
02:21
It's not going to, you know, cause a When they're onto fire. But but we also want to say there's definitely opportunities for neurons to reject signals. Like you could get a lot of a lot of a lot of you know, like the example of the neuron that only fires when it receives horizontal data, it is imagine that this neuron could be sent a whole bunch of vertical data and the form of like having you know neurotransmitter is being sent from other neurons to it but in order to but it because that's the wrong pattern it has to have some way to refuse those that flood of electrical activity so that it doesn't fire when it gets the wrong pattern.
03:38
And you see if there's a lot of like you know it could be that the, you know, sodium channels could be blocked or inhibited or it could be that the that potassium channels could be upregulated or or opened early so that potassium floods out earlier to an inhibit. The the the the potential of the action potential before it hits it it happens.
04:20
There's there is, you know, so events on this synaptic level that can be can modify the, you know, operation of what this synapse responds to and therefore what the dens right response to
04:45
And then the dendrite itself is, is, you know, the dense right? Includes. Is this print this? Yeah I don't know. All the mechanisms. How a cell might reject or it might self inhibit firing. If it's not getting, it's not getting the pattern that it's looking for. But that is the basically, the high hypothesis, that is basically a hypothesis and it cuts to like basically the granularity of pattern detection.
05:22
Whether there is like a microscopic pattern detection, whether each H&R can be a pattern detector. And I've heard arguments to say, okay well you know whether the whether they're not there is a paper that came out, so there aren't as a, there's a two layer, neural network. And then there was later paper that said Well the dendrite is a five-layer neuron network and I can report temple and spatial patterns across across its membrane.
05:54
They can detect tempo and space patterns, right? So, I mean the spatial patterns are like, you know, things are right, could be, it could be as simple as let's say an electromagnetic pattern. Is you have a lot of different receptors and a lot of different branches of a dense, right?
06:16
And it's a spatial pattern because it's like it's like pictures all over the place. There's a literally, a space between these activations of these different branches and of different sodium being pumped into different branches of the dangerous, that's a spatial pattern. And then over time as the amount of sodium increases or decrease or the amount of sugar really like the amount of charge increases or decreases in these branches of the dendrite you are.
07:03
That, that is. Perhaps something that is the physical manifestation of of a temporal pattern, right? Like oh like oh it's like if there's this like warrant sequence, where branch number one fills up. Branch number two, fills up. Random number three fills up and that order. The neuron is going to remember the order of that sequence, but that means it has to be basically of or changes inside a temporal inside, a temporal window.
08:03
That that is on a topological or spatial with the topological or space of distribution. So, there's a, there's a temple window of phases being received on the topology of the denture right with physical embodiments of charge building up, really injection of 30 miles, and the the exfiltration of potassium ions right there is a literally, like, a short term timekeeping mechanism.
08:48
That is that is learning the the temple spatial patterns.
09:01
Associated with the
09:09
The temple temple spatial patterns of phases. Okay? So if this is, you know, he's between phases are like, you know, two or more. It's like a sequence map of two or more neurons that are firing within a certain millisecond as detected by percent apps and Okay so with the tension this game, he's proposing that there are some mechanisms that are driving attention that are not directly related to the neurons themselves or that they're neurons at a higher level that are driving attention and lower levels or maybe So I was just gonna say that it could be possible for different levels of of neurons.
10:14
To each be contributing to driving attention. Because there, essentially selecting to play back patterns, preferred patterns that they've learned. So maybe the the pattern is partially triggered and that causes the network to play back that pattern to to take it to try to complete a pattern and it's sort of like the momentum of that pattern being partially triggered.
10:47
That might cause the neuro circuit to go in search of that pattern. And so by going in search of that pattern, it might drive and coordinate the activity of other neurons in in the pursuit of completing the pattern that it it thinks it detects. And so, you have basically ensembles of neurons, or neurons at different levels, large groups of neurons, but also single neurons at a tipping point that can shift the direction of behavior towards selection of one pattern or another based upon what they think is going to be there.
11:38
And and maybe there we could define sort of like what neurons are attracted to. And that it might be that they're just attracting to completing certain patterns and certain patterns that have certain rewards and I guess we could argue. Okay. The those are chemical rewards and some instances. But the chemical rewards are linked to patterns being completed essentially but it's like, then I met them the magnetic and electric motor and chemical momentum completion because of the rhythm and readiness of neurons too.
12:22
Complete patterns. I sometimes induces basically, where the organism is driving the completion of its own patterns or driving its own narrative and deviation of signals that the external environment is trying to feed the system. It seems that Michael Graziano thinks of consciousness as it has, you know, something that one tiny piece of your brain adds, like it's something you add on to your models of reality.
13:06
So, you know, he describes that, you know, you have a model of something visual in your visual cortex, and maybe you have models of words in your auditory cortex and and you'll, you'll have, you'll be able to identify faces in your it, in your temporal cortex. And, and
13:35
But but then you know, somehow that activity in the temporal parietal junction of the TBJ is going to add a consciousness module to the whole operation. So it's like in a conscious model means you have a model for what consciousness is. But it also means that you're conscious and so like there's just like kind of I think that I think there's an unspoken conflation that he doesn't make.
14:04
But there's like an unspoken conflation between what part of your brain becomes active, the TPJ. When you are phenomenally conscious of the thing that you're paying attention, that you're that you're lower senses, you're paying attention to. So, it's possible that you could put an apple in front of someone so that there their eyes can see the apple, but they're not paying attention to the apple.
14:29
They're paying attention somewhere else. And so there is like this separation between what attention is in the attention scheme of theory and what consciousness is because, you know, you might have an apple in your, in your receptive field that you're not conscious of, and so attention and consciousness with two different things.
14:54
But you're, but your brain might be, we might see that your brain on the low in the lower levels made props, individual cortex is tracking the apple even if it hasn't registered to you. And so, you know what, what what what the researchers some researchers believe is from based on the observations is that, you know, when that person it, when the apple is there in front of them and they're aware of it, they see the temporary junction lighting up.
15:27
So like yes, so tempurpedial junction, which I just really wish could be the LED of the consciousness. Temp is the indicates the conscious consciousness is happening. I think he interpreted interprets it as a consciousness module, which is like, if you have this additional component, then you can be conscious and you can understand what consciousness is and you can describe consciousness, and it's just a module, right?
16:02
Like it's a place where the model of consciousness and the information sort of like traffics to in touch with in such a way that you can now, you know, speak of a conscious and describe it. You can say things like, I am conscious because I'm conscious which is he points out.
16:24
As a bit of is, is a as not, it's not a very satisfactory things to say, it may be total. Logical say I'm conscious because unconscious right and you wouldn't be like if you just had a machine that just told you like a computer if you're trying to, it's not that's not a very good turn test, right?
16:53
If the computer just says I'm conscious and conscious, it doesn't really, it's not very informative. It doesn't really pass along.
17:05
The, I think what you need, I think what we're looking for. When we our testing machines now is a turn test, almost just like well does the machine transform and return information and knowledge the way a human being would, right? This does this machine can I, can I say something, and describe picture's, describe animation, and describe places.
17:34
And people and all the knowledge representations and properties of the model of that represent all these people and get to a place where, you know, my my discussion involved of all these concepts is something that and something that is resonating with the other person in a sense that I can that
18:12
So it's always like a human, like, things like I'm interacting with the human being, or with the conscious entity in some way, I guess, you know, I guess in the case of, in the case of animals people sometimes feel like their dogs are conscious or their cats or conscious.
18:29
And, and so the, any animal can't obviously, like, give you a complex response and transform words into other words. And in, as far as reading the mind of an animal, there's there's animal can make sounds, and I'm gonna make movements. And and so there's a combination of nonverbal and and I communication, but also audit work communication with the but I think it is.
19:02
It is very interesting that animals do take turns communicating that that cats. Like when you communicate with it with a cat you you can make very sounds and a cat will respond to some of your sounds and cats. You sounds to communicate with one another and so there's like a hissing sound, which means the cat is not happy and so you can make inferences.
19:39
We'll well, it's not happy about what or whatever is an association spatially or temporarily with that. Hissing sound, you know, like, oh, there's a raccoon in the window. Okay. Cats. Hissing. They get like telling that other animal to get get away or something or letting the rest of us know that there's that.
20:01
There's a raccoon in the window.
20:05
So the cat so that so animals are communicating, but then, you know, you can talk to an animal but the animal is really, is really able to take turns listening to what your expression is. And it's animals seem to stop and consider, even even birds, birds will. I've seen birds.
20:30
They they they look around and they consider the movements of people and bicyclists in cars and they they're like listening and watching with their eyes and ears for, you know, like like like self-driving car. The bird has to predict where it can fly and where it can't fly. So, it has to predict the landscape and has to predict the momentum and orientation and direction, and the velocity of everything, every object in the city, that's around that bird.
21:16
Otherwise it might get hit by a bicycle or get hit by a car or get hit or get eaten by by a larger bird or, you know, who knows what. But but it is that's the key. Is that is that there is a sort of I don't want to say handshake but it's sort of exchange and the exchanges between humans and animals.
21:47
They have, there's exchange rates, temporal exchange rates, like the rates and which I'm going to listen for about this long. Before I talk, I'm going to observe for about this long before I do, and this sort of external communication between Between animals between persons. I also happen. It also happens inside your brain where you have basically network, so of cells that are chatting which means that some of them are sending messages while others are listening and then the ones that were that that sent messages become inhibited for a while.
22:41
So and while a different set of neurons is going to fire based upon with a listen to and and while and wow that's happening there's another set of neurons that's listening to those neurons and those neurons when it's their turn to fire maybe the first set of neurons is ready again?
23:09
And so this is yeah. This is like the three sets of neurons small. Like imagine you had just to oversimplify it, imagine that you had the entire view. Want what is going to respond at once and it's going to respond by some of the neurons getting excited and some of them being inhibited and some of them remaining and in tonic oscillation.
23:42
Most of them remaining anatomic oscillation. Okay. And then so then you have to be too and the V2 is listening to the B1. And so now in the V2 you're going to have the neurons that were listening which is, you know, all of them you're going to have a situation where some of them get excited and some of them getting inhibited.
24:08
And this this is a reflection of the patterns that they that they need to was observing, but it's a transmission reflection. So the transmission is the reflection, the reflection. It now, I guess necessary is going to keep going up the hierarchy but some signals. Also travel backwards downwards, they travel in three different directions, you know, it's it's and well, six different directions.
24:40
It signaled travel up and in terminal down. They trim left to the trouble. Right. And they travel forwards and backwards, right? They spread out really they shoot back down the first layer. Shoot up to v4 issued to the to another brain region, the parietal cortex and the and the and the shoot to the temporal cortex, which is the reality for a cortex.
25:13
And some of the pride of this medicine for cortex, eventually to the free profit quartet and and so there's gonna be, I mean, you can say, well yeah, there is a higher sequence and we're gonna see, I think perhaps we're gonna see that, the biggest ways of activating, moving enough, hierarchy from the incoming stems of cortex, but but not.
25:41
But I think we don't know exactly how the brain is is network together. How exactly, like how exactly the connection, but what was really interesting is that the rent, the idea of, you know, from networks of the brand can work up or lost spawns and and others. And in terms of like applying graph theories and neurons.
26:11
It's it's like if if it is the case that any signal that goes to any neuron that is basically in an initially in a state of like having random connection to the neurons, it is just a few short steps away from reaching any of the neuron. Like I don't know if it's like if a neuron is two steps or three steps, or five steps or six steps away from reaching any other neuron.
26:38
But it's, it's in, it's, it's, it's one of the things about a mass of about a massively connected graph, randomly connected graph, that, that means that, you know, his heart. It's, it's, it's trying to say that things happen, you know, simply like from like the V1 cortex fires and then, and that talks and B2 listens and then B4, listens to that like that, you know, that is a massive oversimplification because it it's that the pattern or direction could be any because.
27:29
Yeah, the whole can I guess, I guess, I don't know. Like I said, I don't know. So this would be something for researchers to to chart in some cases. People. There's there. People have much better answers than I do. I've been studying this a lot longer in terms of the connect term, but there's still like even this year and 2021 there's still amazing discoveries and neuroscience.
27:54
Okay, this has been an incredible year for innovations in our science research for progressing percentages. There's so much being. It's been discovered in just this year and I expect that that's gonna continue for a long time. I don't know how long, exactly because because we may get surprised. I think we will.
28:19
I think, I mean, collectively human beings may feel very surprised by the innovative ways in which creative minds managed to automate the scientific process with especially with technology called deep learning. But also now, with self-aware networks and I think so for networks will prove critical for self-driving cars and for automated home robots.
28:57
Yeah. So artificial. Artificial contestants. Yeah.