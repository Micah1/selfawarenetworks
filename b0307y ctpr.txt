b0307y ctpr
Synaptic Unreliability Neocortex Machines Brain
00:07
Mhm. Resume pause and resume other time. Okay, that's fine. So. But so what do you think so far about about?
00:54
Oh.
01:06
Right, right, right? So so I guess um, you're right those are two different two to very different things. So the main body of the book is in neuroscience and writing about different research that has been done and linking together ideas that people are perhaps not yet linking together in a public way, maybe they might be linking them together privately but I want to show basically a, Science-based neurology-based map of existing research, but combining some together some novel ideas in order to.
01:46
To to say that basically the the research that we need to say what human consciousness is had, you know with what to have our basically our thought workspace, you know, that that renders are that renders our environment to us to that renders us to and within our brains that basically creates a representation of of you within you and your environment within you and your mind and and and so on.
02:13
And I want to say that that research has like, you know, we're at a place where we can begin to talk about that in extreme detail and begin. To plan out machines artificial machines that can replicate that process. Alright with great detail and and then this sort of like the second part which I started to go into which really is a second part is about it exploring basically what's what's going what's going really wrong with with deep learning in terms of where where.
02:44
It's not doing it's not coming close yet to what needs to be done and then exploring the kinds of things that we would need to see in machine learning in order to. Basically be able for for for a computer to have the kinds of capability that that our brains have and so that is like in a sense the second book is like taking the lessons from neuroscience and then applying them to computation to computer science to say okay, well here's what we're here's what's happening in the brain and here's what's happening in deep learning and here's what's happening in, you know, all these other kinds of machine learning programs and here's here's what we could do that would sort of change things like the like the, The so right these are two different stories but it's like saying okay, well how can I how can I understand the the computational aspect of of of cognitive neurology cognitive psychology cognitive of cognition right the computational aspect of it and then how can I replicate it mechanically so I I'm I'm in the those two so this isn't the style of like a book like like on intelligence by Jeff Hawkins, for example where he basically did.
04:04
Something similar where he was talking about how his idea of what the neocortex was doing about the mechanical process of what it was doing and then he was he was trying to design he was trying to say okay, well we can make him change machine that follows these steps that does with the neocortex is doing artificially.
04:25
And I I'm I'm so that is a certain that's like a book style I think to to where I'm going to be talking about with the brain does but like the whole brain not just the neocortex so the neocortex included but basically near neocortexist is the most it's it's it's the top two-thirds of the of the brain it's it's the biggest part of the human brain but it is like but my the theory that I have is about explaining the whole brain right it's so I that's what I'm aiming to do is.
05:00
Explain the entire human brain and also to talk about creating a mechanical simulation of the entire human brain so that we can have basically artificial sentient machines that that could that could be like human beings and it's sort of it's a vast departure so down to like even even to the you know in deep learning they have this thing it's called the perceptron which is the art the the concept of the artificial neural network, which was I think discovered in like this I think mapped out in like 1957 based upon a misconception.
05:35
Of the of of basically of how neurons work and in the big misconception continues to this day because there's still like this sort of like assumption that that you can even like if you take a class in you know, computational neuroscience 101. One of the first things they tell you is okay, we're gonna just basically sum up the the action potential of a neuron as a one or a zero and and in deep learning they go beyond that it's a one or zero plus like a it's like you get a vector which can can be like the the amplitude above between zero and one so it so it's either on or off plus there's a vector which indicates that the the amplitude could be greater or less or less than zero by up it as high as one and so there's some variability in like the amount of information.
06:31
The amount of information that one neuron can pass along and to the rest of the network but but and so the the whole the whole thing is like everything in deep learning and deep learning is like reduce to you know, you have this network but it only is processing frequency information for the most part it's not processing spatial information and when when you can if you could, Wait, like we can say like now with the latest research that has been that this the perceptron is basically invalid it's based upon this this space upon.
07:10
I wrote it. I wrote an article about this x emulator but it's it's um, it's based upon. So the reality is that that neurons they have.
07:24
Okay.
07:28
Yep, okay.
Transcribed by Pixel

Audio