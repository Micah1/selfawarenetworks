b0303y

(all the audio notes (like b0000y) need to be fixed (neural network based transcription))

Neuralink talk Technology Ethics Brain

00:00


Means is that if we're decoding the the visual cortex or the audio cortex or the you know, the visual cortex from the audio cortex or vice versa or this matter sensory cortex or the prefrontal cortex, whatever part of the brain we're decoding we can get information from any other part of the brain and we can we'll be able to basically listen to your thoughts and and to to download what you're seeing and download what you're hearing into the computer and reconstruct them in the computer so that it's like, It's like then your brain is like an open book like a hard drive that we can just access and that has profound implications in the long run so that's like maybe what is the ethical what is that what is a European legal system going to do then right and the other thing is that neural link is going to be mass-produced technology will be everywhere that means that you know, the European legal system can pass laws about it, but it will beat this this device would be everywhere so so what are other countries going to do with it and what are people who just decide they don't need to.

01:10

While it follow the European laws do even people in Europe. I mean, this is like this technology is potentially more dangerous than a gun it's the the the it's it's definitely um a new world.

01:31

What way do you think it's going to be? Because.

01:42

Actually so I don't think it can be stopped actually the reason it says that what's going to ultimate what drives the advancement of medical technologies is is pain human pain, so for example, you know, a lot of people have mental mental injuries and they they're paying to the health care system they want relief from their symptoms and they're willing to pay for it, in fact the medical system is huge in the US, it's a huge huge problem is is is people in your.

02:17

Know it's and and there's you know, there's huge there's huge desire around the world for relief from pain and in treatment for medicine and medicine that's more effective cost effective everywhere in the world people need better medicine and we need innovations in medicine and that can and so neuralink along with other medical imaging technologies basically are being pulled forth into existence by the money that is summoned by a human pain and because of that there's no no law that can stop it.

02:54

Maybe I can ask.

03:00

Their little something happened or they'll be developed like let's say to class society these ones who have the money and this one full. Can't pay it. Well I mean, so that's that's like a market economics just market discussion. I mean, I think that you know that there's always examples of people trying to control the supply of a product to jack up the prices in and get as much money as they can and those people will try to do that.

03:32

But at the same time what we're talking about here is it's not that you can it's not like the things that are possible in airlink now you can do them like any any sufficiently skilled neuroscience neuroscientists could. Sufficiently knowledgeable and and skilled neuroscientists could do these already without a neural link device but in theory but but the neural length devices like the latest and greatest and they don't it will be duplicated and other countries.

04:03

I think there'll be like the Chinese version of Neuralink, I'm sure but the but the thing is like yeah, so if you can if you can make something cheap enough and you can make it economical and that that's what we're talking about. It's not just an early by the way.

04:17

There's there's many other brain computer interface technologies that are being developed in parallel to neural link by other. Good companies that I know about. And these technologies will become cheap and economical and mass-produced and shipped everywhere in the world. Just because they're needed and because they're they're they're going to be mass produced and so that for price for for money.

04:45

Thanks maker. Thank you at least go ahead and then we might try and move across the stage and get it everyone's perspective before we sort of open up popcorn style fully thank you making there was a very good introduction into where the text sitting at so please go ahead and then we might have to miss you.

05:03

Okay, I would what immediately I mean, what what the game think is that if you put a electrode in the pleasure center of a wrap it will spend all day pressing that lever and equally painkillers. Such as obstacles states tramadol UK. People do quite right? People want really from their pain and this is the root to drug addiction and with it comes in inverted commerce is some kind of enslavement.

05:34

So that I think is a real ethical danger is that if you enable people to have implants or even external paths of advice that simply gives them pleasure for no work or anything like that. You it's a great. Way to enslave the human race. So, I think you raise that just coming back on that point, okay?

06:00

I think the deep that's the yeah at an important ethical issue. I think we'll get into that in quite a bit of detail. I think Elon himself said a famously in one interview that he thought he thought that we were on the precipice of being able to create virtual realities that would be totally addictive and have people prefer to exist inside them than outside them and then when quizzed on it in one of my favourite quotes said, well wouldn't it be hubris fast humans to consider that it hasn't already be done be done and perhaps we already.

06:40

Exist inside the simulation which is sort of an irony when you think that he's now leading the way with the brain computer interface with a view of effectively removing pain and creating the same outcome and the same drive and as you said is that an extreme enslavement do you really want to be living inside the simulation that's inside the simulation.

07:06

I guess is a is a sort of almost philosophical question about site about this technology because you know, if, I don't think that we are but certainly there's a perspective that says it's this that's the case we're inside a very sophisticated one probably not the first release do you want to jump into the first release of the of the lower quality newly developed you know, for those of you who've seen inception it's almost like the the the human interface version of inception anyway, there's a little there's a little science fiction aside to to to this and micro.

07:48

I think we'll definitely. Come back for your opinion on number of points, but I just want to make sure we move through the through the room so let me show you being very patient if you would like to share with us your your introduction and your views and and we'll move through everyone else on the stage and then we'll get into a roundtable conversation.

08:07

The subject was very interesting just one of the number of projects and programs in this field a lot of amazing and the main purpose of the life of technologies to increase artificial CEO where to another just instrument. Is made of this guideline IT technology, but the technology is to build any kind that could be biological adjacent could be just no power and other knowledge it's just an instrument what concerns basically and influence each other and the datings in general the first is the technological integrity of technology and the way we developed the level of how efficient they could interact with the brain.

09:17

I'll put here the people will bring the promised results to people to decrease pain to increase efficiency of the brains where it also could be difficult problem because you will enjoy easily if it is easier to implement with the brains that puts bring some some problems if the technology is not sufficient that's not quite the ones in the first question the second question is biological, however a human body biological body should not reject the, Interpretation.

09:52

Technology.

10:03

Is not that clear if you are not sure if you're on the road or you can get a bit closer to your microphone.

10:19

I will try to switch off microphones. Thank.

10:32

Is it just me or just me or I think I can't hear you yeah okay we might come back to me sure and keep me excuse me, yes hi okay and this one the main question when we resolved technological problems and biological ethics what concern this exercise was technology since when do you remember the ancient?

10:58

Greek myth about when the discussion made the sculpture of lady and was being. Came alive after the goddess. I became a survivor and it was he played by Verna's display volume. I suppose they might difference between artificial intelligence and human beings is a kind of exaggerated the mighty information we could put into robots and the deficient and changes will be stabilized us and this teammate could be used to robots it's like just creatinous motors to distract and so on the human beings you can make robot.

11:42

Emissions similar to human beings. And the danger is extrated.

11:51

Yes, I think this is the hybrid technology between what's happening robotics and I and biology and the integration of the two that certainly the territory that we're that we find ourselves in thanks for sure we will hear more I'm sure as we get into the round table but I so if you'd like to tell us a little bit about yourself and your view on the ethics of neural link and and any related views that you have.

12:22

Hi David thank you so much yes, thank you so much for the space it's been really interesting. So far so my background when it comes to. Subjects that relate to your link is very limited. But I guess I am.

12:44

With I guess how. Ruling and as it's widely adopted how will that change? I guess a foreign policy.

13:07

Um,

13:30

Well if anyone's got a burning response to that let's let's have a look at it now but otherwise. I think you're right we will definitely get into that part of the conversation. Next do. We about yourself and your perspective. Yeah, I'm. Just such a. Profields and it was who can look at my buyer.

14:01

Be big as it was the kind of the slippery slope that we are potentially on. I think he's right very likely on. I would the funny dystopian future in in these terms. I think there's a. 50-50 chance at least that we are headed for some awful kinetic conflict at some point given the rapid increase of the power of technology and it's democratization across.

14:44

Nutrients actors have all sorts and in that sense there may be a greater danger to humanity which is posed by us being conflict over resources and land territory and so forth the one thing about a simulated reality or unreality if you like is that as long as you have hardware there's nothing really to fight over you you might think that you can think of the problem in this way when there's a, Senatoration between human beings ability to Marshall the forces of the material world which increases and is increasing at such a rapid pace and leaving behind our ability to understand and solve ethics deal with the your potentially annihilating aspects of our nature and in some sense placing us in a sandbox where the damage that we did with virtual where the you know, yeah, you could.

15:54

Always. We set a quote unquote the sandbox. Maybe the only option that we have not to wipe ourselves out. That comes of course with you know, I've kind of just like lost over a world of complexity there, but if you if you would all buy the notion that the fact that we are divided into different nations and we're the moment in history where we have the rise of you know, one potential superpower overtaking another or even just a standoff between two potential technological superpowers who?

16:29

Are armed with other children intelligence and you know synthetic biology and so on that not having to fight over resources and land and have conflicts of the over the traditional sort not having to they yeah have the you know, the notion of like ghettos and more desirable parts of cities and all the things which have vitiated societies at the level of just nations, but also between nation states that there is in that dystopian.

17:04

I, Dea but potentially the only salvation or hope that human standard as a species, so while I agree with everything that Micah said instead of very very well. I thought and posing the other end of the spectrum of darkness have been sound as perhaps the sunny option if we get up right?

17:26

Yeah, we're in interesting times as the as the saying goes and it's you know, we've evolved you know, according to one world one view that to maximize our survivability and compete not just among ourselves but in the environment that we're in for resources and AI computer brain interfaces the technology that we developing as sort of the ultimate expression of that so it would be nice to think it leads to some sort of.

18:03

Utopian future, but as a couple of speakers have said it's going to come down to the countries the corporations the people that can afford the technology for embedded competitive advantage both against the environment, which is I guess the shared human condition but also against each other which is what you look at when you look at its application for to the the the military industrial complex and and state-based competition for for control, so we're and I think it was making.

18:36

That said, you know other people might be flowing good for the EU to do some virtue signaling around AI legislation but it won't stop corporations or other countries or other people from developing technology, whether it's inside or outside of that legislative framework, but if our. If our pain centers the thing physically stop us from doing things and if that can be adjusted by these interfaces and drugs and remove that then I guess the only other resistance we have assumes rather than our physical impulses of pain are our ethical standing and value sets, so if you can use a human computer interface to adjust values and change memories, they're not only can you remove pain but you can remove other layers of objection to behaviors and that.

19:32

That as you're saying dexter could lead to a pretty scary future even the utopian version has it's a as it's issues so thank you thank you for that. I think we'll pick all of that up when we get into round table Melissa, I think you're the last on stage for the moment so if you'd like to I give us a bit of an introduction and and your perspective and once again, I divide anyone in the audience to put their hand up we'll bring you up first and comments before we move into roundtable popcorn style room Melissa over to you.

20:05

Thank you David I'm just interested in the perspective of pain and how that interferes with people's lives having been someone who suffered pain for the last nearly nine years. I think people are still suffering pain at the moment it's about whether or not we're doing interfaces with our bodies at the moment that I think if we can do the better.

20:23

I think we should and I think that development's along these lines of fantastic. I think there's some differences we need to learn in language between people relieving pain and then confusing that with being addicted to painkillers. On there's two different worlds there, but definitely being able to understand our nervous system better next interactions and just what I've learned even in the last four months to understand my pain better.

20:51

I wish I knew before but would have been amazing if people could have managed pain but it would have been able to get on with people's lives better think one in five something from pain and I think developments in this area, you know, I'm looking forward to.

21:11

So thank you sir yeah great and there's somebody else who wants to join. So.

21:24

Hello welcome today. So it's your future to point welcome to lots of rooms as always nice to hear your perspective and I think I'm a very appropriate name given the the topic of this room so happy to hear your perspective. Yeah. I love thinking about neural Lincoln. Of it all and where it can go we've had some really interesting.

21:55

And about if over time value clubhouse work. Things that. Your eyes for. Youth ethical thing. This ability. To. You know inhibit neurons that. You know with think about the the future or the past. Meaning, you know, some people. Spent talked about how you could tune it to. You know about to you know, remove certain thoughts and you could also think of that as as a way everything about past what?

22:43

We could also say well I don't want to think about the future too much and if I if I get into those types of things you can. Prove, maybe possible. Theoretically tune it to. People the moment um, which you know might be bad being too much in the moment, um, and because I think you can get into it a loop there so I think there's ethical things but also safety concerns with it but so many interesting interesting applications of the technology and theory so anyway.

23:20

I'm just excited to be in the room everybody's amazing ideas, so thank you. Thank you future What we we might move into a sort of a round table and once we've heard from Ben I think you know, we've spoken a little bit about body rejection and some of the sort of in the moment issues that are connected to newer link and brain computer interfaces, but while we hear from Ben it what I'd like to post to the room is considered the impact on your personal progression around things like your plasticity and what might happen if you interfere with the brains in a workings in ways that we don't fully understand and you can extrapolate that even more broadly to what might.

24:02

Happen in terms of ongoing evolution, you know what we experience and what happens creates changes in our DNA we turn we turn markers on and off we pass those down through the generations. If we effectively stall our our development progression because we we interfere with that are we willing to play the the gamble with the long sweep of that progression?

24:27

I think the the risks are the risks are not just in the current moment and the current time that there are they extending. Just us and our current individuality and spacing in the environment. So, I'd like to hear people's views on that once again. Discussion, but I want to hand over to Ben and then to fall for an introduction and their perspective before.

24:55

I've been a few.

25:03

About the existential. Biologically. I think one of the most encouraging developments of AI that I've been paying attention to is in. Certainly relevant now with pandemic is virtually. And. Be certainly the ability of neural link to adapt and. Be able to provide the perfect companionship seems vastly, you know possible that that would be in the place to pick the exact voice tone that we wanted to hear to provide a face that exactly maps on.

25:44

Would be our most desirable face. And create a situation of. Compatibility that. Maybe isn't biologically. Maybe even set up. A build child syndrome right to where of the our ability to adapt.

26:07

The desire to adapt in the real world might be reduced as the existential dilemma of. Companionship.

26:19

Overall. Big big picture ideas for the human race. Certainly when you look at your pain and. Even just professional. With every production is a threat.

26:41

Not perfection for others and. Just like a relief. The. The bad cases of human companionship and failed relationships. And whatnot. To me, that's kind of. Scary dystopian future. I guess that. Capacity to become addicted and escape. And with something like that that we can so easily adapt to exactly the novelty that we need at the moment.

27:15

With the words whatever we need the. Trick our brain into thinking. Satisfied.

27:40

Having me up to be here. I think this is a really exciting important topic and I think cuz I think I sort of brought me up was the. Comments today was making around in a sort of our existential evolutionary. Confession of the conversation several times, so today. I'm always struck by sort of a and implicit.

28:11

Biased or. Are current stateless being sort of a protected state. You know, I feel like. We are journey of which this is just one particular state and that the you know, what we talk about the existential threat to humanity do we mean the the terminus of that of that journey or do we mean just transition to a new a new state, you know, we've been in the state, you know, I'm a rectus sitting around anymore, you know, and almost say you won't be around anymore.

28:50

As well. And it seems that armor a lot of our journey involves the interaction with tools, right? So with the people that's back far, I think the natural condition is to move past our current state of quote-unquote humanity and to move something else now there are lots of scenarios of good and bad.

29:18

So, I think it's really excellent important to reflect on those. I'm not rejecting any of that reflection. But I am sort of one through reject the sort of the fuck the underlying hypothesis that transition into a new state somehow unnatural or unwanted or you know, something. Is the journey that we're on.

29:41

Thank you to me.

29:47

If nobody wants to jump into that we have.

29:54

Free stage, it's first.

29:58

Then Kelly. So welcome at. Hi, thank you so much for bringing me up. This is such an interesting topic and I just wanted to continue. So I have anxiety and you know what this normally link. I think that like ones application could easily be to really treat people like anxiety or depression easily but one thing that's struck my mind.

30:31

I think Ben was trying to touch on this. Is like should we? Are we interrupting like the human experience and like the human cautiousness and like.

30:48

We really can. Still. Get ah situation. If you kind of like turned the human experience and consciousness into something that could be like capitalized on or like sold or. You know, some kind of technology like that.

31:18

So is there anybody who wants to respond to this question?

31:25

If you think of technology to be capitalized on I think this is the way how we measure the value of any technology. So basically, there's an ocean like. And in here we touch basically the boundaries between ethics and economics because antics is something that. Is very. Qualitative and it's hard and hard to be measured and once you be able to measure any certain value, this is the point where it can turn.

32:05

Algorithmically. Produce.

32:11

I'm not sure if I'm answering your question but basically. The the point of innovation it's is to turn something that important for people into some measurable metrics that can be actually exchange and monetized on fair basis between different humans. That makes sense. Yeah, it does. I see where.

32:44

And the other difference. And like,

32:56

And the way we think about life is getting really. I guess to select the abstract. I like personally think that like progression is good, but like we've already seen that like we have lost our humanity a little bit and social media and like how.

33:20

I think so, my mention is earlier. I. Can more like about personal opinion. We're just entering more and more into like this. Brave New World like. Everything can be. Better kind of like I guess everything that's wrong with. Things with.

33:46

Only as for a quick room reset if that's possible because I'm gonna a couple of people dumping out from the other large rooms and that are now finishing and it'll be great to those sort.

34:02

Of ideas.

34:06

So perfect time for another room race it is just the digital humanist club. We were a club. The basis of the human. Were written in. His read 1973 and 2003 and then got the the research of global research organisation in 20. Inspiration. At the apex of our own developed.

34:34

Technology and what that means is applying the algorithm. And not enslaving abusing or unmanned fairly manipulating suit of technology pretty big difficult times, so that's the nature of the the club this room we've just spoken about newer linking classrooms in harsh weeks this this time is the normal week the time that we we've had meetings or rooms.

35:03

I should say I'm to use the clubhouse language. This week was to discuss neural link brain computer interfaces the merge between AI technology in plants and biology, especially in relation to our I guess the seed of our consciousness and intelligence in our in brains and we've been hearing about people's views on the related issues make has been works in the field and has gave us some update on the state of play of the technology we've heard a little bit from.

35:41

A designers medical professionals. Peter software developers and Paul as in the gaming spaces and everyone sort of crosses over into some of those areas as well, we basically almost moved through their speakers on the stage in terms of a little bit of introduction and personal perspective and once we've heard from the last few which is furthest came and Patrick Cowell ever and Misha I think actually I think we should we've heard from this rejoined.

36:16

Refreshed then we were just going to spend some time. On style discussing related issues, so as you would expect on a topic like this we've had perspectives that cover everything from positive support of exactly what Elon Musking drilling to doing to a more conservative or cautious approach about what it means for potential and more dystopian future for the room at the moment and Carl I will hear from you shortly, but I think next in PTR order is so.

36:57

Furthest and apologies. I know we were in a room together just before and my name pronunciation is not the best, so maybe even correctly. No. I think to correct. So I start with the the group topic and the first word ethics. So, I think ethics is not time invariant.

37:23

So we can argue what's good or bad from our perspective in the time we are in but eventually I think that is going to change and I don't know how so let me not comment on that but let me go back in history and it's let me think of a case where an example from let's say the manhattan project where we created the atom bombs and after the detonation we were well aware of the implication the destruction it can cause.

37:58

And it did not stop us from making more apple bombs or hydrogen bombs or nuclear bombs, right? So the technology is there and it's I think whatever happens with it could or bad it's independent of the technology itself. It's how we as human. Use that technology, right? So I'm thinking because we will think you can have us a lot of.

38:25

Negative connotation attached to it how you humans will evolve how it might impact our thought process how much of a control we might be giving up. My pessimistic view is as much as we could as long as it incentivizes through personal gains, right and going back to the the club.

38:52

I see it says a responsibility to lead ethical lives of personal foods within that asperg to greater good of humanity, but so when I think of good of humanity, I'm thinking maybe survival of the human species. It's probably necessary because if we don't exist I mean, there's everything good or bad that protects us without us, right?

39:16

So that's where I struggle up with it. So I think in general we typically place ourselves mentioned. I am probably even evolution and your link will take us to a different path and even if I go to homotors or homo sapiens in general, I don't have the exact members but I think humans in general have been.

39:39

On the planet for five to seven million years and this may leave some bounds and technology. And then I think of I was in another room. Saying the same thing, right? And they have done anything different for the last two hundred and fifty million years for which they have existed and they're still existing without doing anything much for two hundred twenty fifty million or some I don't foresee a perceive us existing.

40:12

For two hundred twenty fifty million years. It's almost self-destructive in nature and I don't know if it's above or intelligence or it's a feature of her intelligence, that's. Kind of pushing it as to ourselves that I know it's a very pessimistic view. So that's one aspect. I see the other aspect I see is whether when I mentioned survival of the human species.

40:35

The grammar aspect is survival of the self again here. I don't know if survival of the cells is conflicting to the idea of the survival of the human species, right? So I'm thinking because of these huge it ionizing your link has not as a gradual improvement but as discrete jump in our consciousness or where we go and.

41:03

I think there would be bad actors in that would not only that would I think increase these chances that some things worse will happen and I think we won't be doing anything about it. So, that's my Christmas review and that's taking thank you. I've always been up again styled.

41:28

I don't know anything that it's not a linear function, you know, it's some point this world whether we caused it or not was used to be inhabitable and so those cockroaches will lose even though they survived. So technology is our only savior for getting off this rock. At some point disrupt this rockabitable and is this if we want the ice to exist.

42:04

We have to keep going forward. There's no way to stay static or go back and survive on the master time scales. I think then I think you know here Shango was whatever 76 years, okay. And opened the eyes of humanity to the level of destruction. It's interesting the three generations on you know, a number of people in the room have spoken about AI as potentially even more.

42:38

Dangerous and you know flip side two sides of the same coin beneficial technology, it'll be interesting to see what the outcomes are and then like as you were saying our handling of nuclear technology, whether we're able to position the survival of the human race and our collective benefit ahead of self-interest.

42:58

I mean, I think that's almost the definitional territory of ethics. So, I think we'll get more into that once we're getting to popcorn style, but Kailyn if you'd like to tell us a bit about yourself and you're perspective and Then we'll just finish up the rest of the room.

43:17

Great, thank you. David and thank you to all the moderators and the club for holding this face on this room. I've enjoyed the conversation up till now. So, It's interesting when we talk about the ethics of neural like I think that one thing that we need to keep in mind is the utility of the neural link and exactly what is going to affect on a macro scale.

43:41

When we look at humans across centuries, we're motivated it's it's quite interesting we we tend to lose not necessarily lose our ethics but our ethics tend to go from. Attic motion to being very fluid if something becomes. Convenient for something is the better if we notice something better mental all of humanity, or at least most of humanity or maybe most of some group case in point today's day and age.

44:11

We have never throughout humanity that we had a period in time where people are willingly giving up more data at a rate faster than we've ever seen before across all times of humanity just because they can get something such as a package delivered to their house front of the via Amazon in two days and they don't have to say get in their car and drive to the store or wait and extend their period of time as they used to with the other services eBay and things along those lines.

44:45

So, With neural link I think that if it were to affect humanity in a positive way, which I do believe that it will especially on a microscale and it and if somebody such as neuro link that will pop up eventually they'll create their own versions of it and you know remodel of it and take on certain areas of the brain or other parts of the body such as you know, the ears you guys things along those lines to restore functions that maybe we lost or enhance functions that we already have make someone who can already see in 2020 vision to see even better than.

45:21

Before something along those lines. I think that we'll just see something similar. I think that eventually society might ease up it'll be a gradual of easing into the neural link technology tutorial just become a norm, of course there are implications with AI and neural links such as things that can not easily.

45:44

Fun things that can backfire but that's what everything. That again, I don't see neural link. I don't see society or particularly the individuals leave the average individuals to be a bad one, especially when it comes to ethics and privacy because again we're more than willing to give up certain amount of privacy just for better services better products or even a better life than this instance when we talk about neural link and again the things that they plan on tackling so.

46:18

Maybe when we talk about ethics I think that we might need to. View the world from me 10,000 foot point of view and realize that we've gradually been giving up certain ethics or at least letting those ethics slipped through the cracks through other companies and government control and things along those lines.

46:41

Know that if we get if we. Loosen up on our head they felt to say that we'll receive something better overall, so that's just what I have to say and thank you for allowing me to speak. I thank you Caitlin. I'm yes, I think having a top level perspective on this is can be difficult and certainly that's that's a view when we're talking about the evolution of technology occurring far faster than the evolution of biology, we're in a race here we're we're technology is just on such a speaker curve that this intersection is incredibly interesting and very hard for us.

47:27

I guess to look at it in the longer time frame even though that's what? We're trying to do it's hard enough to predict where this technology is going to be in 10 years let alone where it's going to be in a hundred or a thousand but thanks for that perspective.

47:41

Patrick if you'd like to share with us a little bit about yourself.

48:09

Just let me just rest on this when I watch the.

48:18

Big that we had the implant for the door link and how the cake got it if anybody watch this wouldn't cooperate and come out of its paddock and how they were reading the data from the big and. They gave the big a nice name and all this but the frustration of having it live stream to the world and not actually cooperating but I kind of.

48:52

Thought that was interesting but shut when they started to read the data off of the lake movements and how many wavelengths of information they were able to read and how it applies to. Improving the health of people that had different ailments for they had.

49:25

Some kind of you know different different spinal cord injuries and how that might of install were a bit in one of the little small steps before, you know, I thought that was interesting but. What it really struck me was when the door length team was introduced and how was cross.

49:53

Ed a lot of disciplines and how they Elon Musk's team for norlake was just the best of them in the brightest minds who were working on very small segments of this and trying you know, the neuroscience and then the the engineering the material science and then the physicists and all you know, in another room someone had talked about having a Manhattan project, you know, trying to understand.

50:28

And trying to accelerate our understanding of the human mind and you know, I I kind of like it into the early the early 90s of the internet and how door links and and other brain waves. Mapping you know, FMRIS the over with the electrocardium of brain some other neuroscience because to speak more accurately to it, but putting all these things together and reading the science of our brain the human brains that feeding it back to us saying hey, you know.

51:18

You're really not you're really not optimizing your brain function right now and feeling it back to the a person real time so they can either self-correct or they can get some medication that optimizes their function or you need to drink good a cup of coffee right now so that you cannot be the best for your next meeting.

51:44

I don't know it's just, It neural link and the future the ethical concerns are are large that's true but the future of understanding and and optimizing our brain function it's it's really a very interesting thing that an interesting. Standpoint and when you start talking about AI, I think AI is trying to understand the world and build a world but understanding the brain and.

52:30

The human brain and trying to augment it yeah there's there's a lot of different things but I try to wrap my head around the future. And where this is taking us and. Really you know, how do we link to machines without having wires, you know, and and how do we link to the internet without you know, overwhelming our brains, how do we how do we take what what is what is important and and get rid of all the other noise?

53:11

It would be nice if you get noise cancel a lot of the.

53:18

Yeah, thanks Patrick, I think you um breaking up a little bit there, but I think we've got the the gist of the point and I think it is a interesting area some might say that we have already overwhelmed our brains without connection to the internet. I certainly feel like that at times when I get into when I realize how long I've spent on clubhouse, so if I was connected through a human neural interface to to the internet and to all of you guys in clubhouse directly, I can come yes overwhelming.

53:49

Be part of it but I think you painted a picture that a lot of us think it's very hard to forecast where this is all edited and newer link themselves are making fairly limited claims about dealing with things like spinal damage effectively reading signals and then applying them back into systems that support conditions where people being affected by either accidents or genetic conditions, but they do have a stated aim of progressing beyond that to augmentation for people who are otherwise healthy and I think that's there's ethics at every level along that some that roadways.

54:24

I think Patrick. Leave contribution will come back popcorn style and apps you're a little bit clearer, but cow over to you love to hear a little bit about your perspective on topic of the room. Yeah, thank you thank you for hosting a another fantastic room the mods I can see here always seem to be at the forefront of all the best conversations on on club houses wonderful.

54:50

I kind of a kind of share all of the worries that have been discussed in many of the the the both the AI and brain interface rooms that pop up on Clubhouse, but I kind of want to put a different perspective on this is that. I understand the worries of integration.

55:14

I understand that the concerns of lack of privacy and addiction and losing ourselves and losing society at my huge advocate for mindfulness and meditation slowing down society, but I think it's all kind of a mood to point because it's it's gonna happen irrelevant this it this technological shift with integrating ourselves into the digital world whether by a neural link or some other, Company is kind of inevitable it's going to happen and I see a lot of conversations that.

55:53

The revolve around whether we should or shouldn't and the problem with those is when when you're having those conversations when you're having sort of those polarizing conversations you're saying well it definitely shouldn't have what we should never definitely never do it and then the other party is saying no we definitely should you you're not actually talking about the thing that really matters which is how do we do it properly because it is going to happen there's too many financial incentives throat to happen there's too many societal incentives for it to happen even if I think one of the speakers before me who wouldn't catch the name and help the point that even if Even if it is banned even if regulation and either on on a state level or a global level bands it other research will still continue like interfacing with the eyeshadow blindness blindness how you play a cure deafness and those kind of research that kind of research operates on the same level that neural link operates on so it's not like all research on how to interface into the brain will stop and will be protected from that kind of technological advancement it's going to still happen, so it's not something that we can avoid at all.

57:03

Absolutely will happen and I think conversations. I think we'd be we'd be able to have much more productive conversations if we sort of just said okay, there's definite dangers with this but everybody understands that it is absolutely going to happen at some point, how do we do this properly and you know to combat the, The the cons of it you know that there's a lot of ways that it could go wrong there's a lot of ways that we could lose ourselves but there's also a lot of ways, you know that it that it could help you it can easily aid things like helping people judge misinformation and I'm talking about going further down the line of when we actually have sought commercially viable options for for having a neural inside, you know, like a patch on the back of the the head be on the air that kind of thing it can help through things like dietary and and habitual feedback, you know, it can it can help with things like addiction management.


57:59

And you know how you're the things that you're consuming online and that's sort of a and also another thing that's kind of gonna happen irrelevant of whether we wanted to or not is is AI and I think there's a lot of talk about the seniority and how AI will get to a point where AI completely outpaces and the only way the only way that we can remain relevant in a world like that is by enhancing our own cognitive functions and and evolution doesn't operate on a fast enough scale to keep up with the changes that AI is going to bring so like these two things are going to happen.

58:34


Irrelevant and we kind of have to make the decision of whether we want to whether we want to embrace it and talk about instead doing it the right way and doing it in the most optimal way of protecting ourselves and ethically and societally and all whether we just sort of want to want to shut it again and it shouldn't completely and you know going even further go much much much much further on a more ridiculous concept, but you know, You know far far in the future.

59:07

When potentially, you know, and this is ridiculous but you know potentially when when you start talking about maybe sort of an intergalactic. Civilization, you know, it's again it's going to be the only way to stay relevant, you know, so we kind of just have to sort of accept it and instead talk about how we do it correctly instead of hoping that we can stop the progress because it's it's not going to stop at all.

59:36

I don't think. Maybe how I think that it's a good point. I mean how often does? The instruction not to do something not to touch something not to progress something actually work. I think it's humans we're we're almost wired for for a very opposite reaction to latient instruction, so I think ethical controls aren't about not proceeding.

01:00:04

I think they're exactly as you describe they're about how to do it how to do it well and I think that that's that's where the where the exploration needs to go is transparency and clarity about where this is headed and how old is virgins of of different areas of research develop.

01:00:21

Ment scientific. Endeavor of progress and perhaps one of the people things are about newly is that if it is just. Opposed to child for a particular technology and it's done without transparency.

01:00:41

You know, they're the sort of red flags for ethics, it's done, you know. To describe. How to do. It then I think ultimately you. Get the a wonderful point we've got neither anger. Guideline to our server. And apology.

01:01:09

No that was kind. Of I just like to see that like, Thank you.

01:01:22

Guys, honestly, I'm from the UK why that Asian we all come together. By we go out.

01:01:56

One line. We need to you know stand together and this is the only way we're going to be there. Where has all these technology taken off. It is taken to know where destruction.

01:02:48

Humanity at the moment inclusiveness how they look you know, there's a very broad. I don't know that everyone on the stage or new and it's been agreed and technology hasn't helped you. But it's this application and the, Issues of humanity.

01:03:15

I'm really sorry that you're.

01:03:30

Always pointing out it's about doing this work. It's not the technology or progression is is bad, but it can be applied in ways that are that are harmful and create power dynamics that hurt people within the community so I hope that you said that there's a lot of support and a lot of people with perspectives who are trying to apply the endeavors whether they've devoted their lives to the progressive to the progression of their areas that they work in are trying to find the right ethical applications to them.

01:04:04

To remove as. But a lot of us feel this is something Thank you for that. Great. I'd like to hand over to you person comments and your perspective. Everyone. It's quite tricky to follow up after this statement. I resonate with this likely. I live in London UK or free to reach out to me if you want to talk to someone message me on Twitter, I can talk to you and perhaps just listen.

01:04:40

Rather than is the multicultural place and there's a lot of. Say it's hard to say but. There's the racism from from all sizes not just towards particular one group, there's a there's there's there's also subcultural groups who are resisting or two one another lesbians each other, but I don't want to go into this subject let's begin.

01:05:03

I hope that this world is. A tanks a better place. I have my concerns. I'm looking forward to. To be enhanced with filing features to be able to. Have more access to data but I personally believe that these dreams are far far far far away right now, we can see some signals with 2017 of electrodes we need to solve the damage that it may cost to the tissue the revolutionary part is that we may see.

01:05:50

People who may be able to hear and and taste and things like that. I mean, however unconscious. I have many many ethical concerns about this because although we are all imagining what this technology could be. I'm wondering where the technology actually is today and there's a desert there's a great job.

01:06:19

I have a headache darling. I think she goes did you check your subscription to express? Did you get that job?

01:06:39

I think you've got something we might I didn't hear it. What did you say? That thank you for the a little bit of humor in the yeah, I'll try like to get up, you know. I'm only I'm only I'm so interested how this is going to develop, but I'm aware that it's in extreme infancy and perhaps.

01:07:10

My notion is that maybe maybe what we're seeing like the big demonstrations and stuff like that, maybe that's just. A show for public maybe the theme is aware and has done far more groundbreaking. Advances and my feeling is that perhaps this technology is way more developed than we are permanent to know a lot of technology finds a.

01:07:51

Product set so complicated to me the I'm trying to comply free. So the army. The cutting edge technology, they the armies has the first time I will be surprised if there's a fully functioning early there's other somewhere. And. To me we're talking sci-fi here the the the time we're we would be able to use nearly the way we imagine the moment we're already started plugging into my brain is far away.

01:08:31

And. I personally. Support the universe. But I'm scared obviously I'm scared of the unknown and I'm I'm afraid what's possible because we we're still not we are not sure whether we are in the real world today, although some people may argue with me that you know, we can touch it if you feel like we can go on to a holiday discussion with that.

01:09:00

I'm not going to. I'm worried because I have seen some of the black mirror stuff on Netflix on the front show, please just before I cancel my subscription to Netflix and there's this one series. Where people are put to prison in their head for years and years and years of their life.

01:09:28

That this thing must be so secure so that no one can happy to. No one can mess with you right, so I'm going to end this week a free giveaway. All you need to do is go to my profile finally tree go to the. Bathroom. I'm going to need a Tesla's wallet preferably temple even any probably like.

01:09:53

Less than 20 cents in there and you can get free pieces you can find them on there, there's a new release free and they are free okay, so get yourself a piece of history it's by my work. Going around 0.5, so this is me. Not you. Thank you the problem with Hollywood and and other storey killing is you know, we soak up the bestowed the futures more easily than the you type in ones in the storytelling so hopefully.

01:13:27

Saying it Logan Paul I mean.
