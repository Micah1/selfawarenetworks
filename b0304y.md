b0304y spoke to Subatai Neurons Dendrites Column

00:02

That perception is so stable and he just he talks about how you know, those stable representations are likely being held by a very very small percentage of neurons started to keep sense like 2 percent of the neurons firing in the brain at a given time so I mean, I think it's all compatible and I don't see where the thousand brain's theory clauses with that, can I can I jump in oh, Yes please do thank you okay by the way I noticed that super tie is next to me here on the stage and he's from the memento and he's part of it's part of the team that developed a thousand brain stereo, so he should definitely get a chance to speak but I wanted to say that you know, when you're measuring the when you're when you're looking at the brain to see to see that to look for the neural correlates of of what someone is seeing right now.

00:49

I would say that the firing that's happening, you know, it's it's oscillatory as as Katerina said it's it's also toward because it's it is there's inhibition happening all the time that's let's breaking up the The the constant flow of excitation which allows you know information that may be the key to for for the brain to be able to maintain some some discrete knowledge of information because we have all this inhibition happening and but what I was gonna say was that um, it didn't given time when you're looking at a group of neurons is oscillating that you should think of it as not just representing what they're seeing right at that moment, but also representing you know, like the past at least the past ten seconds and maybe like the past, you know, several minutes of their day it.

01:37

Is still sort of like oscillating in there and it's not just gonna be representative of what you're what's happening right now and I think of it if you know neurons fire in in the the fire in huge groups of oscillations and maybe you might see a neuro a neuro correlation to something that you're looking for like an internal terms of a change to happening to to to one neuron in you know, but if that neuron speeds up or slows down the rest of the the group that is that they're oscillating with is going to pull them back into the same like sort of pattern of oscillations and so it's eventually going to like renormalize and make.

02:12

You be what's happening is that the changes are happening but their changes are happening to basically to this like subtle speech to the to the like what I imagine is like you have basically this constant sort of like rendering of your reality in terms of all the modalities happening everywhere in your brain and the incoming senses just need to modify small parts of this just a little bit of your neural activity in order to shift what you're already rendering to include the new patterns of what you're of what you're now experiencing but if you're if you're just looking for straight up neural correlations, you're not going to be it's going to probably.

02:47

Be difficult to decode you know, what one thing is in one instant because it's not because what you're looking at is not just the representation of that one thing at one instance, it's a representation of a longer period of time, so that was what I had to say and welcome super time.

03:01

Sorry.

03:31

It's been really fun listening to this discussion. I think it's been really informed in the questions with everything with some has been saying I think it's articulating the points of the theory and how it matches some of the neuroscience really really well, you know. I'm happy to answer questions on the thousand.

04:06

Wins theory people have it but I think the discussion has been great in terms of you know, maybe just quickly some of the stuff, you know, Tom you mentioned the you know, the difference sensory either implants that we get the diversity of sensory inputs and you know any percept that we have an inferences that we have really taken to account the evidence that we're getting from, you know, diversity of different sensory inputs and even within a sensory modality like touch we're getting input from you know, all different parts of our body series very much consistent.

04:41

With all of that it's probably one of the few series that actually explains it and in the in the if you look at the anatomy and then your cortex. These long-range lateral connections that cross modalities and these are not really explained by a traditional hierarchical model and the thousand brain series is one of the reasons we've got to that theory was training explained connections like that, that's definitely very very consistent with that.

05:17

Yeah, so in terms of predictive coding it's very much based on a predictive model nationally very well.

05:52

Can be used as context for future decisions and there's definitely neural activity is a lot smaller typically when you have surprises and so on activities that are really wraps up different parts of that and you'll cortex just reiterating the discussion.

07:41

Would it be okay? What? I want to. Put to the group here is the the first knowledge that efficiency is so very important and with regard to obviously how the brain works but also the notion of a sentence synthetic intelligence we have to figure out some of the efficiencies that allow us to get the kind of performance that the human brain and you know that that living things do naturally and so one of the areas that I think is really important like co-founder and I we've been working on this for about a decade is is is.

08:43

Creating what we call as semantic periodic chart for computing. It basically comprises 256 elements in there, they're tiny little two and three letters designations and the the the actual letters don't matter as much as it does how they're organized to represent meaning and by doing so what we can do is map those semantic elements those 256 elements to not only what the machine can recognize code.

09:18

Assembly parallelized but it can also be map the other way to to human meaning what we understand natural language is sort of you know studies how meaning is made using signs symbols language, you know symptomatic syntax. Bring those together in a system that can respond to in this case 256 elements or map to it and then use that mapping to generate code.

09:56

I think we're on our way to some pretty phenomenal breakthroughs and in fact we're seeing some pretty stunning results in terms of real time representation of meaning that's basically expressed in one of those ways that by the way is is a human's term and and and I'll finish just by saying they think we have to figure.

10:19

This out pretty soon. I don't know if others agree with me. I think we're running out of time as AI gets smarter as quantum computing advances and so on. Programming languages, please to the strength of the machine right all the effort is around making the machine able to understand what we wanted to do versus the majority of humans don't know how to do that so I think it's it plays to our strength to map what we mean and how we represent meaning to something that machines can understand and I'll stop there what a beautiful sentiment.

10:58

I love. I love what you had to say, thank you for sharing that. I am Jeff you want to say something. I just said thank you, oh my goodness, you're welcome. Hi I wanted to ask going back to the mouse model. I wanted to ask about the engrams if you're talking are you talking about are you saying that you're mapping out the pathway of neuronal firing or are you saying that you know exactly which neurons are firing or are you saying where you know exactly where a memory is stored or all three, can you clarify?

11:50

Oh exactly I would never say exactly but we are tracing with those angles we are tracing which in. In which neurons like let's say in the specific context there's more activity so you have sufficient activity that they send out the fluorescence signal it's not that there's absolutely no activity elsewhere but those neurons have like LTP basically because you need to activate genes that that generate and LTP and we know those genes basically like, The first respond that genes let's say and when those genes are activated enough, we will see a fluorescence signal and we can we can trace those let's say so on.

13:06

Yeah.

16:08

It's.

16:36

Unmute.

20:49

Hey.

21:23

Google.

22:21

I had hardware that we have at our disposal in terms of what works and in actual machine learning problems and what doesn't work. And I think if people are aware of neuromorphic computing. So Intel has been resting heavily in your music computing and they have this test chip called Luisi and to my mind, you know, people some other group they showed that they could run they could take this algorithm of fruit fly and they could write.

22:56

Ship and it was like vastly much more energy efficient than that from better than you know, your silica their conditional moves. So that.

23:12

You can see.

23:27

Getting exactly the same quite a bit and you know, the the properties you mentioned about really high dimensional sparse systems are evident in the neocortex as well, not just in fruit flies. It's a sort of a fundamental property of representations in the new cortex and we think it's extremely much more efficient than today's computational systems the human brain runs on equivalent.

24:02

Of power which is a low end light bulb. It's you know so much more efficient than today's declining systems and GPU based systems and stuff and we do think there has to be different hardware architectures that are required to really exploit some of these properties and if you can represent things as high dimensionals power systems, there's some really interesting computational advantages that you can gain.

24:29

So this is I think an area where, We can actually learn hardware design and actual algorithms can learn a lot from the way the brain works at a very very detailed kind of mechanistic level. And so this is you know, very much a big part of what we're researching and very much the direction that we hope the industry will move towards.

24:54

Before you were in the room. I had actually computing and the fact that we can also store data in DNA. I will also tweet out later some articles that I've written about scientific papers on your market computing and I am super excited to hear a super tie that this is something that Juventus excited about because I wasn't learning that and, I really love the conversions across a discipline.

25:34

I believe that's where innovation occurs not only at the edge but also in between and if I may, I believe you were next and then David Ilion. Not only this room on intelligence, but you're very intelligent. Was actually up to questions for super tie to what I was I was there on the session that you and Jeff did was absolutely enrolled by so thank you for bringing me to the time that you spent it was quite a lot of time with us so I appreciate that and thanks for being here again.

26:21

So my background is MIT and I've been applying various tools of AI specifically of digital health since 2001 so I have a fair sense book as a computer scientist and as a person that I should build these tech companies how well there is technology have been doing and obviously being here in Silicon Valley, I see quite a lot of business plans to be AI or some fasting on AI.

26:56

So pretty far off from what we talked about and we're taught at MIT the field had the potential to become so really excited. Once again new mental pushing the bar to a different level. I guess the two questions are the following how far along do you think things are at the moment approach?

27:26

I'm really excited but in the field of computer science we we tend to see projects. That range from Dublin odds implementation of psych which you know was going to take 15 years ended up taking 30 years so that's one end of the scale of implementation depth to really how quickly companies like DeepMind we're able to apply deep learning to what's moving from chest to go which was order of magnitude a few months instead of several couple decades so my first question to use.

28:08

How long do you think it'll take for us to start cracking implementation of using intelligence on this new architecture that you guys have been thinking through and then the second question is I know since Jeffro at the book on intelligence way back which was the start of it all the whole approach was.

28:31

To be about informing computer scientists how to think about the world of the brain and start the basic modeling Iran's and collections of neurons and the whole system of what is just started the thinking correctly, what would you say is the difference with the thousand rings?

29:03

And computer scientists. Intelligence.

29:25

We are you know, it's always a hard thing to predict the future but you know, we have started the process of trying to take what we know from the north science at a very deep detail level and applying them to machine learning and deep learning with the idea that they're significant components of that deep learning could really use and we could towards.

30:00

The towards the goal of building truly intelligence systems and to really have truly intelligent systems we strongly believe that they have to be built on a lot of the same fundamental principles that are we find that in the neuroscience driven our road map is very much driven by what we have from the north signs in terms of how far along we've worked the foundation of a lot of our stuff is we've already talked a little bit about.

30:35

Systems that work very efficiently on hardware and hopefully announcements in the near future of overall. Speed and efficiency learning systems.

31:22

That we're working on itself.

31:37

Systems and. Whereas real biological neurons are quite complicated. As much. Of neuron. Complex with complex computations that are going on throughout the neuron. Bones and. Interesting constitutive are learning properties, and so we are very much involved in incorporating those ideas into deep learning systems and become those will be very important in getting systems that are truly continuing and learning systems today.

32:19

Are not really continuing learning cess learning systems and to be able to build systems that learn from traditions without requiring really large label datasets that were currently working on and then the last couple of things.

33:02

That we are working towards incorporating into into deep learning systems as well. A lot more than we used to before.

33:35

Okay so this question is to super time so yeah back in November I saw the the press release from the mentor that there was a sparse enables 50 to 50 times performance acceleration and deep learning all networks and so I I went out and started asking people that I know and deep learning like well do we have anything like that in in deep learning and they say they point me to sparse networks and I said that, you know, people are using sparse networks are already and that even the people that GP3 who are working on db3 and open AI that they're they have tried to use.

34:10

Something like sparse networks in the current version of of GP3 and but they're still not like there's the so I what what my question to is what's really the difference with STR is that new memento uses and and what whatever one else is using to achieve sparsity and efficiency in deep learning.

34:36

Has been really appreciating into their systems.

34:45

One in order.

37:46

I think you would need it. Did you like to speak?

37:55

Yes, I can. Sounds like you're in the car. How can I? Yeah. I just wanted to.

38:12

Wait a.

38:24

Minute and. Seeing the power of really high dimensional representation. So a lot of those intuitions originally come from Penny. Thank you for pointing that out. Are you guys supervised? Are you folks kind of in touch with him and tracking what he's doing now? I too. Bonded. And I recently found out he still has He's still doing new and innovative ideas in this area, although there's someone.

38:58

He's now I think working with Bruno's.

39:05

And we've chatted before he was working for Jeff Hawkins actually when Jeff founded the Redwood North Sciences back in I don't know about 2001 2002, so he worked with Jeff quite closely there as well. So we we keep in touch with him. I think he's mostly retired but he's he's definitely still around and he's gonna advising a few scratch students that UC Berkeley that we're attached with.

39:33

Great. I appreciate it people sometimes get even more act. Ive. Anyway, I will have a quick one for you if you don't mind me and that is I'm so interested to hear about the work you doing recently and the particularly the recognition or the acknowledgement of the sort of informational complexity of the dendritic arbors and the information they process and I'm wondering trees.

40:16

Signals and pulses and spiked trains. And what occurs to me is that it seems like the potential amount of information processing that is done in your average dentures tree processing these really complicated high entropy bike trains that are coming into it all of the places plus time. That's an enormous amount of potential capacity just in one.

40:47

Generating and then we have Harmony to hundreds of billions of dendritic trees each with plumbing thousands of thousands of synapses in every little timing of the pulses matters. I mean, how is there any hope that your standard weighted sum plus threshold model is capturing any of them? Yeah we don't think it does so we fully agree with you you know standard linear weighted sum plus our non-linearity cannot capture that complexity there's a lot of temporal dynamics that are going on as I mentioned, they're sort of learning related stuff and this probably a lot of stuff for sure there's a lot of stuff we don't understand yet having said that I don't think it's too complex to model we've gotten pretty far by abstracting away some of that into sort of functional components and whether it's learning algorithms or you know, temporal rules and so on.

41:44

We're probably not capturing the full nons of what's actually going on in parabinal neurons, but it's not clear that we really need to model all of the biological substrate and this is part of the trick. I'm not saying we're doing it perfectly but some of it's pure implementation specific and some of it's really conceptual and important and functional and part of our challenge.

42:06

I think as modelers and theorists all of us is to really find what that balance where is the dividing line what are the truly important necessary functional components. Acknowledge and praise your approach of your team because it's kind of an outlier approach right everybody like most ninety eight percent of the industry is just thinking on you know, more of the same like scale the same old network handles so-called.

42:54

Truly difference and people think it isn't necessary maybe fundamentally required so thank you for doing what you do is asking I think have any crucial insights into like the learning algorithm or algorithms. I should say. Biologically today is I mean, you know what this means?

44:09

Fun 2016.

44:44

Minutes.

47:08

Of 3MP principles those kinds of things both in analysis of investigation into brain functions pathology, but also in informing artificial intelligence strategies those kind of things. I'm just the curious of your comments there because the free energy principal activity answer will always stay they answer in their. Ambition to notions of fasting and also to high dimensionality, so I was just curious whether they're relevant or incorporating into your thinking.

47:57

A lot of his ideas from that from myself, you know looking at the anatomical findings and so on because that's much more mechanistic and if we're building actual algorithms, you know, we we certainly inspiration from. Rather than the very kind of high level view. I mean, 
we do read those papers we're in touch with some of the researchers there and there's you know, definitely an overlap in in the notions but.

48:44

You know, this kind of things like these detail learning roles that happen details about varsity and the numbers of neurons that are active, you know, these idea of reference frames, you know comes directly from the grid cell and place cell literature those kind of things, you know, really inform the way we are going about it and that's our preferences to go from the experimental literature and and try to build up from there, right?

49:11

Yeah, so I just had a couple questions for for you to tie the this this this area of dendritic computation that's like that's my wheelhouse that's what I that's what I studied and this the you know, what I'm trying to get out is the I'm trying to strengthen the the connections between biophysical mechanisms and and and learning roles and how that all works but my question with regard to dendrites from reading the book like, you know, I have strong opinions but, From reading the book.

49:47

I got the impression that. The thought there was that dendrites played a large role that there was do it be a lot of dendritic computations or dendritic spikes more specifically and I'm curious whether that's if you agree with with that interpretation or if not I've definitely would like to hear what what you're thinking about in terms of that and then the last question I have is.

50:17

There's also this other notion in the book that I that I agree with or I at least want to agree with with this idea that you know, the canonical the cortical column is a canonical circuit and it's more regular than it is varying in general. And so then it there's this kind of notion that there's a canonical circuit that's computing something, you know, the using these reference frames.

50:46

So there's just like notion of a general learning algorithm and I'm curious. What you think how you think that I've been thinking about this myself, but I'll leave my own thoughts out of it, but how do you feel this interacts with something like, you know, no free lunch theorem?

51:07

Yes, so this too much they're very different scales at the dendritic level. Yeah where our models are very much built on degree spikes and to mix by very critical to the functionality and algorithms that we're building. So, I think the best place if you want to look at that in the the book tried to explain some of that but obviously couldn't go into a lot of detail.

51:30

You could look at our 2006 paper 2016 paper and, You know, very briefly the the idea there is that what's happening is when you have an active dendritic segment it's detecting some sparse pattern from some surrounding area and that that is acting like detecting some sort of a contextual signal.

51:52

Something happens somewhere that's relevant to this neuron and then you get an NMDA spike which as you know, depolarizes the solenoid for about 50 to 100 milliseconds and that. Essentially what that's like is putting a neuron into an upstate. It's putting the neuron into a state where if it does fire it's likely to fire a little bit faster or a little bit stronger.

52:14

And so we call that a prediction at like a you could think of eat and drink segment again detecting a context and the neuron priming itself to fire based on some context. So and and whether or not based on whether it actually does fire not that then triggers plasticity in these dendritic segments.

52:37

So, I'm not sure exactly the if you had a specific question there, but dendritics segments and indirect spikes and the active dendritic properties and the plasticity that are super critical to every aspect of our model including reference frame computations and so on. Yeah, when you're when you're talking about spikes, then you're mainly talking about the energy spike, but are you also thinking about the plateau potential the actual calcium spike at the apical tuft?

53:09

Yeah, we've, Done a little bit of that so that's a very strong dendritic spike. As you know, you know, even the air spikes have a plateau potentials, you know, they sent to last about 50 to 100 milliseconds as much longer time duration than and then an external spike or a sodium spike the, The calcium space are you know based on contacts again that's detected at the apical dendrites and so you know, it's also have an MGS spikes the calcium integration zone is depolarized and then the neuron then fires an actual potential you get this sort of really strong calcium spike and and really strong learning as you probably know so those are another way another type of context that's processed up.

54:00

I think we're getting very much into the details. I'm happy to talk about it, but you know, you can pick up it as processing context from. A feedback that's coming into layer one into the agricultural dendrites. Okay great yeah any thoughts on the the no free lunch there no um yeah so that no free lunch theorem for those who don't know is basically a machine learning theorem that says that there's no no learning algorithm is better than any other learning algorithm and you can basically use all about what assumptions your algorithms make and so in the absence of any structure or any sort of knowledge about the world you can pick any learning algorithm you want and it's gonna be probably just as good as any other the issue is this is where cortical columns come in is we don't.

54:48

Live in a completely unstructured random world we live in a world with very definite structure, and so. We definitely believe the cortical column and the learning algorithms in there are bias towards the structure that we see in physical worlds and in our if so there are definitely areas so you know, no free lunch is still true but we're not living in no free lunch world we're living in a world where there's deafness structure and if you were to give us inputs that are completely random and don't follow, you know, any sort of recognizable structure that the cortical algorithm is not going to do well, so it's very much biased towards structure that we see in the real world.

55:29

Okay yeah it's stuff. I was like trying to reconcile this myself having read the book and so on my thoughts and my bias toward wanting to believe that as well but I was kind of thinking that it sounds like that's what you're saying, it just seems like maybe you were saying that the the you you know this.

55:49

You what's universal learning algorithm or whatever this algorithm at the cork will column is performing is built to solve problems in a specific format and that the cortical column is is putting problems information into that format and and in that way, you're not in this. You know conflict with with the no free lunch theorem.

56:19

Yeah yeah, so I mean, you know, I wouldn't yeah I would say it's sort of more about the structure of the of the world that you're modeling where you know, we say the cortical column is modeling modeling the the inputs and the the structure of the inputs that are coming in and there's certain you know, it's going to be limited to a certain certain types of structure that that.

56:43

You know, obviously has to be very common in the world if you give it very different types of structure, you know, if you do real random hash as someone was talking about earlier, we're not gonna be able to learn the structure of that right so it's it's very much structure that we expect to see in the real world.

57:03

Thank you.

57:10

In this room amazing. And oh, I just saw that. Time I needed and maybe. She's not had a chance to speak who may. Like or make a comment, could you flash your bike for me, please? Okay and if you're at the audience and Dexter if you're in the audience, I really want to thank you.

57:40

I've been looking at your profiles in amazement and awe and. So many amazing people here at Clubhouse what a wonderful room this is what a wonderful community if you'd like to ask. Please go ahead and just raise your hand you are in the future brain club, we are talking about synthetic intelligence aka AI versus human biological phrase.

58:10

And so many incredibly. Smart domain experts here on stage and the audience it has been. Amazing so with that if I can go I'll be really quick. I promise go for it, okay, so um. What I'd like to share with with the participants here on stage and any audiences so my my team has been doing some work on algorithm generation code generation the ability to process large amounts of data, so one of the patents that's been approved is on digital paternity and logarithmic signal processing one that is pending is applying that approach to.

59:01

Three and higher dimensional data within some pretty remarkable results, we we can traverse petabytes of data by only touching megabytes or gigabytes and with a high level of precision so it's a level of detail control type of approach that we're applying so I encourage you to go to our website or I can post in my my bio here where you can get to that information.

59:30

I think it could be very relevant to what you're working on here. You know, and thank you for joining this room, you've been here with me for many hours. As many hours but I'm so delighted it has because this is. Something that I think is so. The fact that so many amazing people can get together.

59:59

Engaged share ideas understand learn it's phenomenal and multitask let's not forget multitasking, which is a key benefit not heard from please flash your bikes right now. I have to go I never heard from me. I know you've heard me I have to go but I just want to thank you once again, it's like each room is better than the last so keep it up.

01:00:26

Oh my goodness unless I evoke invoke the Wayne's world theme which is we're not worthy, thank you don't feel worthy, but thank you so much.

01:00:44

Okay flash of lights who was next can somebody speak up and help me. I I could jump in. I I think I was second and I thought okay.

01:01:07

So Michael JP / my time guys / or hold your piece, okay? Michael JP. Dexter go for all right, so I kind of have a follow up to what wise I'm and super tying we're saying I hope I'm getting a name right now, maybe an interrupt me if not but so.

01:01:31

We Sam okay now we send so I regarding the NDMA spike and of course the dendritic can kind of the backward spike in the forest spike and I think the book from dementia from Jeff was talking about how forward spike can be a prediction right it could be part of how a neuron predicts that that it's going to fire is there's a some sort of the the dent right so in in the in the first book so on intelligence, which is a 2004.

01:02:00

I think there was this idea that the spines of the dendrite might. They might represent and I guess the spines are formed from long-term potentiation if if that could be correct or not correct. I'm not sure but you could answer that the spines might store temporal information and possibly also spatial information that doesn't the the neuron would use to detect sort of like set its own criteria to figure out what if what is going to respond to based on downstream neurons that are downstream below it, they might fire within two, you know, I have two or more neurons that fire within you know, a few milliseconds of each other and in the dendrite.

01:02:41

The spines that generate might might have this memory that's like a long-term memory that will predict when it's going to fire based upon a certain pattern beneath it and so then it's going to spike in the accumulation of many of these spikes in the in the in the NDMA and the dendrite and the soma is eventually going to lead to the action potential spiking out of the normal period of its normal oscillation, so it'll it that that's it's it's going to either like be more it'll be more excited.

01:03:12

I guess if it's spiked sooner than it then it should have because it's been. Influenced by this counter information So what I'm imagining So whatever I guess I'm asking is how does it the dendrite is my it's my description right or wrong and maybe what may you can add some definition to what I'm missing here and then how is it like basically the question is how is it dendrite going to pass on the detection of temporal information to the action potential into the rest of the neuron?

01:03:36

How does this to to to the rest of the sorry the rest of the reference room? How does a column sort of affect the brain's oscillations? And in due columns themselves kind of have their own oscillations. And is there you know, I guess. Mathematical structure at the level of a cortical column does that involve wavelets?

01:03:55

And maybe you could talk talk to that. Thanks.

01:04:01

So the way the you know at a functional level we think is going on there as. You know, if you have a dendritic segment we see from the biology is as few as eight or nine synapses that happen to cook her within about five milliseconds can initiate an NMDA spike.

01:04:23

So what's required is a coincidence of a very very sparse pattern. So, you know some this is eight or nine synapses out of a sea of thousands of neurons that are firing around it and so it's an extremely sparse patterns that that is detected by the dendritic segment and this.

01:04:43

Predisposes the neuron to fire a little bit stronger or a little bit faster than it would otherwise. And so what's going on is that this dendritic segment is detecting some context and this context is then predicting some some future firing. And so a lot of that temporal there's so too answers to the temple question one is that the synapses have to be coactive within a very short period of time.

01:05:09

So, it's detecting a pattern that's a very it's a population code. It's a it's an instantaneous activation of A bunch of neurons, you know that around it. The second piece of the dynamics is if that context is coming from the same group of neurons that are receiving it so in other words it's recurrently connected.

01:05:33

So if you have a bunch if you have a layer of cells, which is feeding onto itself, then the context is really what that layer was representing a few milliseconds ago or in the previous time step and that's one of the ways that the brain wiggly the brain learned sequence.

01:05:53

Is so it's it's the the you know, the layer has some activity that predicts some future activity coming in which then predicts again what predicts some future activities. If you look at a sequence like ABCDEFGH at any point in time you can then predict what the next letter is going to be and that's because the neurons that represent a particular layer have learned.

01:06:17

Connections to neurons that were active for the previous letter that were active just previously and what we showed in the in the 2016 papers you can actually learn extremely complex sequences this way what's called non-barcovian sequences so sequences where you have really a lot of shared context and a good example of this is sort of melodies to think about, you know, music, you know different musical pieces will share notes and comments and sometimes several notes in sequence in common but we can still distinguish one melody from another.

01:06:52

And so it's not enough just to look at a particular note or even the note that happened right before and you have to understand the full context of all of the notes that came before it in order to make good predictions, we showed that this mechanism can learn very complex sequences like that in terms of kind of I think you're asking about reference frames as well the same mechanism can be used to store knowledge and reference frames and the way that happens is you have.

01:07:24

A location in a reference frame think of it like a coordinate that's represented by a population of neurons that then access a prediction for what sensory input you're going to get next so if I'm happy to be you know, touching my coffee mug is that example Jeff uses all the time you have I'm moving my hand to the top of the coffee mug the top of the coffee mug has the location associated with it that is that map truth and really segments to specific what the sensation I'm going to feel at that point in the coffee mugs that you predict exactly the sensation.

01:07:59

And then when I actually touch, it it's either confirmed or it's a prediction error in which case I learned so the same exact mechanism is used can be used to learn temporal sequences or to store knowledge and in reference frames and and a bunch of other things as well, but those are two to examples and I'm going back to with some questions this is one of the ways one of the reasons we think that really spikes and this sort of forming these contextual associations through dendritic spices so critical in the in the neocortex.

01:08:27

I just want to add like.

01:08:33

I I. Did I repeated those apps they think when this trauma and I combined like a different inputs and compared them like sends me more to text inputs. Trident protection cell like the spinal neurons. Combined with ceramic inputs and all kinds of different inputs. I there actually found that now not all inputs are equal like sensory motor input with that make the left it's not really anymore labels like that, but it has kind of emotional labeling.

01:09:18

I create. With wave to your which is I just had to excite five spots with a tiny laser like five bouton and. Could generate a way bigger upstate from current and from the from the timeline then like other coupons and put so I'm there differences in and brain regions and sell types and.

01:09:52

Dead and then tensity of the apps they did create.

01:10:04

So much. I just wanted to take a brief moment to thank everyone in the audience. Every one of our speaker and our wonderful moderators for contributing to. The most amazing room on discussing synthetic intelligence versus by the biological brain. Phenomenal and this has been such an amazing experience even maybe super happy.

01:10:38

I am so grateful to be listening to you and oh, thanks JP. I see you flashing talk to. Do you think there's some people we haven't heard from yet oh thank you Myra on the stage and I just want to make sure everyone gets a chance to speak or answer question.

01:10:59

S so could you flash your bike at this time if you haven't had a chance to speak yet and would like to speak. I don't think we've heard from fire or have you heard from you and just. Are you guys with us? I know Myra is have you heard from Moji?

01:11:20

I see you flashing your bike the floor is yours.

01:11:28

I just think no and it makes a really good act.

01:11:43

Same one, oh. I'm sorry my ride. I hear you you're having signal issues and jakey's.

01:11:54

So good at give Jeff one last opportunity because I know he's been on the stage for a long time and he hasn't had a chance to speak. Jeff are you with us are you able to speak feel free to admit you're Mike if not we're gonna go back to popcorn style and then looks like JP you want to say something and index.

01:12:18

Yeah, thank you and amazing room is always and I want to thank everybody for their for their great wisdom, we some wow have you just blown my mind tonight sir as well as YouTube which I am trying to reconcile some things that I saw was regard to a BCI and super tie we some I guess I really welcomed yours or any of the rain trust kind of thoughts around this and you know when I when I looked at kind of a kind of nano micro fiber that, Read kind of to your point a.

01:12:57

NMDA or a calcium or a sodium spike and then you know, it looked like you know, the the they were going to pull a dendritic nerve through that tube so that they could read it with that damage it's super tight and you know, we someday to me, it seems like that might you know, and I know it's an invasive surgery but you know would we be able to still get the same type of reading out of something like that.

01:13:29

I guess, you know, this is something that I recently saw. Just part of me almost says maybe there's a different mechanism versus pulling that dead critic nerve through that to versus maybe saying opening it up and encapsulating it around it or something. I don't know. Well that sounds amazing I think that would be probably some swell will house to you know, maybe maybe you know about that technique and and what sort of how invasive it is and full disclosure, you know, I can be very honest and saying that I visited near a link facility.

01:14:06

I saw a whole bunch of things that maybe I do and don't understandably these are merely guesses at what I'm seeing but when I look at the thousand plus fibers that they had the three different sensor areas, you know, the four different risk a you know, a six. It seemed intuitive on how it all worked but the the part of where the robot was going to insert the tip and how they were going to place those nerves inside these nanotubes and concern me.

01:14:38

I'm not from familiar with the technique but I'm getting the idea that you're they would be pulling is this in vivo like, you know in a living brain they'd be pulling a dendritic branch or something like that and to to measure it in isolation or that's merely my speculation we assume at birth the whole bunch of robots.

01:14:59

I saw some beautiful robots at near a lake. I didn't see them in action that being said I did get a look at the chip and the BCI component and you know, when I looked at the nano cube and fibers that Subject on how. Yeah, I mean that sounds awesome my shit.

01:15:18

I would love to see data from something like that but I mean with any experiment you're there's always the question of how much your perturbing is system. I'll say a lot of what we know about dendrites has come from in vitro work. I mean that's changing people are working on in envivo which is you know, I'm among them but you know, you look at the way a dendrite behaves and a cortical slice even if you people done crazy stuff like put.

01:15:50

Ting a half a dozen electrodes into the same neuron into the same branch and and they're they're recording these really high resolution data in the tree, but but you've killed the animal you've fixed the tissue you've sliced it, you know, so there's a lot going on that that in the in a living brain that's a lot different than that and so there's you know, you know, there's a when it comes to life really getting down to the nitty gritty and getting the right answer to how things are happening in the brain there's always this need to.

01:16:21

Measurements that are invasive like that against what you can get from in Vivo and I'll say, you know, even that's hard, right? I use a lot of calcium imaging calcium is a very potent signaling molecule signaling signal in all cells and it's super critical for plasticity some people have cut up the plasticity space into you know, 20 plus met types of plasticity mechanisms and all the ones that people talk about are couple the calcium.

01:16:56

So there's you know, when you're it's an interesting signal to track but if you were gonna try to do you know, say plus the city experiments at the same time you'd have to be super careful because a very sensitive calcium signal sensor is gonna be interfering with calcium, you know, all the pathways that calcium's involved with so you know, it's you just kind of.

01:17:20

We we don't have perfect tools for this stuff but we kind of just get what we can and take slices of the problem at one at a time and try to integrate across them not measurement like that sounds super amazing. I mean, you're you're you're. You have a dendrite that's in in a living behaving animal and at that last moment you're kind of disrupting the environment so it would be very interesting to see that data.

01:17:50

I had two questions which relate to I suppose one to another and follow actually from research comments which for anyone who's working on artificial intelligence or approaching a general intelligence of assault the human brain brings in general have hundreds of millions of years in hand to have accumulated their priors and part of what is so impressive about the brain but don't efficiency and fittedness to its world is that it has encountered one type of world.

01:18:25

Of utilium mechanics broadly to begin from the level of perception. Sorry that with someone else.

01:18:36

Okay, um, can I be heard?

01:18:43

Oh yes. Oh okay so I guess I'm essentially saying I suppose I super tight to you and anyone else who's engaged in this pursuit closing that gap between the brain's accumulated priors which allow it to enter a world and interact with other humans, you know to to be furnished in a sense where at least via engagement with the world that can be pruned down to successively more precise engagements with other specifics in a particular culture, that's a, Massive search-based for any machine system to enter and then essentially arrive at those very surrender sparse connections which are trained appropriate interactions with humans and then I suppose yeah the second part of that question is that that implies in per weekend's comment an embodied brain so a brain which is involved in a perception action loop and it's.

01:19:53

Um economizes and maximizes the efficiency of its processing relative to perception and actions so is embodied in that sense so to questions how do you close the gap of the hundreds of millions of years of priors and and the you know, maybe four or five hundreds of four or five million years of hominid evolution down to an AGI that might be able to interact with humans and then also to what extent do you think it's necessary to have an embodied agent to be able to close?

01:20:27

That gap or yeah create those efficiencies.

01:20:34

Yeah, I think you know from our standpoint, you know, as dearest we can simplify a lot of stuff we can look for simplifying principles and yes there's tremendous amounts of complexity but you know, if if you believe in the idea that the cortical column is is embodied so that the common cortical algorithm in there, we have to we can simplify to understanding how a single cortical column operates, you know, what are its functional properties, what are the learning rules how is it structured?

01:21:09

And that how multiple columns can an interact with one another and if if if we can figure those things out the rest of it is, you know, remember the system is a learning system, so the rest of it is is primarily going to be a scaling issue and an issue of feeding in the right amount of data and so on we don't have to understand the full complexity of every single synapse and every single, you know, aspect of the you know, what's going on, you know, at least that's the kind of approach we've taken is is as computer scientists, you know, simplify it down to some common.

01:21:44

Properties common algorithms and then try to scale up from there and and and to your second point it's very much an embodied system, we think it's embodiment is absolutely critical every every aspect of the you know, every cortical column in the new cortex gets sensory input but also sends out motor commands if you look at some of the neuroscience textbooks and and so on it, they're still this sort of old dogma that some parts of the neocortex are motor areas and other parts of sensory areas, that's not true it's.

01:22:19

Well established now that every single part of the New York cortex has both sensory input and mode and sends on motor outputs, it's truly a really the common the cortical column is a truly sensory motor system and it's very much embodied in you know, whatever's world that it is getting inputs from and it's it's interacting so building embodied system is going to be critical to this endeavor for sure which I will click to the work of all seismic loops as as you know, the the the study of them.

01:22:54

Be a good way to kind of study the phylogenetic history of organisms and you know this whole notion that you can't really separate perception from control and vice versa.

01:23:07

Um, I have read a couple of the papers. I'm not I wouldn't say I'm super familiar with them but the the general, you know, notions of what what you just mentioned are very consistent with what we believe.

01:23:24

I have a couple. Okay a couple questions for us for for super time so there's 20 years of studies on decortisol decortised rats. I'm sure you're well aware of this so there's there's a new book that came out where the guys arguing that consciousness is not in the neocortex is just in the old brain and I think it's probably both but but he's saying that the in these rats like if you decorate if you take away their their cortex that they still behave like the other rats do the differences are pretty minor, so do you think can't I guess to do you think consciousness is also?

01:24:03

An old brain besides being in the cortex for human beings second is this is what is voting more specifically how do what's what's the prediction for how cortical columns are interacting to vote and and in the third is what is the structure of a cortical column in terms of what it contains does it contain the micro columns does it contain micro neurosurgery clusters and will these micro neurosurfect clusters potentially represent separate oscillatory patterns and I wonder how to interface.

01:24:38

If.

01:24:42

I can because if.

01:24:47

You going on in the brain because I'm also doing with camera genetic ruling out a reason of the cortex and neither a lot of different 
behaviors that you will have a lack of learning or coping and so on if you take out just specific areas of the, Agree with cardiac similar questions, you know that maybe some behaviors don't change but you know, there's going to be you're going to see a lot of deficits particularly in learning new new complex behaviors recognizing objects and so on so you know, I would have more questions than they think about the comment you made about the corticized rats.

01:25:32

Especially. I can save a follow-up one of the the things that you mentioned earlier see what I was saying if you had maybe seven to eight dendrites that you could maybe I mischaracterizing it that you could get maybe some neuroplasticity in terms of the types of transmission signal, you know, I'm trying to keep you know, reconciling what I saw to what what what we're talking about and if I saw you know, like 250, you know of some of these Mike, Fibers or nano fibers going in which would say be you know interacting with the brain it was able to read and say something signals would you say that, you know across maybe a thousand of those nano fibers that that might be sufficient to gain enough information to start reading a specific area to your plant with neuroplasticity, you know, my my thoughts were that you would have to go to different areas in the brain kind of thinking back to the old kind of modalities that that were mentioned here, but with the things that you've been.

01:26:46

To I could see that the tip that I was looking at might not be needing any further, you know advancement in terms of having a go to any other areas do you think that a localized anywhere in the brain would give you the same types of connectivity and read write capabilities?

01:27:03

I guess is what I'm thinking and then to the point of critical column so you know, how many fibers would it take to kind of 
substantiate, you know, across say 1 2 or x number of cortical columns?

01:27:20

So you know, the the, To a large extent the principles of cortical columns and the the the neurons that are in cortical columns are independent of the sensory region or the the the area of the new cortex that you're in and so every cortical column sort of follows the same principles now clearly different cortical columns get different inputs, so you won't be able to look at just one cortical column and be able to understand what the whole brain is doing if that's your question you'll be able to understand what that particular cork will column is seeing and what it is.

01:27:58

Modeling in terms of how much you need each cortical column in humans. I mean, it varies a lot between you know region and species and so on but roughly speaking somewhere around 50,000 to 100,000 neurons are in each particle column and so I doubt that just looking at a thousand dendrites is going to be enough.

01:28:22

I think you're going to need to look at quite a bit more than that. Characterizes a single cortical column. Convention on this. You know, I keep emphasizing computations. I feel like it it's you know and agreement with the the model that you've been buildings, super science, you know, just to kind of emphasize it for for people that are just like dude and thinking about this.

01:28:59

In terms of neural tissue.

01:29:08

You you went you went out there.

01:29:14

Like the. 90% of the the synapses are very very distal and and one of the things we know is that these larger parameter neurons which are the primary outputs of these cortical columns, they the back propagating action potentials from this homea without active processes, they're not able to reach those tabs so that means you need for ninety percent of your synapses, you need some sort of active gender process if you're going to integrate information between.

01:29:53

The somatic voltage compartment and and dendrites so I just kind of. Adding, you know, some emphasis on the importance of this topic but in terms of what you were saying about. You know, the devices these PCIs and at what resolution they would. Pardon when would it be useful? I would say what I don't believe is that we need to simulate every dendrite to understand the brain.

01:30:24

Just saying there's stuff we don't know and we this is a very this is one of the places we should be looking and we're gonna learn about computations that you know later on we'll figure out how to abstract properly and at the level of these you know, what what can you be done with these PCIs?

01:30:43

I wouldn't say a resolution interlaminar resolution could be very interesting so instead of trying to pick off dendrites and in this in this big. Web of dendrites something like looking at what's going on in the very upper layers layer one and a cortex versus what's happening in the very deeper layers there's a lot of evidence at top down information is converging on to the the layer one and the bottom up information it's coming into layer four and it's activating the upper layers and the bottom layers.

01:31:22

And so there's this, you know, spatial segregation of top down and bottom up information that I think is very interesting in terms of you know, the biophysical mechanisms for plasticity that are happening within these cells and within the column so I think if if these devices are sent sensitive enough to be able to you know, read out and simply be more sophisticated in the and the way they're stimulating things between layers within a column.

01:31:54

I think that's that's kind of, The place to start I think. And I would totally agree. This so that my distal the input is the more impacted will have on the excitability of the cell like this was shown by I think plot can add all that the more distal the input is just because of conductivity it will have a higher impact so you you have like maps within the dendrites and then within the layers.

01:32:28

Of like there's some kind of hierarchy in there I was about to say we've done yeah that starts to look a lot like the predictive processing and the hierarchical predictive processing that you were talking about there, yeah me back in I could respond to so Katarina and super tie reply to my question before and I I do have a follow up there, so the role there's a paper from 1992 called the role of the cortex and play fighting by rats development and evolutionary implications and so that talks about basically young young mammals young young rats, and They were the their cortex was removed and the the difference was they they basically had most of the same responses as the rats who had a cortex but they but they stopped they they were less playful with defense and the idea was that the the rats would without cortex might be a lot less that they might play a lot less and that's develop a lot less if a lot much much fewer skills, but but they still have a lot of normal behaviors.

01:33:35

And I'd by the way, I linked both Katarina and super tie on Twitter to those papers and if anyone else wants to look through the two most recent like post that I made. Yesterday that there's a lot of compensation and the mammalian brain that can go on. I mean, they're first for example a kid that was found out later he never had a cerebellum and he was perfect like fine which is a older like um brain region where like for example automatization like riding a bike and so on but um, there's a lot of compensation going on during development, that's.

01:34:18

But that's why I said my care that the removal of the cortex would have you would expect implications specifically on social behaviors and it makes sense with plays and play the young age is about you know, developing a bonds and also ordinating the social hierarchy where you here it's explicitly social of course other things are passed on in play but what you're described would make exact sense and also speak to the notion expressed by many people here that you you wouldn't expect no effects from rumoring your cortex, you'd expect all.

01:34:53

Sorts of facts and explicitly social effects. I definitely wanted to bring up a reawaken a question that was asked earlier what is what's voting in terms of how cortical columns interact or type perhaps, what do you predict that that is? Yes so voting so in in the the work that we published when we say voting, you know, each cortical column is modeling it's world it's it's building it's understanding the structure of its world and building a sensory motor model of its world and then multiple cortical columns are getting each of them are getting different inputs, it could be from different portions of the same sensory modality for example one finger to another figure or you know, it could be different sensory modalities completely like auditory versus some medicine.

01:35:44

You. Versus visual. And so each political column is trying to make inferences of what it's seeing in its world. And then the voting process allows different cortical columns to share their inferences and quickly arrive at a consistent. And in inference that's consistent with all of the available evidence. And so, you know, if I'm you know touched if the simple example is if I'm you know, stick my hand in my pocket, maybe one finger as as feeling, you know, something, But it you know one finger by itself can't tell what I'm sensing it might be something cold and hard but if I'm if I look by getting this the information from all of my fingers, I know oh it's my keys or oh it's my cell phone that I'm touching and even though any given finger is is sensing something that's ambiguous through the voting process we can quickly arrive at an at a consistent interpretation.

01:36:45

And the what's going on there? So, we published one very detailed model of how boarding can occur back in. I think 2017 and that that paper should be available on the mentor.com website but basically what's the information, you know, what's going on there is that each cortical column will transmit the set of hypotheses that are consistent with its interpretation so far in the form of these bars representations these connections are associated connections on active dendritic segments again and through a competition process you basically quickly narrow down to the hypotheses that are.

01:37:29

Consistent with the evidence across different cortical columns and there's inhibition involved and dendritic computation involved all of the the elements that we've talked about before are involved in this process. So, but hopefully that gives you a sense that a high level at least what's what the voting process is accomplishing.

01:37:50

Yes, follow up direct follow up with a narrow imager be able to tell that voting has happened and what it neuralink device be able to decode near neural columns and, Yeah, yes, there's a great question and and you would have to run right run your experiments in a particular way.

01:38:11

It has to be in the context of cortical columns that are exploring or you know, trying to do that at the task first of all. And it you would have to be imaging multiple columns simultaneously and imaging the layers that are involved in voting. In that paper, we speculated it's in the in layer, two three because those layers have very long-range lateral connections which are with.

01:38:37

Pink is where the voting information is transmitted so you could look at you could look at the you know neurons at that layer across different cortical columns and if you could construct your experiment correctly, you would feed in ambiguous information at first to specific cortical columns, you should see you know, certain amount of represent, you know, certain representation and then as you get more and more information the representation should get sparser and until it locks in on the representation that is consistent with the particular object that is being sent, so the the, Color.

01:39:13

Expecting. So maybe to ask where which journal it's published in. It's one of the frontiers journals, which is an open access journal. You know, I don't have my laptop with me right now, but it's 2017 if you go to numenta.com slash papers, all of our papers are are listed there.

01:39:34

And may I ask why you didn't submit it to a peer reviewed the process was just easier and quicker. It is a peer review journalist. Okay, sorry about that. Yeah. Yeah, I wanted to jump in here real quick and I have a question for Subutai. I was wondering if you have heard of or are familiar with the paper in the frontiers and systems neuroscience journal.

01:40:00

It's titled brain computation is organized via power of two-based permutation logic. I think what the the final author on that is that is Jodeci and it basically talks about how there are cortical and sub-cortical pathways that are organized in this power of two permutation where it's kind of like organized in a way where things go from specific to general and it's kind of structured in a way that allows this.

01:40:35

Kind of like like fractal hierarchical representation of certain information representations and the article also goes into how us some other systems such as the dopamine neurons don't share this power of two permutation. I was wondering if you were familiar with this paper and the power of two permutation architecture.

01:41:01

No, I'm not it sounds intriguing. Maybe someone else here is familiar with that and can speak to that but I'm personally not familiar with it. I'll look it up. Yeah. I I found that paper to be very valuable in understanding some of the the architecture of of the brain hang on the meat just started.

01:41:29

Around me if. We're Mike. Baking it would be most respectful and I would appreciate it. Yeah, yeah. I'll I just want to double down unplugging that article for you. I think um think it's kind of like right up the alley of you know, like the cortical column and it kind of like, you know, like traces, you know, the the architecture, you know from the cortical to the subcortical and kind of like abstract how there's kind of like a shared structure in the information sequencing.

01:42:10

I'm struggling to come up with the right vocabulary to describe this the paper. What would do away better job but yeah if you have if you can pull like a like some notes on your phone, I really encourage writing down this article it's open access, um, it's titled brain computation is organized via power of two based permutation logic.

01:42:32

I think it's a groundbreaking paper and um, and I think it would be a very valuable paper to have in the repertoire. That's great thank you what is it this specific about powers of two today talk about it, um power to permutation it's it's kind of like something we're very used to in computationally but I'm puzzled why that would have any biological significance yeah yeah it's like n equals to to the i minus one and it kind of like it abstracts that this, you know, power of two permutation applies to neuronal representation and it's it's something that.

01:43:13

I have difficulty you know, articulating, you know, it's something to do with you know, how things go from specific to general assembly and there's like an architecture that kind of like can abstract, you know things from from specific to to general and there's kind of like a hierarchical structure, you know, where you know, you start with you know things that are more more local if I could give kind of like an abstract analogy, you know, let's let's just use like a semantic concept such as um, you have like a cat and a Porch from cat you have like like animal and upwards from animal you have you know something like something that moves you know, and then upwards from that you have you know, you did the way you descend these things from like like like inanimate objects so there's kind of like you start very specific, you know, which is cat and maybe even more specific than that, you know, like you have like stinks cat or or Maine coon cat and you know, this is like so this is what we would call very specific and you know, the more you abstract outward, you know, you you could go up upon the levels of abstraction.

01:44:24

Um you have something more general you have something like animal and then more general from that you have something like like something that like an inanimate object and and that that was that that's what would be specific and you have like basically in in how knowledge is represented most most of the semantic maps in the brain follow this kind of architecture where the way that the brain represents these semantic concepts neurologically follows this yeah specific to general architecture and you can abstract this to most of the mom.

01:44:59

Rules the information models that the brain makes and I think this this example that I brought up might not be the most illustrious example, but I think the paper does a fantastic job of articulating this concept this fact power of two permutation and I think it's a when I first read it, like my mind was blown so I just really can't overstate how valuable I found this paper to be.

01:45:29

Cool, thank you for that thanks. Thank you so much. Francis always good to hear from you and we can't thank you enough super tie for the 
many questions that you've answered in your generosity of time and there's some speakers who have not had a chance to either ask a question or make a contribution at this time.

01:45:51

I'm gonna ask you to flash your mics, so I can see if you would like to add a comment or question from people we have not heard from on this stage Maximilian Roger Beth. Chica you want to flash your mics? I see Roger flashing his mic. Roger the floor is yours.

01:46:14

Hi yeah first I always want to congratulate super tie and Jeff on on your work is just it's just brilliant and takes a lot of guts to go right at the brain and say we're gonna figure out his best we can't how it actually works so it's fantastic so keep up a good work there for.

01:46:36

Artificial intelligence for trying to to make artificial intelligence based on the principles you're discovering things we would tie you already pointed out that it's you know, extraordinarily complex there's so much complex complexity that you've you want to abstract out some some elements and see if they can work for AI and I I'd consider that a sort of a top-down approach which I think is really worth doing and again, I think you should just keep doing what you're doing you're gonna get really far with that, but for someone who doesn't have a background either in the or Will in the neuroscience but is a computer scientist there's just not me by the way, but for computer scientists who wanted to apply some of your principles.

01:47:20

I was wondering if you think you would be possible to take the opposite approach a bottom up approach so if you think about the perceptron which was developed in the 1950s, it's extraordinarily simplistic idea of what neurons do and yet it's produced youth astonishingly kind of surprisingly powerful results when it's scaled up and people kind of cleverly link these units together, so my question is can you?

01:47:46

Suggest the next more complicated unit something that would incorporate some element of what you've discovered that could create the replacement for the perceptron that people who are basically just computer scientists could program in a practical way and use to experiment with and see what kind of intelligence they could get out of it, so for example the idea that that the brain is a predictive engine we could make a prediction unit an expectron, so to speak of some could you figure out a way to make some.

01:48:21

Suggest a way to make some thing that takes this act of prediction that that even single neurons seem to be doing make a computational model of it and just let people run with it or another idea would be taking the idea of the action perception. Loop that was talked about earlier so on.

01:48:39

So I'm just curious what you have to say about that. Yes, first of all, thank you for your kind comments before.

01:48:49

You know in we talked about this a little bit earlier, but incorporating dendritic processing into a neuron model. I think is going to be a very natural next step. There are these active properties of dendrites and we think that's one of the basic ways that neurons form predictions and that's there's a lot of work in the literature that shows how these quote unquote predictions can then lead to learning from from predictions and from prediction mistakes.

01:49:20

So, I think that stuff can be abstracted into very simple. Computational models where cut we're working on that we published a paper detailing a little bit of that back in 2016, but we're actually working on incorporating that into deep learning today. So, you know, I think that would be kind of the next logical step up from a simple perceptron is to really include more contextual processing through these dendrites.

01:49:49

Thank you, yep. I would definitely chime in on that and I totally agree with what you're saying. What one thing like in terms of where to start wrapping your head around it? I think Bartlett Mal's work is pretty interesting he was I think the first to formalize the dendritic tree as a two-layer neural network.

01:50:14

Just to kind of give you an idea of how the computational power could expand and I'll just add one little anecdote or not a one more point. That might add to you know, motivating people more people working on this there's a paper by pay leave in lab here at Harvard.

01:50:35

They just published it and they talked about they tried to do. Like a very robust gardener style capacity measurement enclosed form for dendritic trees and you know, the the two three sentence summary of what they came to is given active dendritic processing you and and you know in order to do it analytically they had to take things at the limit.

01:51:05

So at the limit of infinite branches in a dendritic tree given active processing that they found the the capacity in other words. The number of memory patterns that the way it was been analyzed for perceptrons actually grows on boundedly and so as you scale up the size of the arbor you get more and more and more memory capacity for you know, storing patterns and whatnot as a theoretical perspective.

01:51:37

Thank you with your contribution to this room has been incredible. I really thank you. Fancy from if you can flash your mics, if you have not had a chance to speak and you'd like to make a comment or ask a question you can flash your mics otherwise we're gonna go and PTR and because we do have cups on these speakers that chica and mark would you like to unmute your likes and?

01:52:11

Make a contribution. I just got here. I'm gonna wait a little longer.

01:52:19

Fair enough.

01:52:23

I just want to reset the room we are in the future brain club. I am the host and the founder it's named after my blog on psychology today the future brain at the intersect of artificial intelligence and neuroscience and the theme of this room tonight has been or this afternoon that has gone into tonight if you're on.

01:52:48

A California synthetic intelligence aka AI versus human biological brain and we have span multiple of both hard science and humanity's and exploring this topic they're no wrong answers here, this is an inclusive discussion where we make respectful conversation and, Meaningful discourse and I really want to thank everyone who's here, we will be winding down at 8:15 if you enjoyed this conversation if you enjoy the incredible collective brain power this room which I find amazing.

01:53:38

Please feel free to follow the future brain and the sister club orthogonal fractal we often have spontaneous rooms like this and you'll be notified of that and and with that I like to give another call for speakers before I turn off handraising Micah the floor I can Dexter the floor is yours awesome, so I definitely wanted to ask if if Ramsey was a speaking or if that was a wee sound but if you could, Post a link on your Twitter to the the two layered dendritic tree and also to a link to the there's a story you're talking about the paddling lab at Harvard that was giving active dendritic processing to infinite branches.

01:54:29

I just like to look at those papers we could post on on your Twitter or something yeah. I don't have a Twitter link top right now, but I have my Instagram if what you can reach out on Instagram and I can slide you some. Some links, thank you. It's a tight if I can and I don't think mine is a great wrap-up question, but hopefully hopefully that's one after mine but I'm curious from the earliest days of learning about the grain.

01:54:59

One of the the first ways that we ever began to learn about brain anatomy and function and and the pairing of areas was through injury and lesioning and that sort of thing. But I am curious to what extent your research grasps, what can be learned from? Neurodiversity from autism pathologies, like schizophrenia.

01:55:29

Parkinson's I was thinking about frontal lobe dementia frontal lobe dementia, especially with relation to slender the neuron connections like one economy one economo neurons those kinds of things and yet just the general question of how much do you learn about the abstracting of what the brain does from when it, you know hits particular failure modes?

01:55:54

Is that informative in your work? Um, that's a good question and we have not spent too much time on that literature. I know Jeff definitely is starting to think about that a little bit more to see if there's the things we can learn but you know, I tend to be much more at a mechanistic level the level of individual neurons and circuits, but I think some of that work is starting to get really interesting and I'm not definitely not an expert and maybe someone else here is but I think, Down the road.

01:56:28

I think we will be able to learn quite a bit about it learn from it, right? If you're a great ad sir. Like in general in your 
assignments.

01:56:42

The people and disorders so yeah when you're assigned started we learned from the disease state quite a lot and when brain regions were lesions. So at different region reasons or from the bottom is until one. So we gained a lot of insight through that computational wise. I don't know.

01:57:06

I may have a question. Which I do know them the seven day eleven dimensions. Features that. Part of the blue brain project and that you know, they basically found like clicks of of cells that go up to eleven dimensions and how what do you think if if that is still part of you know, the theory you guys use and how accurate or what you think of this eleven dimensions field?

01:57:52

Um that's a really interesting question. I have not I'm not too familiar with it that's another paper. I'll have to to look into so thank you for that pointer, you know, the general idea of having clicks of neurons that are working together is very consistent with in a sparsity and population codes and the way active dendrites work and everything we've been talking about so the fact that there are clicks of neurons working together is definitely consistent if I understood that correctly we've dimension.

01:58:26

Ality is you know we know that it's a lot of our theory is based on reference frames and creating a map of environments and objects and so on grid cells and place cells seem to be, you know, primarily two-dimensional. I think people have looked experimentless have looked for three-dimensional grid cells and I think there's they're starting to look at bats and three-dimensional animals and they're starting to see some interesting structure, you know beyond that it's it's I don't know what the experimental literature is.

01:58:58

I think mathematically. You know we've shown that you can take even one-dimensional grid cell modules and use a bunch of those one-dimensional modules and through random projections, you can actually model much higher dimensional spaces so it's but you know as obviously, you know, eleven dimensional spaces would be extremely difficult to to model as you might imagine so I you know, I would love to find out more about that paper and and look at it and see exactly what they found that sounds pretty interesting yeah, it's in Switzerland Switzerland was.

01:59:36

Funded by the European community it's a blue frame project it's really intriguing yeah, okay. I'll try to find it okay yeah if you just look for 11 dimensional and blue brain you'll find the paper. Thank you thank you so much weird minutes away from closing down this room all good things sorry, but I do after parties so if you follow the future brain or or see sister clubs dog and all fractals, you will be notified if there is an after party we often do spontaneous rooms such as this I do want to do a last call for this because on stage if you have not had a chance to ask a question or make a statement.

02:00:30

Could you please flash your life now before I do a final wrap up, okay? I see it's is it pronounced see or so yes see the floor is yours.

02:00:48

Okay mind question is so I'm cheaper designer and if I make a controllers, so I know the computer although. Running. So the therapy we can build biological computer Nowadays, the DNA can storage. So crisper is a good tool that to create the tools to.

02:02:36

Before you know, the insertion should be made when we change the genuine to any kind of organism was kind of random but with crisper you can be. Way more precise. So for a research, it's incredible tool and that's good. It's ongoing. The precision is still ongoing. So Crisper itself is just the tool to be very precise with where you want to edit the genome.

02:03:13

I would agree with that and nuclear weapons are also tools.

02:03:21

I I think we're kind of veering off the subject here, of course everything is do use and I think people know to disagree with that. So yeah. I guess I have some some questions for super tie. Is it diva any predictions for the basis of the information structure and data 
structure in a reference frame?

02:03:43

And does that extend to multiple reference frames like if we're talking god?

02:03:54

Um,

02:03:59

So yeah in terms of data structures for reference frames. We think we we don't have the full answer but we think it's going to look a lot like grid cells and the way that grid cells operate and. You know it's I know we're running a long time this is a yet another huge topic so but and you know, we have whipped published extensively on that but we've other people have as well that that if with grid cells and particularly multiple grid cell modules you can actually form very very rich representations of space in in multiple dimensions in ways that allow you to sort of predict where you're going to be based on movements and allow has this sort of property called path integration where if you you can always, You know, if you're moving around in some reference frame, you can find the shortest path back or if you're back to a location where you are before it's going to be a very consistent representation to what you had before so these are some of the properties that you need from a reference frame in addition to some of the storage stuff that I discussed earlier, so we think that data structures are going to be a lot like grid cells.

02:05:17

Do you think that is there do you know can you predict what the brains equivalent of a bit of information would be at the would it be at the neural level and is a binary? A bit of information so. You know everything's going to be represented as sparse representations and no single synapse and no single neuron is going to be critical the brain is very very redundant so unlike computer codes like ASCII and things like that we are we have an extremely robust representation then you can actually quite often remove 30% of 40% of a given set of synapses are given set of neurons and things operate just fine so it's never it's going to be hard to isolate it to a single anything it's going to be sort of populations and groups of neurons and groups of synapse.

02:06:07

That are sort of active together that's that's how we believe essentially that information is represented in the end the brain when you're cortexing well a concept or an idea or an image have like a sort of metric structure that would allow to be passed around the brain well, it will do concepts, do you think travel across the brain?

02:06:29

Well in the thousand brain theory everything is represented using reference frames so even conceptual, you know, you know concepts and high level abstract constructs such as mathematics and philosophy and so they're all based on unreferenced frames it's not clear whether the reference frames themselves are passed around because each cortical column uses reference frames to understand the structure of its world but the inputs that a given cortical column is is is getting is very different from what other.

02:07:04

Column is getting and each one is going to have its own set of reference frames what might be important to pass around is sort of the relative positioning of things rather than the actual reference frames itself, so knowing that in the example. I gave earlier if I stick my hands in my pocket and I feel some cold a hard metal knowing the where my the relative locations of my fingers might be very critical in determining.

02:07:28

I might grabbing my keys or my grabbing my cell phone or my grabbing my pen and so those that kind of, Mission might need to be transmitted but we don't right now we don't think the reference frames themselves need to be transmitted. If I understood the network, go ahead, sorry.

02:07:44

No, I don't want to catch off. If I understood the network protocols of my of microcortical columns or aortic columns, it's very in terms of how they communicated with one another would I with a as a neuroimager would I be able to use something like a neural link device to to put in an HDTP request for an image at one part of the brain and receive it from another part of the brain.

02:08:08

Do you think information can travel like that? Yeah, absolutely and you know, I don't think you need neural link for that. You can you can you know, definitely invoke representations. I think you know effort there are from our I studies that that show that you know, you can think about you can you know show subjects.

02:08:30

I'm stimulus and invoke lots of different representations and they're predictive representations that happen, you know all over the brain. So, I think that's that's probably pretty well documented. But I mean it go ahead. Keep going. So what I mean is like if I if I was if I was able to talk to the audio cortex could I if I knew the information protocols do you think I could like like dial in like, you know age to any address and call an image from the visual cortex back through the audio cortex to my sensor?

02:09:05

Well, except for the HTTP part. I think that's already been shown maybe someone else knows this already but I believe if you for example hear the sound of a cat you can invoke. In v1 and and and different parts of the visual cortex representative, you know neurons will fire that represents a visual image of a cat.

02:09:27

And so, I think that that's that's stuff is documented already. I just had a couple of questions that you know kind of build on top of what you've been talking about with with mica, um, but the first one is with you know, these reference frames. I know you know, I know we don't really understand how grid cells work and clear and obviously we don't understand how reference frames work and the cortex if if that's what's happening, but I'm thinking about you know, I work in the auditory cortex and I'm I think about a lot of these pathways from hippocampus up through, you know, the temporal lobe.

02:10:10

You know until Rhino cortex and then Perry Reynolds cortex and there's some interesting papers showing that the you know, Perry Rhino Cortex is doing some sort of gating and layer one of sensory parts of the cortex. So just you know, that's where my head is and I'm wondering where if you're thinking about the way these reference frames are built as a local process is the cortex co-opting something, you know, that's an older evolutionarily and and modified that and it's, Due in.

02:10:45

It on its own locally or do you feel like these inputs from areas that are driven by?

02:13:07

And so, I had asked one of the moderators to yeah. I think it was a person who was kind of trolley if he will for lack of better words. I think you guys know who I'm talking about. It's usually patrols game. Well, I'm glad that we're all here now and that we can enjoy this together.

02:13:31

I'm sorry, this is happening to you. Did you lose ownership of the club? Yeah, that's not.

02:13:42

The stage. I'm trying to take over the room and I'm pretty sure I know exactly it is. Very interesting because I saw your so there's a knot there was another cami in the crew with moderator, which is super confusing exactly from pictures and everything you know what I think that's um, Yeah, but I I'm hopefully that person wasn't speaking no.

02:14:13

I would've been kind of interested. Turing tests though talk about digital twins. So.

02:14:28

Full room and thank you so much for them you're all or your Wi-Fi card your radio the things that actually deal with the hardware on up for instance. TCP/IP has a flash in it that's because the TCP and the IP are on two different layers. I think it's called the session in the transport layer and then up top you've got the application layer which is where and the whole idea is you're gonna people working on network cards people working on operating systems of people working on protocols and people working on applications and so I look at Bitcoin as sort of a another layer.

02:15:02

Yeah well I will tell you moderators and future moderators be careful who you ask on stage. I try to be so inclusive but apparently, you know, just I don't know what to say hi David hi, can we what happened? I I've had a few rooms of my anger pear shaped every now and again but sounds like it was pretty dramatic.

02:15:29

Oh no drama there was. Someone on the stage you had not so good intentions, let's just. Tell me is just a signed moderator to people who trust I don't want to be inclusive with your very kind and you try to bring up a lot of people but it's okay for us not to have that green bean none of us actually work for that green bean so.

02:15:59

Just sign it only for people that you kind of trust.

02:16:09

Break. And I also believe that sometimes people make mistakes, but that's kind of a hard mistake to make so. Yeah I think even in I think that's right and I think even in the big rooms. I think six to nine moderators is plenty to give even if it's long lasting to give a share to the moderating job and to move around but if you if you give it to everyone who's up on stage, it's just too much confusion and opportunity for somebody that even accidentally makes somebody or some moderator or close the room or something like that.

02:16:48

I think I always make somebody at least one other person because the other thing that can happen is if your network connection drops out a new. Ly. You can you can actually lose the right which is not very good. It's happened to me this. I found that out in like a little private room though.

02:17:07

I think with my rods. It was funny what happened.

02:17:19

I think myra and then I think she liked her someone else and like the room ended and we're like what what just happened it took us a minute to figure it out. So if you're the only mod in the room and then someone calls you like the whole room ends forever well.

02:17:39

You mean like a phone call seriously. Uh, yeah.

02:17:47

Hi Micah and Myra hi hey hey thanks for joining the either party you guys really made the room. I really enjoy what you had to say and I'm super grateful. For everyone actually in this room.

02:18:07

You just just really made my afternoon, thank you.

02:18:15

Jimmy I always loved your rooms. I've never had such interesting topics, it's like every time gambia has a room. I'm like, we're fagin those. You are too kind thank you so much right seriously. Oh look I read muted yes, go ahead and tell. Everyone to say something. I'm looking at this picture here that that's really cool picture, by the way.

02:18:44

Give me if I could my rose and take in the little R&R I would say a clubhouse break but she's like clubhouse she's a she went in a little vacation. I wanted to say out of town to relax so she.

02:24:25

You.

02:27:52

You.

02:28:37

Okay, it's amazing and you are so kind just amazing.

02:28:46

And I wish you'd have.

02:28:53

Two gracious me.

02:28:58

Mes. Thank you. Oh, I just wanted to say thank you very much for the for the session earlier. Cammy that was a wonderful talk today. I was I was about heading to to dinner myself and so I was just I thanks again very much and happy to join another time.

02:29:37
