b0145y Whisper (This version was auto transcribed by OpenAI's Whisper)

Title: Thoughts on Michael Graziano's Description of the TPJ as a Consciousness Module, and his Attention Schema Theory contrasted with my thinking on a distributed Observer made up of many smaller observers each of which is an oscillator.

Quick note: Some of my thoughts on Michael Graziano's work, his TPJ module vs my comparison of the brain as a tv monitor rendering one line of pixels at a time, my thoughts start off rambling but then I draw a contrast between theories of a local of central focus, or a center of consciousness, to a distributed conscious observer consisting of smaller observers, audio is cleared by me to share

Listen to the Original Audio here https://recorder.google.com/share/b05673ce-0f9d-4d54-918e-1d054b8be409

Audio transcription begins below this line

---------------------------------------------------------------------------------------------------------------

Yeah, so Michael Grasio thinks that consciousness might be like a module that you add it and

then suddenly it can have the concept of self.

I think that's incorrect.

I think that the self-concept can be learned like any visual concept or audio concept and

to be able to have language and speak about yourself is something that a machine could

do unconsciously.

The machine could construct a language dialogue that describes its own, that describes, you

know, because the machine, because the human being you have, you're not born with this

representation of yourself, you know, at some point you don't have language, you have to

learn language, but you see, but you have to figure out, you know, your eyes have to

learn.

If you look at the book Action to Perception, you know, the story is that some people who

lost their eyesight regained it, but they had no eyesight for such a long time that

when they regained their eyesight they didn't immediately understand what they were looking

at.

In some cases what they thought were black holes would look like, I'm sorry, would look

like crazy black holes, later on their mind figured out that those crazy black holes were

actually windows in another building across the courtyard or something like that.

So there was a sort of like relearning, visual learning that over time through the action

and curiosity of their own intention and attentional processes they were curious about their incoming

sensory inputs to their eyes and they were, you know, continuing to look at those crazy

black holes until they figured out that they were actually windows and they had rectangular

shapes and that they had borders and that they were in the context of being parts of

buildings and this was a sort of like visual conceptual buildup and I suppose that the

same thing happens when someone's newborn that they may look around as if they understand

what they're looking at but there's no reason to think that they do that, you know, that

the restoration of sight to someone who hasn't had sight for a long time, sort of like paints

a picture of what could be happening to newborns when they first come out of their womb and

they look around in the world, they are not able to make the kinds of distinctions that

adults can make.

You know, their eyes can look and you might project that they understand what they're

looking at but of course they can't, at that point there's no language they can't say anything.

It's hard to say what's going on in the mind of the newborns but let's just stick with

the idea that your eyes have to create visual models, your ears have to create auditory

models, your audio, I'm sorry, your visual cortex and your audio cortex.

Your brain has to create models of each of your sensory representations and at the same

time receiving the sensory inputs is also receiving motor inputs and so it's creating

a model of your own motor activity that includes the sounds that you make and the audio cortex

helping to build a model of the sounds that you make, not just tracking your muscle movements

but correlating the sounds that you make with your muscle movements and your eyes are tracking

how your body moves in the visual scene so you can feel your arm moving, you're moving

your arm, you're seeing your arm, you're hearing your arm when your arm collides with something

or claps, you make a clapping sound with one hand.

Have you ever done that?

What exactly does that sound like?

Okay, just listen for a second to your one hand clapping.

Just listen to it.

And yeah, so we have these models of the self and there's no, in principle there is no reason

why a robot can't make a model of itself in addition to making models of the rest of the

world and I think that's what Michael Graziano is missing is like it's not going to be like

the consciousness module, you add it, so you have these sensory modules and you have to

add a consciousness module so that part of your brain is just modeling, it's just now

capable of modeling consciousness because it has this additional module.

I'm going to veto that idea, I'm just kidding, it's not that it's definitely wrong, it's

not an idea that I am in favor of because I think of, yeah, it's not, I think I have

to go back to the idea of you have observer mechanisms, you don't have a central observer

but you have observer mechanisms that correlate and so that's the OSC and yes, OSC is separate

from the attention mechanisms are going to be separate from the observer effect because

you have incoming frames of patterns but it might be that it could be that the TPJ represents

some sort of peak in the hierarchy of both observers and attention, it's like when observers

and attention collide, maybe that's the peak of the hierarchy of the brain in a sense and

I know it sounds weird so you say okay well obviously the incoming senses, the primary

sensory cortices which include the location of the TPJ, those are lower in the hierarchy

and the prefrontal cortex is above it and argument is okay but maybe the signals from

the prefrontal, because we want to say they are a lot more distant from the incoming senses

but again going back to graph networks as applied to the networks of the brain, it could

be that it could be that there's so much interchange and traffic that the real peak of the brain

isn't the prefrontal parietal lobes but it's actually closer to the temporal parietal function

in terms of information flowing from the prefrontal parietal back to the TPJ, again I don't know

but we have some activity coordination across the corpus callosum and we have a lot of connected

various, the phylamic bridges and Broca's and Werner's area, there's a lot of spots

where the distally separated information seems to converge in a coordinated way, some areas

seem to be more, there's a lot of silent cortical columns and the cortical columns are

more, most of the connections are local and so therefore they're kind of in a silo but

not completely and most of the connections that branch out from the cortical columns

we're talking about, those are just in the upper layers, it's a fifth or sixth layer

where the pyramidal cells are now reaching from the peaks of the siloed cortical columns

to reach out and connect or network different cortical columns together, the network with

long interneurons, they have different regions of the brain together, they form rich clubs

and they form the default network and there's other anatomically described networks and

so it seems that, it probably is the fact that the TPJ is at least one of the major

crossroads for the convergence of attentional patterns and the higher more macroscopic levels

of observation that are tracking patterns at a higher level, so my hypothesis was that

because we have basically this, with anesthesia we have the impaired function of pyramidal

cells and the pyramidal cells are linking together brain areas and so you have this lack of consciousness

when brain areas are not linked together because the pyramidal cells are being inhibited, not

inhibited but disrupted from functioning, so the brain is not linking together and there's

a loss of consciousness function and a patient under anesthesia could have some of their brain

lighting up, it's not global brain activity and so that's what I think of and so the idea

that somehow it's just a module in the temporal pyramidal function that we could copy and put

into a robot to the rest of the robot and now it has a conscious model so it moves from

its representation of what's seeing, representation of what's hearing to its conscious module

and now it can think of consciousness and that is just not really possible, it's not

impossible but it's not possible, I mean it's like the reason I say that is because I think

yeah you have to have this, you have to have large sequences of multi-scale interrelation

related data across many different modalities in many different areas of the brain collaborating

in huge sequences to achieve something like what we would sense as a human level or animal

level being this and this is going to be something that the computers will be able

to do because it is, but it's not going to be like a module, it's going to be like how

because one of the key things is you have basically like this bubble with a lot of bubbles

inside it just to oversimplify what it is, you have cells or they're at the bubble that

is a 3D, that contains a 3D learning machine that learns and it's not just a learning machine,

it's also a speaker, it's a learner and a speaker or it's a listener and a drawer so

it draws and it listens, it's a observer and a transmitter, it's a receiver and a transmitter

but it feels, it feels because they can create basically a feeling, let's just say a feeling

is a multimodal association, so multimodal tracking and multi-modal correlation, so if

you could take different kinds of data and you can track it, you can feel it, you can

detect a pattern, you're basically like a feeling is a pattern that's being detected

in a multi, it's a multi-dimensional pattern that's being detected, it has, it has feelings

have characteristics, patterns, it's a temple of spatial characteristics, if you rub your

finger on some cloth, it could be your jeans or your socks or maybe a flannel shirt, rub

your finger on different materials, maybe the carpet or just the flat surface of the

feelings have, you know, the feeling of a texture, of a textile has, maybe it has bumps,

maybe it doesn't, maybe it's rough, maybe it's smooth, but those are temple of spatial

characteristics that a grid of cells is modeling, it's modeling what it is, it's taking lots

of moments of feeling and putting them together and compiling them so that, it's compiling

them so that your experiences of that feeling develop the more you sort of tune in and pay

attention to and continue to experience that feeling and they, you know, at some point,

you know, when you're really, when you're paying attention to something, the multimodal

nature of what, of paying attention to something, it's going to be engaging multiple areas

of your brain simultaneously, like the visual cortex, the occipital cortex, I'm sorry, the

occipital cortex is the visual cortex, but I mean the occipital, the parietal, the temporal,

the prefrontal, different areas of the brain are going to be engaged when you're paying

attention to something and, you know, so that's why, that's why I made the joke about being,

the temporal parietal not being the module we can add on to make machines conscious,

but instead being the LED of the consciousness in terms of an indicator that the, that enough

of the global workspace across multiple regions has been, you know, has been activated in

is, is interlacing and is communicating. It could be an indicator of crosstalk between

the senses, which actually makes sense. That actually makes sense because when you're paying

attention to something, there is a convergence of your sensory activities. And so if you're,

if you're really paying attention to someone, that means you're bringing your, your visual

representations and alignment with your auditory representations and alignment with your somatosensory

representations. And that probably resulting, would result in some peak activity in your

temporal parietal junction or TPJ because it's right at the center of your incoming

of, of the primary sensory cortices. And so in that, in that sense by itself, like, you

could say that thinking that of the TPJ as the, as the, the consciousness module sort

of obscures an alternative idea in which you're just thinking of it as a symbol that your,

that your primary sensory cortices are working together at the highest level, which is, which

is going to be a good correlation of multi-sensory awareness or multi-sensory attention. And

so you could, I guess you could argue that, yeah, we have visual, we have attention at

every level of, of neuroanatomy. And, and so it could, it could, it could just be that

because you notice like attention can change, like you use smoke pot, some people become

very detail focused. They start focusing on details obsessively, like little stuff. And

so you start to wonder if there's other kinds of ways to alter the mind and what you're

focusing on. So, you know, some, some people have had experiences where they'll take a

psychedelic medication and they'll, and the, their focus will get very broad. Now start

thinking of things in them on a longer timeline. Let's start thinking of, of, you know, of,

like maybe look down at your hand and you can see a hundred years of history in your

hand or in the clouds. You see speakers going back generations, ancestors, great minds.

And this is like, this is a total opposite of, you know, your mind is, your mind's perspective

on time is expanding versus your, your attention contracting. And, um, so anyway, going back

to like, yeah, I think maybe the TVJ represents the convergence of the primary sensory courtesies

in terms of like attention exists at all levels. And, and, but therefore like, um, the reason

the top of the hierarchy sort of dominates your conscious attention and you are not necessarily

uh, you know, your consciousness may not, it's not that, it's not like we want to make

an argument like, yeah, well, well maybe it's only the animals with bigger brains that have

consciousness, but like, how do you explain how a roach operates? How do you explain

how a mouse operates or a dolphin, right? And all these different, uh, animals or like

or, you know, um, insects that have, um, some sort of, uh, operation and I, and I get that,

I get that, you know, we want to, we want to believe that I want to believe that fish

are not conscious, but, but it's like, okay, well, what, what, why is, um, why is the consciousness

at a high level? Why is it happening at a high level? And it could be that sort of like,

going back to basically the attention schema theory, it could just be that the stuff that

is inside consciousness at a high level, like I'm consciously aware of stuff, it's stuff

that is just, um, I mean, I, I guess this is covered already in the theory, like it's

like, it's the stuff that's dominating other stuff. It's, it's the patterns that outcompeted

other patterns in a, in a way that moved up to the higher levels. But then, and you have,

you know, you have this sort of competition that patterns go through to become the pattern

that is, is dominant in the architecture of the mind. They're competing against each

other. Um, they're competing to take up space in your mind. I mean, it's one way to look

at it. Um, trying to say these patterns have their own agency is a little funny. But, uh,

you know, I would say maybe it's the moment, it's the momentum of past patterns that, uh,

and perhaps also the momentum of, of, um, the memory of what, of your past that you've

learned in terms of what your ancestors did and that, that drives you and, um, drives

your neural patterns, right? Your memories, uh, are drivers. And because that, because

memories have their own, like, momentum, right? And, and, um, well, yeah, I guess I have a

big disagreement, Michael, across the honor, because I don't think of neural consciousness

as just like some module that we can just slap onto the back of a, of a robot and then suddenly

it's going to be able to talk about it. So if that's, I don't want to say that's ridiculous,

but that's what I'm thinking. Um, I think that, uh, that the, if you, if you look, I

think that the brain has, is taking turns rendering on a large scale, the brain is taking turns,

um, just like, just like, okay, so like when you think of how a computer monitor works,

right? A computer monitor, a computer is, is sending, uh, an image to the screen, uh,

one pixel at a time, one line at a time, like when, when, when a screen, when a television

screen renders, uh, an image, it renders one line at a time, but it does it so fast that

you see, when you, when you look at a computer screen, you, you see, um, an image in the

computer screen, maybe you see a moving image, maybe it's a bit, maybe it's a video or a

video, and, um, but that, but that is made up of like one line being drawn at a time across,

one line goes across the top, and then another line underneath it, and then another line

underneath it, like if you slow down a computer screen, a computer screen is just doing one

line at a time, and then when it gets to the bottom, it goes back up to the top and starts

drawing the next frame, and it has to do, like if you, if you're watching a, um, a film

that is, uh, 40 frames per second or playing a video game, that's 120 frames per second,

um, that means that, that's, uh, for each of those frames that happen in, in each second,

there, there, what, there's still like, you know, one line is being drawn at a time, that

line is being drawn so fast, that you don't perceive what, that you don't, you, you typically

don't perceive that one line is being drawn at a time, you just see the movie, you just

see the whole image transforming, and, um, and that's what I'm suggesting that the whole

brain is doing in a distributed way, is that the, um, you know, the, what, what Michael

Bryson and I might refer to as the attention schema, is basically, um, the neurons that

are activated, versus the neurons that are inactivated, but in a global way, each part

of the brain is, is going to sort of, um, be writing a different line of the pattern

that represents the, the sequence of things that we consider when we're conscious, and

so of course the visual stuff, the screen, uh, uh, uh, that we see is going to start

in the, in the B1 area, and like, like just on a visual level, that's just all it needs

to be.

It is, you know, basically creating basic models, but what those models mean, the meaning

of those models, um, that is, that's, that's another thought that takes up another line

on the monitor, and so that's how you, you see, the brain is like a, it's like a distributed

rendering, a distributed drawing, think of the consciousness of distributed drawing,

where each part of the brain gets to render a different, uh, pixel, and each oscillator

gets to, gets to, um, and the different pixels are like dark, it's like one line, like you

have a whole bunch of, so you have a quart of comb, and each quart of comb in the, in

the neocortex is representing one line of the screen of the mind, and, um, and then

what happens is the oscillator, where's all the neurons that didn't fire, that are basically

listening and predicting when they're gonna fire, because they're collecting little electric

surges, actually, I mean, they're collecting, um, phase differentials, right, they're,

they're, uh, like, you know, either they're receiving neurotransmitters in a very regular

way, um, or they're tracking basically novel, uh, patterns, and predicting when, when they're

going to fire, which is going to allow them to activate in a sequence, in a playback sequence,

and so that observation, that observation, um, is something that the entire, um, the

observation that a single neuron is doing in order to predict when it's going to fire,

um, is something that's also being done by the network, or the oscillator, or the, what

they're calling, so yes, so we have, so we have predictive coding at the individual neuron

level, but we also have predictive coding at the oscillator, uh, level, at the cortical

column level, and, uh, we have predictive coding at the, um, larger scale of, of different

brain regions, and so the, so the interneurons are participating in predictive coding of,

um, you know, firing at, at the greatest level, and that, and so what I'm saying is, like,

at all levels, we're, you know, at the micro level, we're deciding on individual pixels,

and, uh, at the cortical column level, which is also the same as the oscillator level,

you know, the meso level, we have, uh, we're doing lines, so pixels, lines that we're rendering,

uh, and then at the global level, that's like, okay, the global level is like, um, the cortical

columns are going to play back in sequences, so that it's like one line gets filled in,

and the next line, and the next line, and the next line, and then you have the computer

has now rendered an entire frame for your eyeball, but it's not for your, it's not for

your eyeball, it's a set, it's you have, um, not a singular observer, but you have, um,

the network itself being an observer, you have a distributed observer, you have many

small observers that work together to create the illusion of the singular observer, because

the many small observers are, uh, producing, uh, together, collectively, they're producing

a common, a common pattern.