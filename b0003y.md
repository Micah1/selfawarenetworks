b0003y

(audio note - the transcription needs to be fixed)

You can listen to the raw audio here https://recorder.google.com/share/df384502-2dd4-420a-9bc1-59f087972fb6 

00:00

Considered for the brain that all you have are cells and the communications that go between cells, and we can deduce that it's phase changes, not spikes, that are being transmitted inbetween neurons, a spike happens on the body of a neuron and then it transmits a phase change.

00:27

A cluster of cells has a regular tonic frequency firing and that regular tonic frequency firing changes and these phase changes are bound together with oscillations and the dynamics of which you can read about with the likes of György Buzsáki and Steven Strogatz. But what we need to consider from a computational standpoint is, what does it mean to create a neural network that has that only transmits face changes in between cells?

01:03

And from that constructs, a picture of reality, a rendering of reality that in which the participant can do things like separate objects from from other objects or identify different items in the environment or identify locations and space. The participant can have distinct representations because actually map representations of the environment including a concept of self that has to be somehow rendered within these cells and the phase changes that there are that they are transmitting in between one another.

01:50

And so, for that reason, I imagine that the architecture of an artificial sentient and self-aware. Neural network might consist of and neuro network. That is, that is primarily a distribution of nodes that are oscillating with the phase pattern and that phase pattern is regularly regularly interrupted with phase changes that come from this sensory inputs.

02:28

But also come from basically the oscillatory dynamics of the human brain that. So so it's not just sensory inputs that will generate changes to brain state. It's also the internal dynamics of the brain, the brains physical activity, and it's especially it's neurology, the oscillating nerve phase pattern and the magnitude of the neurotransmitter release.

02:56

It it's it's neuro transmitter timing properties. I guess I want to argue in and I said to be researching this, I want to argue that that the regional differences in and across the brain in terms of neurotransmitter, populations in the vessels or the exercise are correlated with the frequencies that we observe in the different reasons of the brain that the frequencies, that that we, that seem to trend but also that the more quality of the brain is responsible for, for both the distribution of neurotransmitters and the the kinds of frequencies that exist in different parts of the brain.

03:48

But besides the those facts, the main point is that to build an artificial neural network. We sort of need to imagine how the sentient and self-aware neural network is it's something that has dynamic arrays that have that are able to transmit information in it in a 3D context that the brain can learn the 3D.

04:20

So that so that the the brain can learn 3D patterns and play back through your patterns over time. So three patterns over time and so a neural network that can crunch 3D patterns over time and then draw links between. So it's like keeping learn what is the pattern? It's like is like a representation of the data coming in to senses.

04:45

And and on top of that, representations of that are predictions or thoughts on top of the data coming in, through the sentences that are established through the feedback loops inside the brands activity patterns soilated by the oscillations of in the physics of the brain, and the narrative, the neurotransmitter mechanism and so on.

05:16

So, there's a lot, there's there's a lot more to cover. But basically, that's why I can say, we couldn't reduce an app in the abstract, we could reduce an abstract, the human brain to a field of tensors that are. I feel the face. Cancer face answers are tensors that consists primarily of frequencies with magnitude.

05:43

So phase sensors are. In fact, everything in space is a face sensor. In a sense, everything has a frequency in a magnitude. The magnitude is amplitude plus duration and there's an inverse relationship between the magnitude and the frequency. So it's not, it's, but when we think of like the brain, it isn't.

06:03

It's, I'm arguing that we've the current model of the brain is one. And one in which a phase is is not not something that has a magnitude a sort of like started in deep in the magnitude of the phase is sort of discarded in and in the modern deep learning network.

06:25

It's not it's not really considered. There's not a really a spatial hard dimension or a dynamics spatial relationship and in a deepening network, there's deeper on that work. Every node is is map to every other node, in the next, the next layer or the previous layer. There's a, I mean, there's it's not like in the brain which you have is you have memories that are represented by a connections.

06:53

So, a neuron dynamically has connections and those connections represent the memory. So that's different from what a deep learning neural network is and that's the key to like why? And the network. The 3D morphology of all the synaptic connections, allows the network of the brain as a whole to relate one.

07:26

One to relate the the face pattern coming from one part of the brain to, to, to a distinct memory at that, the rest of the brain that will echo across the rest of the brain and what you have in terms of like the human experience in this phase cancer field of mind.

07:53

In terms of the animal experience and human experience is you have a situation where There's a sort of collision of multiple representations happening concurrently. And I guess you can point to books, like David Egman's book in which he he describes the brain as a as a. I think he said it was cooperation of rivals or yeah, like a cooperation arrivals.

08:29

Like like there's a competition between oscillatory groups, over over what sort of brain operations, get what sort of territory. And so you have this huge huge dominance that has been described by neuroscientists accuse, dominance with visual activity relative to the quantity of cortex that is devoted to processing other types of modality activity, like ought like like audio or tactiles and station.

09:05

So so it's been an observation that it seems like a huge amount of the brain is is devoted to visual activity. Now, I would go further in and then that and and and and and argue that actually the the whole brain is processing all of the sensory input data.

09:27

But there is some, there's there's some accuracy to. I think the fact that if you, if you put a blindfold on blind blend blend fold, you put a blindfold on and, and block your vision, a hundred percent. If you're in total darkness, then your visual cortex starts to work on processing information from your audio cortex.

09:52

So there is an actual observable quantity of brain activity that is being devoted to visual activity that it's not. It's not this, it's not that neuroscience is when I say the whole brain is processing, visual visual activity, and whole brain is processing. Audio activity that that doesn't contradict previous assertions that.

10:16

You know. The that a large portion of the brain is is really it's resource or being used up in a competitive way to do one sort of operation, like processing visual information or processing audio information. That is true. Is someone loses a limb? Like like you know, could be an award or something.

10:37

That is they're the brain that was processing. The lost the last limb over. Time will likely be consumed by by the brain activity patterns belonging to to the rest of the brain. So the brains resource essentially will grow to to take advantage of of what's available. I mean that if you if you lost your site then you're gonna have the rest of your of your senses competing.

11:21

Take over the the activity space. The temporal spatial activity space that was devoted to processing vision information. Now, it can go to processing, acoustic information or tactile information. And or for supports they're smelling information, you know? Or there's some just so much. There's so much. There's so much that I that that, that has been so much research that has been done on what happens when on this topic that I don't really need to go into that much, but, but that helps.

12:03

But that this idea that, that even though everything every pattern goes everywhere, there are still going to be dynamic trends associated with the quantity of brain activity. That is accessible to answer the quantity of of a brain activity that is accessible to each type of operation that that that the organism wants to participate with.

12:44

So I going back to going back to the the model with the giant dog in terms of like, yeah we can we can through computational modeling. We could we can deduce what kinds of brain structures are going to a sort of like reverse engineer. Which types of brain structures given this model are going to produce the behavior patterns of the dog and friendly info, dog.

13:17

This can be sort of like, it's like using computational modeling to discover the neural network that corresponds to the desired behavior, right? And so you can use an evolutionary program to test out lots of different. You know, iterations to elucidate the behaviors that you're looking for and then you can.

13:39

But then with with these insights, we can sort of like drill down it really specifically into what the the contributions are of each of each node in the network to understand what is the more logical contributions of each of each note. So it's not the case that we need even need to discover every possible.

14:00

Type of neuron you know, like I wrote in a note that you know it's not like you're gonna find an eyeball inside a neuron the the the range of of possible types of neurons. It can be argued has it has already been parameterized. There's there's a it's going to be very there are still going to be undiscovered types of neurons but they're not going to be that different from the types of neurons that have already been discovered.

14:31

And we do not actually have to be that precise about knowing every kind of possible type of neuron in order to begin to experiment. Computationally with models for self-aware sentient. You know, that works that are going to effect that the results that that that are desired in a machine that can have the friendliness in cooperation of a dog.

15:05

But the the skill and ability of a of someone who does construction work. So I think that's what we're looking for. Is our machine set are friendly smart loyal and we can design them to love so that they love working. So they love to work with us. So they love to do construction work.

15:37

And so that is, we can design them. So that it's very rewarding for them to help us to work with us to be our partners in constructing. In doing construction work. So we can, we can build homes for the homeless. We can those free homes and beautiful places. We can build roadways.

16:03

We can, we can build speeding trains that will take people into into new places if people the human beings aren't at. Now we can have robots that clean up the seed. We can have robots and build windmills. We can have robots that build batteries, we can have robots that build solar panels.

16:24

We can have robots that do every kind of task and they will love doing it. They'll love doing it because they'll be designed to love helping us with these tasks and these tasks, they will understand help everyone. They help will help the help everyone on earth. And so there is a sort of nobility as well a concurrency that these robots can understand that they are a part of something great, their unified with human beings in establishing something great and we also can design sort of monitoring systems and alert systems that not only safeguard human beings from robots.

17:07

The safeguard human beings from other human beings so that we can notice when an artificial neural network, the artificial sentient neural network is is damaged and and having a strange behavior pattern. And we can notice, when a human being is that when there their brain is damaged, having a strange behavior pattern and we can, we can fix both the human beings and the robots with the same sort of, you know, it can be a, like a there's there's there's voluntary, you know, monitoring that people can take part of if they're involved with certain kinds of of work that that involves certain kinds of risk and danger.

17:56

There's voluntary self-monitoring devices that people can take on so that if their brain ever breaks down in a serious way that they can get help and they can get that problem fixed. So, they don't become a risk to others and that would be, you know, something that you like, you know, maybe you want to apply for a really dangerous weapon, like a licensed operate, a nuclear weapon or or maybe, maybe we're talking about an automatic rifle that, you know, like the kind, the kind that the kind that a really violent, you know, killing machines.

18:36

Maybe we need to say, okay if you want to license to have this super gun or this super weapon, you can get that license as long as you voluntarily agree to to have a self-monitoring device is sort of like monitors, your your brain on a regular basis or or it could just be coming in for a brain scan once once a month.

18:59

I mean, it doesn't have to be a 24/7 monitoring thing. But you can come in for a brand scan, once a month. Just so we can make sure that you're not at risk of of are going psycho and doing crazy damaging shit. If someone has a job that doesn't involve risk to other people, then there's no reason for them to have passwords.

19:26

That's that sort of checking, right? If you, if you you, if you're writing books and you know, on the in on a mountain bike yourself, right? Why would you need? Why what, what's been with the risk of just leaving you alone? I don't I don't know and in some cases you can have just wait like the same principle of policing you can have a sort of regional monitor you know likely like right now the government will employ his police but they also play monitors to listen for signals.

20:05

That indicate a nuclear bomb has been has been exploded right? Or or there's their sensors for earthquakes or centered their sensors for gases or sensors for air pollution. You could have a regional sensors that sort of like, well monitor a region without invading, the privacy of individuals, for science of that, that violence and neural networks will be able to predict what part of the world imminent.

20:34

Violence is going to happen based upon a regional center data, right? Like you know, if there are obviously if there are their guns being fired on a regular basis, you know, maybe maybe then, then maybe we want to dial in from a regional examination of sensor, activity to having a to starting a police investigation, that's more.

20:59

More specifically trying to find out what's going on in that region. So there's different levels of sort of monitoring that can go on. But the reason that this is a doable proposition to put these dog likes into aware robots out in the world to do construction work is because essentially human beings are sentient and self-aware robots and we can manage our relationship to human beings.

21:24

So, therefore, we can manage our relationships with these robots and I understand that the, the principles of neural activity to degree and I can show that, you know what, what is, what is what is the thing that's enabling an in the, and again, this can be proven what is the thing that is enabling higher?

21:50

Higher levels of cognition this can be proven by by examining the contrast. The contrast of differences between the more quality human brains, and in other and elephant brains and and dog brains and ant brains, and bird brands and D brains. The the there's a there's this, you know, there's there's lots of 
difference between different species.

22:14

It's a lot there's size differences. There's, you know, different shapes to the different kinds of dendritic morphologies, right? Like, the, the dendrites and human beings are much longer than they are in mice. If you, if you put human, if you put human glial cells in mice that the the memory of in the might, and the mouse becomes a lot better because it's human beings have have evolved.

22:44

Some hardwares sophistication to the actual to our tour, to our neurons and the cell by cell base is that allows us to have cognitive abilities that mice. Do not have memory ability. Is that nice to have the little differences in morphology matter a lot and so from the study of this, I already have some good insights into why the structure of pyramidal cells allow allows us to for example, have high lows of cognitive abilities.

23:19

And you know, we have, you know, I guess you can look at a mouse brain or an elephant brand. You can say, well, the most of what's happening, you know, it's even if you know, most of what's happening. Seems to be like one or two, two layers deep and and, you know, you know.

23:38

So, you know, you look at a zebra fish and there's not really something you that you can call it a the cortex, right? The same. But the general principles sort of exists in terms of like how intelligence is working in the differences between zebra, fish and myosin elephants human beings points to how we can construct Rope sentient robots, that are at dog level versus it.

24:07

Sensing robots that are at human level. This is within the realm of what of what the book is at. So yeah.
