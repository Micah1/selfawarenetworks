y0034 (audio was intentionally deleted as it was noisy and difficult to listen to)

# SciSummary KeyPoints Long

1. The paper discusses volumetric video technology, which allows for 3D videos that can be viewed in virtual reality headsets.

2. It introduces the concept of 3D semantic segmentation, explaining how computers can recognize and classify objects within volumetric videos.

3. The author draws parallels between the way computers process visual information and the human brain's neural networks.

4. The paper mentions the author's involvement in neuroscientific research, brain-computer interfaces, and virtual reality projects.

5. The author claims to have developed a unified field theory that explains how the human brain processes consciousness and reality.

6. Unified field theory is described as an explanation of how gravity works at a fundamental level, with equations to support the theory.

7. The paper references the concept of brain oscillations and how they relate to the creation of mental images and thoughts.

8. The author discusses how different brain oscillations and phase wave differentials contribute to the formation of mental representations.

9. The last section references an individual named Abraham Hicks and her concept beliefs as vibrations in the brain as oddly correct for a non-neuroscientist, tying it to the author's discussion of brain oscillations and phase wave differentials.

# SciSummary KeyPoints + Overview

**Key Points**
1. The article discusses cutting-edge technology such as volumetric video and 3D semantic segmentation and draws parallels between computer algorithms and the human brain in identifying objects in volumetric video.

2. The author has led a hackathon involving EEG and VR technology and is writing a book about brain-computer interfaces, neuroscience, and artificial intelligence. They developed a unified field theory explaining how the human brain generates conscious experiences and reality, and utilized AI to turn the theory into actual equations and developed an equation for a modified Schrodinger equation.

3. The article explores the concept of brainwaves creating a blank canvas and loading objects into brain space, delving into the idea of brain oscillations creating wave differentials representing thoughts and perceptions in the universe.

**Synopsis**
The article discusses cutting-edge technology such as volumetric video and 3D semantic segmentation. The author draws parallels between computer algorithms identifying objects in volumetric video and how the human brain may function similarly. They mention leading a hackathon involving EEG and VR technology and discuss a book they are writing about brain-computer interfaces, neuroscience, and artificial intelligence. The author developed a unified field theory that explains how the human brain generates conscious experiences and reality. They also mention using an AI to turn their theory into actual equations and the development of an equation for a modified Schrodinger equation. The author discusses the concept of vibrations in the universe and how the brain's oscillations create wave differentials that represent thoughts and perceptions. The article delves into the idea of brainwaves creating a blank canvas and loading objects into brain space.

# OpenAI Whisper Transcription

 So I was like, I was watching this, the most cutting edge technology that they've got.

 So we've got like volumetric video where they like, the video is in 3D and you stand in the VR headset and you can, they're playing a video, it's like a video, but every pixel is plotted in 3D space, so you can like look around the video, right?

 And it's called volumetric video, you can like look around and see it in 3D.

 It's like the whole video, it's like, imagine like reality itself is a volumetric video, you can look around and see it in 3D it's like the whole video, imagine reality itself is a volumetric video sort of right, like it's like a video is playing, except it's interactive that's the big difference, volumetric videos are not interactive but you know, I'm just going to buy one of these so then, there was this thing called 3D semantic segmentation how does a computer, if you're giving a volumetric video to a computer, how does the computer know that this is a computer and this is a desk and this is the floor and these are shoes and this is your nose?

 How does the computer know that?

 And the thing is, there's all these sorts of things where you run the algorithm and it says, okay, find the dots, you find the dots that are closest to the closest dots.

 So everything in space is a different dot, right?

 And the dot here and the dot here are close together, and you run the nearest dot algorithm, and you try to say, okay, maybe these dots belong together, and these dots belong together, and these dots belong together, and all these dots, they kind of have, like, from one angle, they have the view of a desk, and so we're gonna do semantic classifiers.

 These dots, all the dots in this space, they kind of have like, from one angle, they have the view of a desk.

 And so we're gonna do semantic classifiers.

 These dots, all the dots in this space, they represent a desk.

 And that's called 3D semantic segmentation.

 All the dots in this space, associated with this monitor, that's a monitor.

 And so the computer is algorithmically figuring out what dots belong to which thing.

 And when I realized how they did this, I was like, maybe the human brain does something like that.

 Right?

 Because we are neural networks.

 Maybe.

 That's true.

 Sorry.

 So I study, because I've interviewed lots of neuroscientists.

 So I've interviewed lots of people in tech, lots of people in neuroscience.



 I've also led a hackathon called Noisebridge where people just meet up and use the computer and work on tech stuff.

 And I've led a bunch of meetups, like every week for a year in 2018.

 We brought EEG into virtual reality with WebVR.

 You put on a headset, walk inside a representation of your brain activity from the center of your forehead.

 And it was so cool.

 And to this day, nobody has replicated that project exactly the same I mean, other people have done EEG and VR but not EEG, but web video That's cool! Yeah, exactly So, my book that I'm writing is about brain-computer interfaces and neuroscience, or neurophysics Were you writing a book?

 I was writing a book, yeah So the first part is about brain-computer interfaces, the second part is neurophysics, and the third part is about artificial intelligence.

 As a journalist, I've been studying all these different categories, neuroscience, actual biology, from the whole brain to individual neurons and cells and stuff like that.

 And I figured out how the human brain generates phenomenological quantities.

 And I'm writing about it.

 Yeah, and you can read it right now if you want to.

 I stumbled across, I developed a new unified field theory.

 So I have a theory in mind which is an explanation for how the human brain works that we can use to make robots that are conscious, conscious that render a representation of reality that their conscious existence is like human existence.

 Right?

 Figured that out, that's a theory of mind that explains how human beings, how human brain helps you create the experience of being you and having the experience of reality because it's like a computer program that your brain is your brain involves this neural network, this complex neural network to render sounds in 3D to the organism that is you and even develop computationally a character that is yourself.

 Oh cool! Yeah, and so not only is the theory so late, it's not just that, it's like down to like individual neurons, highly individual neurons are doing computational rendering to 3D semantic segmentation of recognizing that these points are space-time objects, right?

 And, so we've got three of these, I'll take one of these three, and I'll get it.

 So this led to, so I got all the way down to the nitty gritty physics of it.

 Physics of waves, of rain waves, of basically, if you have to, there's a big thing in consciousness, how does consciousness relate to physics?

 This is like a big open question.

 Anyway, the long story short is, as I was working through these problems, I figured out a new theory of everything I would call unified field theory.

 And unified field theory explains how gravity works at and I use ChatsDBT which is an AI to turn my theory into actual equations the modification of the Schrodinger equation.

 Oh cool, so you just told Chats, do you need to write it for you?

 No, I came up with a theory a year before I talked to ChatsDBT, I wrote all of the stuff about this theory and then you told it?

 Then I told it to ChatsDBT and of them have developed an actual equation for it.

 A differential equation, a modification, according to your way of equation.

 There you go.

 So I have an actual equation for a unified field theory, which basically, there is no unified field theory.

 I have the only one.

 I came up with it.

 Oh really?

 Yeah.

 Did you get the feeling of it?

 I think so, didn't I?

 I think so.

 theory, and a theory of lines.

 And I'm plugging off both of those in my book.

 Which I'm working on while I'm working here.

 

 Her name is Esther Hicks.

 She channels this alien voice named Abraham Hicks.

 And Abraham talks about how everything is vibration in the universe, and she says a belief is a vibration, which is actually right. She's right and she didn't even study neurophysics or anything, but basically, your brain has all these soliton wave oscillations, electric, magnetic, mechanical, acoustic, chemical, and heat-related.

 Basically, by oscillation, it's like something that happens over and over again in a cycle.

 All of these oscillations, basically, they create like, there's these tonic brainwaves, and they're very repetitive, and Neuroscientists have argued that tonic oscillations have no information in them, just because broad spectrum tonic alpha or beta frequences, at least the averaged result you get with EEG is like pink noise or brown noise.

 So you can't really extract information from something that's so regular and so repetitive, because it has low information value in the context of information theory.

 But what happens is, when you see something, when you think of something, what happens is it causes these ripples, these sharp wave ripples, where your brain spikes to a degree that's different from the standing noise.

 And that difference is a phase wave differential that happens in sequences in space and time within your brain that represents the things like this which are phase wave differentials inside your brain that are distinct from, they're dominant from the standing wave imagine that, have you ever seen the Star Trek holodeck?

 you know what it is?

 like holodeck, like like um ok, virtual reality, virtual reality you know how like, virtual reality has like you saw the matrix, the Matrix I've heard of it I don't think I've ever seen it but yeah I know what it basically is so there's like there's like the loading program is like right the loading program for the Matrix is like this blank room and there's nothing in it.

 So that would be like, imagine you're in a room and there's no walls.

 It's just blank space, forever and ever and ever.

 To be silent.

 And there's nothing at the end of that.

 It's just blank.

 Just blank.

 Yes, it's like, it's almost like a Gansfield of like, could be like a white light or, it doesn't have to be white light, it could be black.

 It's totally dark.

 So the idea of this is no contact.

 And the idea is that your brainwaves, because they have no noise, they're basically creating blank space, blank canvas.

 And then if you have an object that appears, you load objects into your space, into your brain space those are phase wave different programs, they're rhythms or vibrations that are different from the room they're different from the what that is.

 