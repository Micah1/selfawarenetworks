The NerveGear Show

Nov 2, 2017

original audio/video here https://youtu.be/p9yTPBrrES4

(auto transcript needs fixing)

00:00
Michael here with and and I'm here with Sarah. Who's with virtual bites? Hey. And we're gonna it. Yeah, let us know if the audio is better this time because we're gonna try to rework the, the nerve gear show we take yesterday. So I hope the audio is better this time.
00:20
So so I'm so sorry. Here is a neuroscientist, you know, and where did you study neuroscience? I was studying the second because it's really hard to actually do people's getting approval experience in yours, and I opened and remembers the VR lab in my department. And I was researching how premature reality can affect our brain.
00:52
And in fact, our preception about our body, you know, and now still doing this for and execution and users are like them. And we really wanted to put the story to these ideas about what this technology can do for brains that the goods that eyes and also the possible babysitters should be considering.
01:13
And we found out with two demos every month to just use it wacky ideas that we have about, this is technology can do and you can always, you know, repeat under the vertical, but great. So so yeah, so virtual bites, they're doing like research by building actual VR apps.
01:32
Now tie it into their neuroscience research. And so virtual advice was actually at the first SF0 360 and September. And again, in October, we had because we're doing a monthly events and so, you're actually going to be able to see Sarah speak. By the way, at the SFVR, note them event, which is going to be at the Microsoft reactor.
01:53
This is the SFVR logo. One of them. We we have many different versions of this logo. I'll show you another one real quick. Grab a camera. So this is our other logo and so gosh, I really hope people can hear us, okay? I could see that like a fee, but okay, so I want to like we got we talked a lot of neuroscience last time, so the nerve gear pipe, the nerve care podcast was sort of like, created about like, you know, how my like I really wanted to say how could we accelerate the point in time, in which we do AR and VR with that headset and with just by sending signals directly into the brain.
02:34
And so we have this time we got a bunch of brain images here so it's a really complex problem. But in general, I'm really interested in building next generation, brain computer interfaces and they happen. I'm a study neuroscience for 12 years and I have a had a neurofeedback business.
02:53
So we were combining in 2012 year, combining EG taking EG signals, which has noted, they're very noisy consumer grade. Each is very noise, it's very bad, but we're enlightened sound effects to the biometric singles. It was picking up and that, that would include signals that are mistakenly muscle signals.
03:14
Like, if you move your eye and stuff like that, easy sensors, the job is that eliminate as much of that noise outside the spectrum of EGs possible. So you're not picking up, ECG or EMG or just reminded people that it is from perspective. And one of the biggest problems of ETGs it again, with, pick up all of us comparing myself and that are significant guys and you're reported decks.
03:42
So we're losing a bunch of bunch of the data even just a bit again with us. That's right. Yes, I'm pretty sad, for example, these sensors are usually measuring something between zero and and 200 Hertz, but brainwaves go up much higher than that, the the so there's a neuroscientist.
04:00
I got his picture. This time is gonna grab this real quick and show you this. This book is the neural basis of free will by Peter's sea criterial, causations of subtitle. And that book is really great because it served like and we also got the on intelligence book here.
04:19
He lost me and also got, this is on a telegraph and let's see. We also we also got networks of the brain by oral offspring, say that right there. So what I was going to say was so going to Jeff Hawkins book real quick but then we'll go back to Peter says but so Jeff Hockings book and you've read his book, he talks about how grids of cells are complex enough to to measure a.
04:51
Like a three degree of cells is complexion of to measure. A really complex sequence of inputs from any sensory operas can be very general learning algorithm the stores as spores like. So you have incoming, inputs from eyes, or ears from your nose. And it can store unique patterns with amazing complexity.
05:14
And the patterns that it stores are based on patterns that came in and those become predictions for what patients. So if you get a partial pattern that comes in it triggers that same network that responded to a larger pattern to retrigger. The okay. This is really nice, just hope.
05:36
It's a lot of access. The first time going to like this, I guess this is smooth. We are because I can really be controlled in incoming images. So the brain and the decide, whether these inputs are the normal protections. The people are already have or whether they feel, right?
06:37
So when I'm looking at you right now, and yeah, you have a sort of habit or that it is predictable. But then you have this you're the whisker thing that creates novelty for my very right. Yeah, is the currency you really get a night. And I like to think of it, that's gonna be the great work.
06:55
So that'll give his passed on to about the parts of the brain around being tested use that ethnic explain the novelty. This is world people that we have, right? So so Hawkins book, really drives how our brands might formulate models with the world based on sensory inputs. But then what was really great about periods.
07:17
Seasbook or Peter says book, the nobel basis of free will criteria. Causation is he then says, well, they in the brain says, well, maybe every neuron is a coincidence attack really quint and the maybe the basis of a bit of information. The brain is a coincidence. And and with that means is that if you have a higher key of cells like this, this is rightly believe.
07:39
This is a Jeff Hawking's work. So, you'll see a hierarchy make this bigger then. Okay, magic. So if you have a higher, give yourself. So let's say that you're the lower, the inputs. Let's say you're your eyes when the census come here. Brand, they go in through the bottom of the hierarchy first.
08:01
So, let's say your eyes are over here, and to have a better one, but so they go to the hierarchy. So, what happens is like, at the lowest level, the hierarchy, your brain, just like an artificial, note would be recognizing lines and edges and curves. And colors is blue light or red light.
08:19
And then, at the second level of the hierarchy, or the next couple of the hierarchy you, it's gonna combine, it's gonna combine and these lines edges, go together. This color goes with this edge and at another level, you know, these lines edges, could be, you know, like an eye or something and it, and at a higher level in the higher and how you open are here, and hire you up in the hierarchy, or the deeper, you go into the brain, the larger, the chunks, get so, then you, when one level you're looking at eyes, another boy looking, is this a dog or a cat or, or a car at?
09:00
And this is how is how, like, the self-driving cars are designed to work. Where you see if I have the self-driving car, when I don't know if I brought it but so the idea is that the self-driving car is basically using deep learning neural networks to representations of the world.
09:18
It's in its concepts are how all the wines and edges connect at a higher level in the hierarchy of the network and so that. So basically you can see the basis of a concept for an artificial neural network is all of the is the map of associations between all the lower level bits that come in through the base of the network or the sensors.
09:40
And so people don't maybe some people don't think of there. You think of your eyes like one thing. But it's actually like loss of different sensors and lots of different, you know, edge detectors, and color detectors. You have different layers. Hey, and what's interesting is that we try to talk about hours.
09:59
Oh, this is a sense of itself. Right week under this our operating abstract a sense of self-sup. Yeah. So and I I think that you know if you look at like so look at it I was gonna get the book for Douglas hostage, Douglas top seller says that the self is a strange loop of.
10:18
So it's like a learning paper. So, you have all these concepts the world. This is a dog, this is a cat. This is a mouse. And then the you had the, if you had a self-harming car, or a person, observing the world long enough, they begin to notice features about like the self-driving car.
10:36
Should begin to notice features of itself if it could see itself or it's relationship to other things. And if you had that in a feedback loop, it would begin to perform permanent model of some. And some sense it has like it's not a self-aware self but it's like a self.
10:51
Like can I move forward? And it's to get a self-aware self. You'd have to have not only a model of the self, but you'd have to have it in a feedback loop with all the other data. So, so I started this that we couldn't even try to share.
11:15
So you just currently it's difficult for another hand, your brain. Just tastes the data is. Yeah. So you're so your brain is here. So it's just like your model of yourself is is just data that your brain is putting together. And, and that shows the clothes that we wear the tables that we use, they all become a part of this, the self model of what we think of ourselves.
12:40
And in, you know, the biggest bodies having we have. So, the people think there's this, the, you know, people call consciousness, the hard problem. Like, how do you explain what that is? And I think that, you know, there's several components to it. There's, there's, there's an audio component. There's visual component.
12:57
But what? But just imagine, like, and and animal in nature, what I'm, what I'm saying is that it's basically like it. Let's say this is a brand and this is the world that the animal is seeing. And basically what you're saying right now, like everything you're seeing is idyllia that your brain is taking through the sensors of your eyes and and through the hierarchy of the neural network, assembling into a coherent picture.
13:23
And the reason it's the reason it's like a, you know, an active conscious experience because it is for the brain, a temporarily active brainwave pattern and in the, in the temporal reality of it is something you could observe, when you like every every emotion every modality has, you know, like like a sign is like a stock anyway.
13:44
It has peaks, it has lows because like, when you, if you like to say, listen, imagine that you take a second of consciousness and divide it up into milliseconds. You have a thousand milliseconds of consciousness and you look at it like a movie. So it's like you know, if you take a movie you need to bite it up into 10 seconds or something.
14:04
And you looking at each frame, you say what is happening in each frame of this movie? And you could say, well in one frame of the movie the animal or the person is looking at a laptop and another frame. They're looking at the next to the laptop, and this is your laptop from your work.
14:22
And then they're looking at Sarah or I'm looking at Sarah and then they're looking at it. Yeah. And then I'm looking at this table and these pictures and I'm hearing my voice and so in 10 seconds of conscious as I have this sort of like to grab this one right here, this is a picture that consciousness and not person, okay?
14:49
I guess school of thought would have come instead of this word it's an illusion. I think it's a useless word. That's not getting us anywhere. I think we should certainly looking at these new words that we have 86 billion of them, right? Yeah. And the moment we ended up get activated.
15:07
It's what we call consciousness, but that exists because, you know, enough of it gets to this area of our brain, we can convert it into communicated to others, right? So a lot of people consciousness is just reported idea that ability that I can report or something to another social or writing.
15:30
But so this fact that we're, you know, another product of our brain or being active debated, and not under the majority, or the specific network, doesn't mean that cells are not contagious. A lot of athletes people. That dance everybody that the flu state, you know it we are extremely conscious when people what exactly my body was doing.
15:56
And I have got to let go, the brain has to go over this, a little verbal part, to be able to get into the moment and then move it to reality ended that way. So this is an illustrator that so I know I hope the sound is better on.
16:14
The actual thing is that way, where's that? I don't know. There's music. Well, I don't know it. Where's that coming from this man controls. Oh, I'm so sorry, but I'm what I want. What I wanted to show was settings here, how to my perspective as you can't. Yeah, experience.
16:53
So, very worldly. What can I pass you? Let's see. Is there like a piano? Here's a nice. Maybe. I think you can roll the dice and we're a little bit. Give it to you, Here, we could. Before we cannot pass again, why they're saltinated with VR and hacking on every brain because as we can really control things and control their environment and ways that we never have to, we never had at the same ability.
18:02
So can you see this about the visual set of it's about everything around us? Yeah. So you can see this. So this is and illustration of a neuron. Yeah. And the density of neurons which you were just talking about the very densely packed in the brain and so an example, neuron, let's see what I wanted to show you.
18:20
Was we have this which is a. As you can see that there is the when I should start with this one first. So, this is, this is an example of different networks different. Yeah, different networks that are activated different. Yeah, different email, specific conditions like I guess. Yeah. So so the idea is that you, when you, when you are neurons activate in a circuit, you can see.
18:49
And there is a video that I got, but I'm not gonna show it, but I wish I could turn out the sound. Let's drive me. It's really driving. That's like, that's not fair meditation. Yeah, but okay. Let's try media upstairs, it explore.
19:16
Let's try to cut this again. Yeah. Okay. Let's see where this happened. Okay, I don't know where that's coming from. But now we're in a different like location. It didn't stop. Unfortunately, that didn't stop the that back noise. Yeah. But is that coming from anyways in your head? So what else can say with this when you have a neural circuit you have a sequencer as it could be five or six, you know.
19:58
It could be a lot of neurons that are lighting up in a swims and they're not necessarily directly connected or we not necessarily aware of all the connections, but it just have a specific again. It's a physical properly designing, right. And so, but you can say that because of the if you like watch it, watch videos of this.
20:16
This activity has been mapped. It kind of suggests that our brains neurons are lighting up, and it is a kind of suggests the electromagnetism that are in our neurons are activated by electromagnetic system. And the point that I like bringing up is that, you know, maybe because we have these, we have our dendrite.
20:33
Let's see, this has dendrites, but yeah, we have, you know, generated that is a genderizer computers. They're like many computers and they have all this amazing processing capability and idea here. What? Yeah, so the idea is, they have all these. It's like, they all have these amazing. Like, it's like, it's like they branch like trees, right?
20:56
And they have always different hairs and they can, they can actually convert, they get a very complex ways. Yeah. And in a parent and apparently decided wanted to pass on them and what they get and make appointment is very chemical, giving them a term for them. Sizing in them is a bit problematic together, extremely intelligent in their own ways.
21:20
So one of the ideas from the neural basis are free. Well, Peter C was a in something. He's like, he's just trying to say that and some cases we make our decisions for what we're gonna do in advance. Like the, and there are decisions are based on, like all these little tiny bits of criteria.
21:33
So, if we encounter some situation, or some person that matches all this great material, then we have already planned acting away, and that's sort of gets around the idea that your decisions are like, you can see your just like in, if you're measuring a brain waves, you can sometimes see your distance before your personally aware of it and exactly, but that it could be possible that that's because you sort of planned your two decisions of what you would do, if certain criteria were met.
22:04
And so that's what he's trying to say that maybe it's not that your decisions are being decided that you're conscious awareness that you're your sins are being decided at a previous time when you decided that and then there's sort of maybe perhaps stored in dendrites which can active their own action, potentials, and start causing neural activity.
22:24
And so the dendrite is perfectly positioned to. So normally, when we see, like, see we just grab a picture of a neuron here. Normally with nationalism. So normally in taxpayers say they say like a neuroscience text box. I say that the action potential travels between cells and a chemical synapse and it's early but it's actually traveling cell body.
22:49
And what travels between neurons and a chemical synopsis is the neurotransmitter. So you can see with medical imaging that are, it looks like there are electrical signals passing between neurons and look at medical imaging. But with what's actually happening is that action potentials just passing along the body of a single cell.
23:08
And what travels between is, is our chemical activations. That can trick ourselves further down the line. But what you don't see in all these textbooks neuroscience is the really complex mappings between all the neurons. So, this is like this, right here, represents this right here and this is the dendress, the generic could activate something.
23:26
Then as you were noticing in the in the previous call, there could be between 10,000 and 200,000 connections between all these different cells. So the question is, like, when you have a neural circuit which are bringing this one. If if point, like let's say this point is a cycle of activity.
23:41
If each points connected to 10,200,000 other possible neurons, how is it possible that this circuit lights up in a consistent way? When that signal could be traveling down any possible branch? And so the hypothesis that I have is that the dendrite itself when you're which what you say, you have a future decision, you're going to make the internet itself is going to when all the criteria event, it's going to become the lowest possible negative and I mean, electromagnetic negative.
24:10
So like a lightning bolt will strike the the monkey negative points on the earth. And so that would be a way for a dendritic computer to attract a signal to itself. And thus, it would allow for an organized neural circuit where you have a consistent pattern of activity, where these would be the entries that had the lowest point of electro, electromagnetic, negativity, and you in there, attracting the signals to themselves, creating a consistent neural circuit, and the brain that resembles a highly coordinated pattern action.
24:42
And so when you have a neural circuit, like imagine that each one of its listen to match, we have an arrow circuit, that's very general. And one room represents the. Let's go back to hierarchy of patterns in your brain. So you have patterns represent eyes and some of the dogs and cats.
25:00
And you have the sky brought at this time, but you have this guy, his name is Jack alone and he got in a cortex, all these semantic relationships between neural correlations and like, indifferent things that people see in movies like dogs and passing houses. And and so he was saying like in different parts of the brain.
25:21
He said you know dogs will be here, cats will be here. I think let me get that pen and so he says he would say like, you know, somewhere over here is dogs and some over here is cats and over here is is motorbikes and some of it, here is cars and cars and motorbikes will be closed together and dogs and cats be closer together.
25:38
And people enclosure dog and cats and far away from from motorbikes and cars to and again organize. Yeah, so all these sensory patterns would be creating like so this. So this this would be one part of your neocodection and maybe from your eyes and this would be creating like a or eyes and ears and this would be creating like visual pattern.
26:05
You have audio patterns and then the different parts of your brain would represent that and then when you have your neural activity which is starting getting busy. Bye. We have your when you have your neural activity idea is that intense second and one second of neural activity, maybe you're, maybe you're seeing someone like, I'm seeing zero right now or you're you're I'm seeing this this image.
26:25
And in the next millisecond, I'm hearing my voice and the next one. I'm thinking about myself wearing this headset. And the next bill is second. I'm looking at the world behind Sarah and in the next one, I'm looking at the pictures behind Sarah and each second is made up of all this, all these conceptual models, which consist of coincidence in the brain, and there are light upon a sequence in a neural circuit and because they are and anyway, because of the dendritic computation and so then you're talking about this information directly from the stall distributed.
27:07
That's right here with a pretty interesting idea of information. Where there to see that down? Feedback? Everything can seem. So almost few things. Yeah, I think to try to get there. So if we're trying to like imagine how the brand actually, let me grab this one right here. If you're trying to imagine how the information flows to being, you know, with with regard to the visual cortex, I can see the eye is megurate that pen.
27:43
Again, this tracking is not so good, it was much better extra day but so imagine your eyes like right around here, right? And so you have, you know, photons are bouncing off your, give me a and your ganglia are the proteins are flipping and it's causing ionic, displacement of calcium in potassium, ions and the separating of charges positive negative charges, and that results in an action potential, which is triggering chemicals.
28:14
Synapses. And so, you see signals and medical imaging traveling from the eye, to along the earth, to the thalamus, was here in the center was putting on mark right now. And so the signals travel, the optic is optic nerve this thalamus, and then they travel back here to the visual cortex.
28:28
This is the it I've said for loves and these are the parietal lobes right here. And, and there's something similar happens with ears. So with your, you know, you have your ears would be out here somewhere. Let me get a different marker for years and I don't know if they can see this years to be out here somewhere.
28:44
And again the signals are going to travel to the thalamus and then they're going to travel to the audio cortex. And so the point being that like you're your eyes and your eating your ears and most of your senses, except for your nose are going to travel through to the thalamus.
29:02
First now is talking to. I went to I meet up and I saw David Ecomitt who's a kind of a well-known neuroscience author and he was saying that, you know, if you're trying to, you know, if you're trying to like use a medical imaging to oh what are you trying to get?
29:17
Yeah, you better myself. Let me send this here. So if you're trying to do medical imaging with EEG from the scalp, if you consider the work, if you consider the work of jackal one, all the semantic, relations are spread out and a sparsing distributed pattern all over the whole brand at the point in the neocortex.
29:39
But if you consider the only the incoming senses, go to the town's first, it's Alanis could be the optimal place to look for to create a new brain computer interface if you could, if you could have a sensor and so I know of some new sensor technology that's coming but you've got a sensor that you either insert up the nose to target the thalamus reading or point it from the nose up to the nasal, to target the dominance.
30:03
And you can the sensor. It's like a light field sensor before electromagnetism and you can configure it for. So, you can notice the orange point of a brain that you can predict camera for electric, for, for brains. And then, if you can map the signals coming from the analyst, then you have the signals before they get more broadly distributed, across new cortex would be where.
30:24
And so, which interesting is about the dominance is that nonemergency go into your, you know, cortex. It goes through the thousand. Neo cortex and just, you know, all the semantic map is all over the place but that's stuff is a big feedback. Looks back into town. It's like the thomas is like the the bottom and the top of the pyramid and brains like a big feedback loop.
30:42
And so I through the neocortex and back into the columnist so that could be like the integration point for all the different sensors into modality. So if you're if you're saying a dog and a cat and a house and a motorcycle and a car at the same time, it could be that those things are you know being grouped or being like there's a neural circuit that's it's running through the you know cortex and passing that information back into the thalamus where it's being integrated.
31:07
And I think that that could be true. I know. It's so the idea here is that if we could take this self-driving car type of computer to put in the backpack and it can formulate a, you know, like so there's just really cool. This is three camera company just really cool, like AI that can recognize patterns from pixels and also draw like shapes around the recognized patterns.
31:32
And so anyway, idea, is that if you haven't AI, look for the patterns or something in a world like what Sarah's drawing right now and says, trying a car right now. So I guess all these lines and edges, that represent a self-driving car as a conceptual pattern in the computer could be.
31:51
Oh thanks. Thank you. Now, we've got a card. So, the idea is that, that concept can be recognized by the computer, and at the same time, we, the idea is to apply some new brain computer interface, and deep learning programs to studying the brain looking for narration neural correlation nurt correlation to the outside world.
32:14
So that we're creating combining the conceptual models of the world. The computer recognized within sexual models that the computers make of our brain waves to say, well, this car in the world is kind of a car matches this brainwave pattern. And then the next step is like, we look at the work of like Olaf sports, right?
32:33
And that was so the brain safe, the brains, like a network. What is the communication protocol? Is it more like TCP is a QDP, are we throwing packets or reserved from handshake as their feedback loop, that sort of thing? So that's one of the things we talk about. If we can figure out the communication protocol with the brain, which I I think could be alternating transmission protocol, which is need to all change between TCP and UP type of connections for conscious.
32:56
It would be. I feel like I'm I'm taking up. I'm just like a but anyway. So if I'd like to, yeah, I'm talking yesterday because of that, I do feel that this is part because I am in control of some of the movements. Yeah, it's a moment. There's like that it didn't come from my body.
33:30
Anyway. Goes like happening here. Yep. So the reason I have everything that there are designed to start thinking about. So I'm part of this group that makes this program called microsphere vision agency and what we're doing with my photos of yarn. What we're doing is, we're combining VR with EGs and it's clear.
33:52
So it's creating and show you. Let me show you an image of the of the graphics of my if I have it. Yeah. So micro dose has amazing graphics. Okay? And so you get with your controllers and you're creating these amazing graphics and show you this realize this. And then what we're going to do is we're going to have your brain waves it's already thing.
34:11
This is in the nearly podcast number five, I talked to Android Jones. They we got this headset from use and let me pull this music down. Okay, around that, what did I do with my name? Sorry. So we got this headset from us. Okay? And the news headband and it integrates into the Facebook.
34:31
You can see that integrates into Facebook, some not know any screens into the divide headset. Here's another. This one is another easy four or five headset. And so anyway, we're looking, we're looking at the right now, working with me as we're looking to get about. But the point is that your brain waves can dry a changes to light and sound effects and microdose, VR, and that enable you to become aware of how your thousand feelings are brands and how those brainweights are causing change.
35:00
The light sound effects. In fact, it seem to change the light side effects. That sort of like expand your redness of your brains. And how your thoughts and feelings are brainwaves, or our reflected in brainwaves, is what I meant to say. It's really interesting and funny experience, another micro gospel, but go ahead, your turn.
35:20
So and I love it. Here experience is my that I've tried and have you tried my number? That's my interview experience. Yeah, well you know it was so the next video yeah well the thing is what? I'm when I'm organizing it actually, okay, I'll download it because I was organizing it.
35:41
I really want to actually try. I did try its experience again. You're giving me different music and effects. And that's great about letting go of a neural reality and the normal world models and updating things and getting a related armor better. Those ... Or it just a device that can then receive electromagnetic signals and send the the pattern.
37:15
It's finished between the punish you have in your thalamus right now and the pattern of what your thoughts would be, if you had something in your reality, like these, like these glasses, like these glasses right here. If you had that passive you, that is it. You have this pen in the computer, you can send it back through the transmission protocol through your electromagnetic signals.
37:35
Caused your neuron, in your brains of fire in a pattern. That is isometric to the to the pattern that that the computer recognized when you were looking at glass and you would see glasses in your reality. They're not actually there via so it's virtual reality, it's sent directly to your brain, basically, any pattern you could create for your brain, if you know that pattern has no transmission protocol the brain.
37:55
And that's the that's like sort of finding a part but the really sort of like useful and not super fun. Part is that if we understand how much of neurons can make other parts of their eyes, understand how those communication signals are packed in, what the dat, we could things like reconnect spines and we could finish artificial lens or transport.
38:13
You are set yourself into an artificial body and you could have like a mechanical. We could be a little bit of that now with VR. And so, what we've been talked about in a sense is the convergence. So all these great technologies like artificial intelligence and virtual reality and medical imaging, like EEG.
38:29
And so, we're beginning to see the convergence of like biometric sensors EEG, like heart rate, sensors and eye tracking, people dilation sensors into your headsets coming. Anyways and people are figure out how to combine you know of course blockchain and all these other great technologies and drones together and that is the topic of our meetup in November where there's gonna be talking, the San Francisco PR is we're gonna be talking, I'm gonna be talking about it was maybe one of a different things that's that.
39:57
No, it's it's there's a honors potential for healing from the artist. There's also like enormous potential for you get that vehicle. Very responsible because you can use this definitely a potential to do the reverse to not do the good things for mind. And again today, why would two third element you yet?
40:22
So much pretty disturbing of affects that might happen. If we don't think it looks like a little bit, a little bit more about your your company. And who's this gentleman here? The extra with you at your company. Matt, so that I've met oh and you need people can say people can.
41:12
Yeah. Okay, that's a co-founder. And I use a PR because remember different. I'm the more and a good way to sort of just go through one of your and you can just create web sites that will work all the confirms and that sort of is and project we're doing, is it gonna be based on under that memory palace experiment NCGF, you can learn French better and it was just using your words and in an experimental condition.
41:49
But when we're very curious, it's being and an immersive place or expertise using visual imagery created, whatever. I could literally take to learn the words with you, remember them better. So that's, however, I wish I could grab this but I can't. Okay, go. One thing that I think might be useful explaining why we are could be more powerful for learning and
42:25
To decided to shake which is so. So thinking about this for a while VR can have special powerful effect on your ability to learn and could come down to this concept of criteria. Causation, the idea is, if you have like, if you're not answering detectors and you're hierarchy of detecting high level coincidence patterns, and with your, you're creating this world around you, this world of information which is creating a lot of different control, right?
42:54
That's the design of what is the coincidence. So we're saying it was that you had this volume of spatial information. It takes up here, which space when you're in BR and that could definitely lead to causing your brain to trigger at a high level when it's trying to absorb and learn from all the information question, that that's a very big thing to like the fact that it's early, my individual says correlated to my microphone, it is, that's very important and we can get out to be.
43:25
So the more sensors you get into it, the most is reality. The vertical part is to just mean something to the forces of the picture. Okay. So okay we're gonna wrap it up and I'll say that what we call the guys we have for speakers. That's Sarah and Richard Vice must have decentraland.
43:42
You mentioned that Matt saw is really into web VR with the central line is gonna be talking about convergence of web with blockchain, which is what I think, maybe not the other city or yeah. All right. So, all right, so we're gonna go ahead and end up. Thank you much, Sarah.
44:01
Thanks for. Thanks for watching person as watching. We got some point but we'll see about the sound and yeah. Okay. Truth.
