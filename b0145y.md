b0145y ctpr

(audio transcription needs fixing)

Michael Graziano Consciousness Attention Observer

00:01

Yeah. So my grazio thinks that consciousness might be like a module that you you add it and then suddenly, it can have a concept of self and think that's I think that's incorrect. I think that that the self-concept can be learned like any other like any vision like a visual concept and audio concept and to be able to have language and speak about yourself is something that a machine could do unconsciously the machine credit card constructor language dialogue that describes its own that just that describes you know you can even because it's because the machine because the human being hot you have you don't you're not born with this representation of yourself, you know at some point you you just you don't have language, you have to learn language and but you see and but you have to figure out, you know, your eyes have to learn.

01:17

Like if you look at the book, actually the perception, you know, the story is, some people lost their eyesight, regained it, but that they had no eyesight for such a long time that when they regained their eyesight, they didn't immediately understand what they were looking at. And in some case is they what they thought they thought were black.

01:39

Holes would looked like okay we looked like crazy black holes later on their mind figured out that those crazy black holes were actually windows in another in another building across the courtyard or self or something like that. And so there was a sort of like relearning visual learning that over time through the action and curiosity of their own intention and attentional processes, they were curious about their incoming sensory impulse to their eyes.

02:19

And they were now continuing to look at those crazy black holes until they figured out that that they were actually windows. And they had rectangular shapes and that they had borders and that they were in the context of being parts of building. And this was a sort of like visual conceptual buildup.

02:39

And and I suppose at the same thing happens when someone's newborn that they look they may look around as if they understand what they're looking at. But there's no reason to think that they do that, you know, that the restoration of site to someone who hasn't had site for a long time.

03:04

All right. Sort of like, paints a picture of what could be happening to newborns when they first come out of the womb and they look around in the world. It's they are not able to make the kinds of distinctions that that that adults can make, you know, you well their eyes can can can look and you might project that they understand what they're looking at, but of course, they can't.

03:39

At that point. There's no language. They can't say anything. It's it's it's hard to say what? What what's going on in that? In the mind of a newborn. But, but let's just stick with the idea that your eyes have to create visual models. Your ears have to create auditory models.

04:07

Your idea of I'm sure your visual cortex and your audio cortex. You're your brain has to create models of each of your sensory representations and and, and at the same time of receiving the sensory inputs also, receiving motor inputs and so it's creating a model of your own motor activity.

04:26

Then includes the sounds that you make. And, and, and the, you know, the audio cortex having to build a model of the sounds that you make not just tracking your muscle movements, but correlating the sound so you make with your muscle movements and your eyes are tracking hagger. Your body moves and on the visual spec individuals, the same.

04:47

So you you can fill your arm moving, you moving your arm, you're seeing your arm, you're hearing your arm when you when you when your arm and collides with something or claps, you make it clapping sound with one hand. I've heard that what exactly is that? Does that sound like okay?

05:09

Just listen for a second to that. Tears to your exterior. One hand clapping.

05:22

Different just listen to it. And, and

05:31

Yeah. So we have these, these are models of the South and ended. There's no in principle. There is no reason why a robot can't make a model of itself. An addition to making models of the rest of the world. And I think that's what Michael Graziano is missing is like, it's not like, it's not gonna be like the is some consciousness module you add it.

05:56

So you, so you have these sensory modules and you have to add a consciousness module. So that you're so that you're so that part of your brain is just modeling. It's just now capable of modeling conscious because it has this additional module. I'm going to veto that idea. I'm just kidding.

06:19

I'm like it's not that it's not that it's definitely wrong. It's just I don't. It says not an idea that I am in favor of because think yeah, it's not, it's not

06:42

I think I have to go back to the idea of you have observed observer mechanisms. You don't have a central observer but you have observed, a mechanism, that correlate. And so these, this the OSC,

07:06

And and yes OSC is separate from the attention mechanism, they're going to be separate the from the observer effect, right? Because you have incoming streams of patterns, but that but

07:30

Me. So it might be that it could be that the TPJ represents some sort of peak and that in that hierarchy of the both observers and attention. It's like when when observers in attention, collide, maybe that's the peak of the hierarchy of brain in a sense. And I know, NOAA sounds weird, right?

08:07

So you say, okay, well obviously the incoming senses, the primary sense record issues, which include the TPJ, where include the location of the TVJ. So those are lower in the hierarchy in the prefrontal. Cortex is above it. And that argument is okay, but but, but maybe the signals from the

08:36

The prefrontal because because there are, you know, I we want to say there are a lot more distant from me, the incoming sense. But again, going back to graph networks as applied to networks of the brain. It could, it could be that a lot of the, it could be that there's a lot of

09:07

Because it could be that the if there's so much interchange and traffic that the, the real peak of the brain, isn't the frontal right of lobes. But it's actually closer to in terms of like information flowing from the that the front of vital back to the TPJ again, I don't know.

09:43

But we have some coordinated, some activity coordination, across the corpus callosum. And we have, you know, there's a lot of connective, there's a lot of connective areas. The, the fountain, the, the filmic produce and, you know, brokers and learners area. There's a lot of spots where

10:20

Where this way separated information seems to converge, you know. And and coordinated way, right? Some areas seem to be more like, you know what? We have. There's a lot of thyroid cortical condoms, right? And the cortical columns are are most of the connections are a local and they're sort of.

10:49

And so, therefore they're kind of in a sile but not, not completely. And most of the connections that branch out from the court of columns. You know, we're talking about those are just in the upper layers. It's it's fit their sixth layer where the pyramidal cells are now reaching from the, from the top, from the peaks of the, of the siled cortical columns to, to reach out.

11:24

And connect or network different portable columns together the network, you know, with long intern neurons, they connect different regions of the brain together, Vape, warm rich clubs, and they form the default mode network. And and there's other and atomic anatomically described networks. And and so, it seems that well.

11:59

So, you know, it could be that You know, so it probably is the the fact that the TPJ is one of is at least one of the major crossroads for the convergence of of attentional patterns. And the heart and they hire more macroscopic levels of observation that are tracking pattern that a higher level.

12:37

So my hypothesis is that it, you know, because we have basically this with anesthesia, we have the impaired function of parameter cells and the pyramidal cells are with our linking together, brain areas, and so you have this lack of consciousness. When brain areas are not linked together because the perimeter cells are being inhibited, not inhibited but disrupted from functioning.

13:05

So the brain is not leaking together and there's a loss of consciousness function and a patient under anesthesia could have some of their brain lighting up, but it's not global brain activity. And to this what I think of and into that. So for the idea that like somehow it's just it's just a module and temporal parietal function that we could copy and put into a robot to the rest of the robot.

13:32

Now, it has a conscious model so moves from its representation of this seeing representation. What's hearing to its conscious module and now it can take to build consciousness and events just


13:47

Not really possible. It's not impossible but it's not possible. I mean, it's a reason I said I was because I think yeah you have to have a

14:03

This.

14:10

You have to have large. Large sequences. Of multi-scale, inter related data across many different, modalities in many different areas of brain, collaborating, and huge sequences to achieve something like a like what we would sense is a human level, or animal level being this. And this is going to be something that the computers will be able to do.

15:01

Big because it is, but it's not going to be like a model. It's going to be like how the because because what you because one of the key things is you have as if you have is you have basically like this this bubble with a lot of bubbles inside it just to oversimplify what it is.

15:26

You have, you know, cells are like they're little not they they are at the bubble that that, that is a 3D that contains a 3D learning machine, that learns and learning, and such as learning machine. It's also speaking a speaker. So to learn and speaker or it's a, it's a listener and a drawer, so it draws and it was so observer.

15:54

And a transmitter is it receiver and a transmit. But it's, it's, it feels. It feels because they can create a, basically, a feeling. Let's say it's a feeling of multimodal association, some of the mobile tracking and correlate, and multi-modal correlation. So if you could take, if you take different kinds of data and you can track it, and you can feel it and you can, you're going to tack the pattern.

16:29

You're basically like your feeling is a pattern that's being detected and a multi. It's a multi-dimensional pattern that's been attacked. It has. It has feelings have characteristics patterns this temple of spacer characters. Just like if you rub your if you if you're if you're jean your finger on some cloth that could be your jeans or socks or maybe final shirt, different ruby finger and different materials.

16:56

Maybe the carpet or just the flat surface of the table feelings. Have, you know, you the the feeling of a texture of textile has maybe it has bumps, maybe it doesn't, maybe it's rough, and it's smooth. But those are temple and special characteristics that that a great of cells is modeling, it's smiling with it is it's it's taking lots of moments of the feeling and putting them together and compiling them so that it's compelling them.

17:34

So that your experiences of that feeling develop, the more you sort of tune in and pay attention to and continue to experience that that feeling and they and they you know, that's not at some point. You know, when you're really when you're paying attention to something, the multi-modal nature of what of paying attention to something is going to be engaging, multiple areas to your brain simultaneously, like the visual cortex, the acceptable cortex, I'm sorry, the acceptable cortex is a visual cortex, but I mean, the obstacle, the parietal, the temple, the prefrontal different areas of the brain are going to be engaged when you're painting attention to something.

18:26

And you know, so that's why this why I made the joke about being the temporal tidal, not being the module, we can add on to make machines conscious. But instead being the LED, the of the of kind of the consciousness in terms of an indicator that the that enough of the global workspace across multiple reasons has been, it has been activated in, his is interlace and is communicating.

19:05

We could be an indicator of cross talk between the senses which actually makes sense. They're actually makes sense because when you're paying attention to something there is a convergence of your sensory activities. And so if you're if you're really paying attention to someone, that means you're bringing your visual representation and alignment with your auditory representations and alignment with your somatosensory representation and that probably result in would result in some peak activity and your temporal pridal junction or TPJ because it's right at the center of your incoming of the primary sensor cortisol.

19:53

And so in that sense by itself, like you could say that thinking that of the TBJ, as the as the, the consciousness module to sort of obscures an alternative idea and which you're just thinking of it as, as a symbol that you're that you're primary sensory courtesies are working together at the highest level, which is a, which is, which is going to be a good correlation of multi-sensory, awareness, or multi-sensory attention.

20:40

And so you could, I guess you can argue that. Yeah, we have visual, we have attention at every level of neuron anatomy. And and so and now I could, it could, it could just be that because you notice like attention to can change like you smoke pot. Some people to come drink detail, focus.

21:05

They start focusing on details obsessively, like little stuff. And so, you start to wonder if there's other kinds of ways to alter the mind in which you're focusing on say, you know, it's some people, I have had experiences where they'll take a second out medication and end up and the they're focused will get very broad and I'll start thinking of things in them on a longer timeline.

21:34

Let's start thinking out of, you know if like maybe look at it your hand and you can see a hundred years of history in your hand or in the clouds. You see speakers going to act generations. Ancestors, great minds. And it's just like, if this is a total opposite of the, you know, your mind is it your minds perspective?

22:06

On time is expanding versus your attention. Contracting. And so anyway, going back to like yeah, I think maybe the TVJ represents the convergence of the the primary sensor quantity, in terms of like attention exists at all levels and and but therefore like the reason the top of the hierarchy sort of dominates your conscious attention and you are not necessarily conscious may not.

22:45

It is it's not that like we want to make an argument like yeah. Well, or maybe it's only the animals with bigger brains they have consciousness but like how do you explain how our roach operates? How do you explain how a mouse operates or a dolphin, right? And all these different animals or life or you know, insects that have some sort of operation.

23:14

And I get that, I get that. You know, we want to, we want to believe that I want to believe that fish are not conscious, but but it's like, okay. Well, what why is? Why is the consciousness at a high level, right? Why is it happening high level? And it could be that sort of like going back to basically the attention schemoth theory, it could just be that the stuff that is inside consciousness at a high level.

23:50

Like I'm consciously aware of stuff. It's stuff. That is just I mean I guess this is covered already in the theory like it's like it's the stuff that's dominating other stuff. It's it's the patterns that out. Competed other patterns in a way that moved up to the higher levels.

24:10

But then and you have, you know, you have this sort of competition that patterns go through to become the pattern. That is is dominant in the architecture of the mind. They're competing against each other. They're competing to take up space in your mind. I mean, it's one way to look at it.

24:40

Trying to say these patterns have their own agencies is a little funny but you know, I would say maybe it's the moment. It's the momentum of past patterns, that, and perhaps also the momentum of of the memory of what of your past that you've learned in terms of what your ancestors did, and that, that drives you

25:11

And drives your neuro patterns, right? Your memory is our drivers and because that because memories have their own like momentum, right? And, and

25:35

But yeah, I guess I have a big disagreement with Michaela because I don't think of her of consciousness is just like some module that we can just slap on to the back of a of a robot. And then suddenly it's going to be able to talk about it. So if that's I don't want to say that's ridiculous, but it's what I'm thinking, I think that

26:06

That we, if the kids, if you look, I think that the brain has is taking turns rendering on a large scale. The brain is taking turns just like, just like, okay, so like when you think of how a computer monitor works, right? The community of computer monitor a computer is, is sending an image to the screen, one pixel, at a time, one line at a time like when, when, when a screen, when a television screen, renders an image, it renders one line at a time, but it doesn't so fast that you see, when you screen, you look at a computer screen use, you see an image in the computer screen, maybe say a movie image, maybe it's a bit.

27:03

Maybe this video or a movie and but that, but that is made up of like one line being drawn at a time across one line goes across the top and then another line underneath it and then another line underneath it. Like, if you slow down a computer screen, computer screen, just doing one line at a time.

27:22

And then when it gets to the bottom, it's goes back up to the top and starts drawing the next frame. And it has to do has like if you if you're watching a film, that is 40 frames per second or playing a video game. That's 120, friends per second.

27:42

That means that it that's for each of those frames that happen in each second. They're what they're still like, you know, one line is being drawn at a time that lies being drawn so fast that you don't perceive what that you don't, you typically, don't receive that one line of being drawn at a time.

28:06

You just see the movie, you just see the whole image transforming and and that's what I'm suggesting that the whole brain is doing and distributed way. Is that the you know, that what would microprocessing and I might refer to the attention. Schema is basically the neurons that are activated versus the neurons that are inactivated but in a global way, each part of the brain is is going to sort of be writing a different line of the pattern that represents the sequence of things that we consider when we're conscious.

28:54

And so, of course, the visual stuff, the screen of that we see is going to start in the interview when area and like like just on a visual level that's just all it needs to be it just you know, basically creating basic models but what those models mean, the meaning of those models that is that's that's another thought that takes up another line on the monitor.

29:28

And so, that's how you see the brain. It's like it's like a distributed rendering it. Distributed drawing Think of consciousness of distributed drying or each part of the brain, gets to render a different pixel and each oscillator gets to get to. And the different pixels are like dark. It's like one lot, like you have a whole bunch of.

29:52

So you have a cortical calm and he's quarter. Calm. In the, in the neocortex, is representing one line of the screen of the mind. And and then what happens is the oscillator resolve the neurons that didn't fire. That are basically listening and predicting when they're going to fire because they're collecting little electric surges, actually.

30:21

I mean, they're collecting phased differentials, right? They're like you know either they're receiving neurotransmitters and a very regular way or their tracking basically novel patterns and predicting when when they're going to fire which is going to allow them to activate and a sequence in a playback sequence and so that observation it observation is something that the entire that was a reason that a single neuron is doing other words, predict when it's going to fire is something that's also being done by the network or the oscillator or the quotable column.

31:14

So I guess so we have. So we have predictive coding at the individual neuron level, but we also have predictive coding at the oscillator level at the cortical column level and we have predictive going at the larger scale of different brain reasons. And so the narrow, so their intern neurons are participating in it.

31:43

Predictive coding of, you know, firing it at the greatest level and that. And so what I'm saying is like I all levels where you know at the micro level where deciding on individual pixels and at the cortical column level which is also the same as the oscillator level, you know, the missile level we have, we're doing lines.

32:13

So pixels lines that were rendering and then at the global level that's like, okay, the global level is like the cortical columns are going to play back in sequences. So that it's like one line gets filled in the next line or the next line. The next line. And then you have the computer has now rendered and entire frame for your eyeball but it's not for your eye, it's not for your eyeball.

32:49

It's just that it's you have not a singular observer because you have the network itself being in observer you have a distributed observer.

33:07

If many small observers that work together to create the evolution of the singular observer because the many small observers are producing together, collectively but producing a common pattern.
