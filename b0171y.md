b0171y Concise Summary:

Drawing on personal insights and analysis of neural dysfunction, the author envisions the brain as a dynamic spectral graph where consciousness unfolds as a sequence of temporal frames. In this model, spatial perception is not innate but learned; cortical columns each capture a unique “slice” of a unified pattern, which, when integrated over time, forms a coherent map of the external world. Experiences with substances like Salvia and DMT revealed that when the learned construct of space dissolves, so does the sense of spatial separation—implying that the observer’s mind is inherently contentless. Instead, what we perceive as space is a product of complex, temporally synchronized neural activity that bridges disparate sensory inputs. This perspective challenges traditional views by suggesting that the brain’s coordination of complex information relies on the invariant, oscillatory frames shared across regions, ultimately forming the basis for attention, perception, and cognitive function.

Graph Column Space Spectral

b0171y Whisper Transcription + Formatting

I, I'm smiling because I used an insight, I used an insight from my work from the book that I'm working on which part of it covers the topic of the human brain and I had an idea about what might be going wrong in someone else's brain and that gave me an insight into my own brain because I took the same sort of like, I imagined a process of how that other person's brain was not performing correctly and I used what I learned from that analysis. I came up with a new conclusion, I'll call it, it's, it's weird, it's not that it's a new conclusion, it's that it's a conclusion from another point of view that I had in another area.

So it's like taking, it's like saying, well I'm making this assumption about what's going on when people talk to each other, I'm making an assumption about what's going on between different cortical columns, I'm making an assumption about what's true, right, in terms of the importance of my own ability to put together complex information, right; all those ideas are related and the relating factor is time, temporal synchronicity. At that moment I knew how I was going to do this book, I knew how I was going to accomplish this book, I knew how I was going to put it together, I knew how I was going to put everything together because I saw this human mind as a graph, a spectral graph which means that you'd have a concept of something appear in one part of the graph and a concept of something appear in another part of the graph and then later on when the graph learned how those two features were connected it would bridge the two. But although they're located apart by a distance, the brain's concept of space is also something that's learned; there's not an innate knowledge of space. And so I think that space is something that's learned—like we learn what space is but based upon observational patterns, right—the brain puts together the concept of a space and we think that consciousness has to include space, or at least I thought it did. I thought that space was part of it and I was really confused when I tried Salve di Vinorum and I could no longer tell the difference between one thing and another, and the same thing happened when I tried the— the same thing happened when I, when I tried the DMT. Did you see what I'm saying? This, I saw the walls to my right and to my left; they disappeared and suddenly I was in a vast space. My sense of space was completely changed with the Salvia, with not being able to see the difference between any two objects, so it's like that would imply that the observer self is not fundamentally connected to like the space or empty space because there was a lot of that preaching—like there's the content of the mind and then there's the empty space that contains the content of the mind. It actually didn't occur to me that space itself or space time was also the content of the mind and not the mind itself, and that means that it's contentless; that the mind itself is contentless. That means there's no, there's no, there's no sense of space around you when you're contentless—contentless means no sense of space.

It's like that story that goes like people think that blind people are, are in darkness—like when you're in a lit room and you turn off the light you're in darkness, you think that a blind person feels like they're in darkness, but they don't feel like they're in darkness. There's just no sense of light or dark; there's no sense of— they're not sensing that they're missing something. And by the same token, the actual content of the observer—that content isn't space time. If the observer doesn't create space time, that's the content; that's content inside, that's learned content, and that's the key to understanding the graph: there is no sense of space. It is learned, and it has to be that way because it is a computer—a computer does not have an innate sense of space. Why would it?

And so that's not—so it's not that the oscillations are conscious; it's that they're frames—they are frames in their consciousness, and a whole brain consciousness is the frames in it. But it's a pattern that we can reason; it's an invariant pattern learned by the whole brain, which is somewhat invariant of the cortical column—although some cortical columns may have features that others do not, so the capabilities—but it's the patterns that are invariant across cortical columns. That would mean that, like, you have the cortical column for sawdust and the cortical column for rain; you could have a pattern in the rain that appeared in the sawdust and therefore a pattern could transfer from one cortical column to another. Ideally, if you're seeing rain and sawdust at the same time then each one is represented at least by the patterned activity of a cortical column, but either one of those columns can represent that data. The thing is that data is being represented with a certain bias towards some texture or material or concept or pattern trait. I think I mean, if all neurons—if we're all, I say this because it's like, yeah, there are examples of when specific moments—see, that's the thing: it matters a lot. There's been a lot of neuroscience where they've been like, "Okay, we're going to basically study this patient after they've had such and such, you know, surgery or they've had such and such an injury. We're going to study them for a certain amount of time," but that's not necessarily going to be a long-term study. It's not necessarily going to be a rigorously done study, and we may go back and say, "Okay, we need to do the study bigger with many more patients," but we just can't because you just—you can't make up injuries to study. So, in a lot of sense, a lot of science has been done—a lot of neuroscience has been done on the patients that doctors had access to—and that fundamentally is an issue when we look back and ask ourselves: Is the data that they found that was relevant to the patient's inability to speak words, for example, or inability to remember features of language, or inability to perceive the world in a coherent way—like maybe, like whatever the issue is—is it possible? But I want to know: it is.