b0321yGPT

b0321y was re-transcribed with OpenAI, then the transcript was divided into 8 parts (# Part 1 - # Part 8) and each part was fed into ChatGPT 3.5 to create summaries with lists of key points.

Original Audio: https://recorder.google.com/08bb0654-7461-49f0-8d63-b3b9e1a365bf

# Summary of all the summaries:

I copied & pasted the ChatGPT Summaries & Key Points from all the parts back into ChatGPT and then I asked it to "Summarize all the summaries and key points in the following text as they relate to this conversation above.")

This conversation covers a variety of topics related to brain-computer interfaces (BCIs) using EEG and FNIRS. The main focus is on a paper that uses a hybrid BCI approach to control a quadcopter drone using both EEG and FNIRS. The group discusses the trade-off between the number of commands that can be controlled and the accuracy of the BCI. They also touch on the importance of machine learning models to keep up with neuroplasticity, the relationship between mental activity, oxygen consumption, and brain activity, and the limitations of using mental activities as commands for BCIs. The group also discusses the frequency range that EEGs can measure and the limitations of using only EEG for controlling devices. They suggest using a combination of EEG, EMG, and FNIR signals to provide better information for controlling devices through a brain-computer interface. Finally, the group discusses the importance of considering human factors when designing brain-computer interfaces and improving their usability.

# Part 1: Summarize

ChatGPT 3.5: The group is discussing a paper that combines a brain-computer interface (BCI) using AGF and FNIRS. The study uses several tasks to decode the signal, including mental arithmetic, mental coving, mental rotation, and word formation tasks. Participants were able to control a quadcopter online using real-time signaling. The paper achieved several things, including the use of temporal windows and achieving a high level of accuracy in differentiating between similar tasks. There is also discussion about the number of FNIRS detectors used and the distance between source and detector. There is some uncertainty about whether the EEG and FNIRS data were used together to increase accuracy or separately to increase the number of commands that can be used.

# Part 1: List key points.

"ChatGPT 3.5: The group is discussing a paper on a combined BCI using AGF and FNIRS.

The study uses several tasks to decode the signal, including mental arithmetic, mental coving, mental rotation, and word formation tasks.

Participants were able to control a quadcopter online using real-time signaling.

The paper achieved several things, including the use of temporal windows and achieving a high level of accuracy in differentiating between similar tasks.

There is discussion about the number of FNIRS detectors used and the distance between source and detector.

It is unclear whether the EEG and FNIRS data were used together to increase accuracy or separately to increase the number of commands that can be used."

# Part 2: Summarize

ChatGPT 3.5: The group discusses the use of EEG and FNIRS in decoding different types of tasks. EEG was used for eight commands and for eyeballing and movement tasks, while FNIRS was used for mental tasks. It is unclear whether the EEG and FNIRS data were used together in the analysis, but it is clear that they were used at the same time. The accuracy discussed relates to the classification of different commands, with the main added value of using both being to increase the number of commands that can be used. The paper suggests that with EEG, the best accuracy is achieved with a one-channel system. However, it is unclear why one channel EEG is better than multi-channel EEG.

# Part 2: List key points.

"ChatGPT 3.5: The group discusses the use of EEG and FNIRS in a paper on a combined BCI using AGF and FNIRS.

EEG was used for eight commands and for eyeballing and movement tasks, while FNIRS was used for mental tasks.

Participants were able to control a quadcopter online using real-time signaling.

The paper achieved several things, including the use of temporal windows and achieving a high level of accuracy in differentiating between similar tasks.

The accuracy discussed relates to the classification of different commands, with the main added value of using both being to increase the number of commands that can be used.

The paper suggests that with EEG, the best accuracy is achieved with a one-channel system.

It is unclear whether the EEG and FNIRS data were used together in the analysis, but it is clear that they were used at the same time.

The distance between the source and detector is important in FNIRS signal processing.

The accuracy of control would improve if there was a faster signal transmission from the brain to the quadcopter.

There are potential uses of BCI technology in controlling various devices, such as music or a theremin."

# Part 3: Summarize

ChatGPT 3.5: The discussion revolves around the use of EEG and FNIRS in controlling a quadcopter through brain-computer interface (BCI). The combination of EEG and FNIRS was used to decode different types of tasks, which allowed for more commands to be used without decreasing the accuracy of the BCI. The study showed that using only EEG or FNIRS could result in decreased accuracy for BCI due to the accuracy reduction problem, which arises when increasing the number of active commands. Additionally, using only EEG as the brain signal acquisition modality would not be reliable alone to control the quadcopter for an extended period of time. The study also found that using a single channel EEG could result in better accuracy than multi-channel EEG. However, it was unclear why this was the case. The discussion also touched on the importance of sustainability and avoiding potential problems in BCI. The accuracy of BCI was found to decrease as the number of classifications increased, and the use of a hybrid BCI combining two modalities was proposed to increase classification accuracy while allowing for more commands to be used.

# Part 3: List key points.

"ChatGPT 3.5: The study involves the use of a quadcopter controlled by a hybrid Brain-Computer Interface (BCI) that combines Electroencephalogram (EEG) and functional near-infrared spectroscopy (fNIRS).

EEG measures the electrical activity of the brain, while fNIRS measures changes in blood oxygenation.

The hybrid BCI was designed to enhance the classification accuracy and increase the number of commands without decreasing the accuracy.

The combination of EEG and fNIRS allows for more commands without decreasing accuracy compared to using only one modality.

The study shows that the hybrid BCI system with both EEG and fNIRS allows users more freedom to control the drone and avoid misdirectional movements.

The accuracy of the system with only EEG for controlling the drone was not reliable for long spans of time.

The accuracy reduction problem is a drawback of using both EEG and fNIRS, as increasing the number of commands decreases the accuracy for BCI.

The hybrid BCI system provides users with more commands and avoids a decrease in accuracy.

The paper discusses an accuracy reduction problem in the use of multiple modalities for BCI.

The accuracy of the EEG signal can be decreased by increasing the number of commands or classifications.

Combining EEG and fNIRS in the classification of 12 different types of music should improve accuracy compared to using only EEG."

# Part 4: Summarize

ChatGPT 3.5: In this conversation, the speakers discuss various questions related to EEG and its capabilities. They wonder about the timing of the delay between neuron firing and dipole activity and how high of a frequency EEG can pick up. The sampling rate of EEG is 128 Hz, but it can only capture brain waves up to 80 Hz. The speakers also discuss the depth of EEG and whether it can capture all six cortical layers and anything below that, and the limitations of using FNIRS for mental activities like mental counting, which might require changing commands over time to maintain accuracy.

# Part 4: List key points.

"ChatGPT 3.5: The discussion centers around EEG and FNIRS and their applications in brain-computer interfaces (BCIs).

There is a trade-off between the number of commands that can be controlled and the accuracy of the BCI.

A hybrid BCI approach combining EEG and FNIRS can provide more commands without decreasing accuracy.

The study discussed in the paper used this hybrid approach to control a quadcopter drone.

The hybrid BCI approach also allows for more freedom in controlling the drone and avoids misdirectional movements.

EEG sensors typically capture frequencies between 0 and 80 Hz, while the sampling rate in the study was 128 Hz.

EEG primarily captures large-scale dipole activity, but localization can be used to trace the origin of signals to the core of the brain.

The Nyquist rate dictates that the signal acquisition rate needs to be higher than the fastest event being collected.

The discussion also touches on the timing of neuron firing and the delay between neuron firing and dipole activity.

The group discusses the limitations of using mental activities as commands for BCIs, including the possibility of the brain becoming trained and needing less oxygen to perform the task over time."

# Part 5: Summarize

ChatGPT 3.5: The conversation covers various topics related to EEG and brain activity. Sharina asks about the frequency range that EEGs can pick up, and there is a discussion about the correlation between the density of EEG electrodes and the frequency range. The conversation then shifts to neuroplasticity and the need for machine learning models to keep up with it. There is also a discussion about brain wave frequencies and how they are generated from firing neurons. Sharina explains that brain waves are created through synchronization between neurons and how the power and frequency of brain waves are inversely related. Finally, resources are shared on subcortical electrophysiology activity and biophysical modeling on the origin of EEG.

# Part 5: List key points.

"ChatGPT 3.5 As an AI language model, I strive to provide objective and neutral summaries. However, in this conversation, there were several topics discussed, including the use of machine learning models to keep up with people's neuroplasticity, the different frequencies in the brain, and how brain waves are generated from single neurons firing. Sharina explained that the brain has numerous different frequencies happening all the time, and multiple frequencies can be superimposed upon each other. She also used the analogy of a group of people clapping at different rates to explain how brain waves are generated from single neurons firing. The group discussed a paper about subcortical electrophysiology activity, which is detectable with EG source imaging and how accurate and deep the EG signals can be detected, as well as a biophysical model on the origin of EG.

Sharina raises a question about the highest frequency that EEGs can pick up, and whether it depends on the electrodes used.

The group discusses the frequency range that EEGs can measure, with the consensus being that EEGs can typically capture frequencies up to around 80 Hz.

They also discuss the sampling rate and how it is different from the maximum frequency that can be measured.

The group talks about the use of machine learning models to account for neuroplasticity in EEG signal analysis.

Sharina asks about how brain waves are generated and how frequencies are picked up from individual neurons firing.

Sharina provides an analogy of people clapping at different rates to explain synchronization and the generation of brain waves.

Sharina recommends two papers for further reading, one on subcortical electrophysiology activity and the other on biophysical modeling of the origin of EEG signals."

# Part 6: Summarize

The discussion revolves around the relationship between mental activity, oxygen consumption, and brain activity. It is suggested that routine tasks require less oxygen and may result in less firing of neurons. However, neurons require both oxygen and nutrition to fire, and in some cases, less oxygen and nutrition may still allow neurons to fire. The process of transduction of neurons involves sodium and potassium pumps, as well as calcium signaling, and the firing of action potentials that excite or inhibit the next neuron.

# Part 6: List key points.

"ChatGPT 3.5: The group discusses whether mental training can reduce the amount of oxygen the brain needs for certain tasks.

It is noted that brain activity always requires oxygen and energy, and that routine tasks may require less oxygen.

The idea of training in hypoxic environments for athletic performance is mentioned.

Neurons require both oxygen and nutrition to function properly.

The process of neuron firing is explained in terms of sodium and potassium pumps and action potentials.

Brain rhythms and neural circuits are described as being dependent on action potentials firing and exciting or inhibiting other neurons."

# Part 7: Summarize

ChatGPT 3.5 The speaker shares a fun fact about the periodic table and how the separation of positive and negative charges leads to action potential firing in the brain. They also discuss the effect of neuroplasticity on EEG signals and the possibility of changes in signals for individuals with ADHD or attention conditions. They note that noisy signals and training may be required for brain-computer interfaces in these cases. The group also discusses the threshold for capturing signals and how it may not significantly affect results in short-term trainings.

# Part 7: List key points.

"ChatGPT 3.5: The separation of positive and negative charges in sodium, potassium, and calcium leads to the firing of action potentials in neurons.

Human beings can be thought of as metal robots because of the electrical charges in our cells.

Neuroplasticity can lower the threshold for firing neurons and create new paths in the brain.

The signals captured in EEG are extracellular and come from the chemical gradient between neurons.

Neuroplasticity may affect EEG signals, but it depends on the threshold used to capture the signals.

Noisy signals in attention conditions can create a challenge for creating a brain-computer interface.

With training, a person can become better at creating brain-computer interfaces."

# Part 8: Summarize

The speakers discuss EEG devices and how they fail in terms of controlling systems with EEG due to decreased brain activity as one becomes better at a task, creating a paradox. They suggest that combining EEG with other modalities such as EMG and FNIRs could improve information regarding brain activity and commands. They also discuss the importance of behavioral correlates such as performance on a task in addition to brain activity when creating brain-computer interfaces. The use of EMG signals is suggested as a potential solution to the problem of decreased brain activity in controlling systems. The speakers also touch on the importance of considering human factors when developing brain-computer interfaces and improving their usability.

# Part 8: List key points.

"The hypothesis is that EEG devices fail in terms of controlling systems with EEG because the signals become weaker as the user becomes better at the task.

The use of EMG signals instead of EEG signals might be more consistent for controlling devices through a brain-computer interface.

Behavioral correlates such as performance on a task are also important to consider in addition to brain signals.

Combining EEG, EMG, and FNIR signals might provide better information for controlling devices through a brain-computer interface.

Human factors and what is instinctual should be taken into account when designing brain-computer interfaces.

The use of EEG to increase the number of commands for controlling a drone is effective.

Trial-to-trial variability in FNIR signals is a big field of research.

Differentiation between mental tasks might be much more pronounced if the task requires a transition between computational and memory tasks.

Mario Kart serves as an example of how people initially try to control devices through instinctual movements, but eventually learn to use more efficient methods."

# OpenAI Whisper

# Part 1

So, Adam, I realized that you also shared another link,

which goes to another paper.

Was it an extra suggestion or was it an error?

I wasn't sure.

No, no, that was an extra suggestion, maybe for next week,

or that was a connection between that paper and this paper

as well as a little bit.

But your paper is kind of a BCI flow chart,

the algorithm flow chart.

The other one was just a nurse and regarding memory,

but there was some sort of the algorithm

that they used in the second paper

was related to the first one.

But I think tonight we're going to talk about

the first paper that you suggest.

And just to a quick intro about this room

is every Monday at 10 p.m. Eastern time.

We're going to get together only for one hour,

more than that, and review a paper regarding neuro-technology,

variable device signals, some interesting papers

that we're going to review those for one hour.

Sounds good. Should we start?

I guess so, yes. Let's get started.

I think Che, that was your proposal.

Do you want to kick it out?

Yeah, of course.

Hi, everyone.

So in the previous weeks,

we have been talking a lot about combination

of different imaging methods.

And I think one of the things that Adam has been quite

interested was FNERS.

And so I picked that paper because it's really interesting.

So first of all,

it's a combined BCI using AGF and FNERS.

And then they use different,

they use several tasks to decode the signal.

And one of the interesting part is that in here,

people actually control a quadcopter online

using that real-time signaling.

So there's different comments that they try to decode.

So for example, like there's this mental arithmetic,

mental conving, mental rotation,

and word formation tasks.

And these are decoded by FNERS.

And then they also decode some of the tasks with the EG,

like the two eye blinks,

three eye blinks, and eye moments up and down.

And yeah, so I think maybe like,

you know, if you want to kind of like add to me,

you can unmute and go.

Sure, yeah, I think on a high level,

we talk a lot about EG and FNERS.

And EG is capturing brain, basically neural impulse,

which is an electrical signal.

And FNERS is capturing oxygen saturation,

which is kind of an input.

I think in this algorithm,

if you look at the flow chart for FNERS,

for basically feature extraction,

they were using two second window.

For EG, they were using one second window.

As a kind of data science point of view,

or a kind of a system engineering point of view,

if I'm looking at one neuron,

it should be a time delay between

when they are consuming oxygen

versus the time that they are firing impulse.

When we are capturing those two signals at the same time,

we have to be careful about that time difference.

And I'm not sure the reason

that they were using two second window for FNERS

versus one second window for EG

is because of that or not.

Or I don't know what's the best way to make that synchronize

because there should be a time delay between

when part of the brain is consuming oxygen

and then they are firing impulse.

Yeah, I think one of the importance here,

as you mentioned, you know, that time,

like two second, the ability to measure

with two second window for FNERS

and one second window with EG.

I think that was one of the powerful parts of that paper.

And I think also, like, they...

Also, like, regarding the number of commands

that they were using, this is also interesting.

So there's been several earlier studies

that, you know, that try to control quadroppers,

so that ask the participants

to control a quadropper using BCI

and then, like, one of them, for example,

used motor imaginaries for, like, left, right,

or both hands.

And so, you know, like, it's been...

I think it's been an interesting task, right,

like, to have that BCI to control the quadropper.

But I think...

So this paper got a lot of citations as well,

and one of the reasons is that they achieve a few things.

So first, as Adam was saying, that the temporal, you know,

window was interesting, like,

and that was a good achievement compared to the earlier studies.

And also, like, the number of these tasks,

these commands were interesting.

And one of the things that I find quite surprising

is that, you know, if you think about these four mental tasks,

like mental, mathematics, counting, you know,

think about, like, you do some math,

you do some counting, or word formation,

or mental rotation, these are all really, like,

you know, frontal lobe tasks, right?

It's not, like, it's not...

It's really, like, they have some similarities.

These are...

And I think differentiating between these different tasks

using that signal that has been recorded with F-nurses

is quite an achievement.

So if, you know, if you record, like,

if you're trying to differentiate eyeballing

from a motor task or motor imaginary task,

you know, these are more easy things

because they're very distinct tasks.

But I think there's some similarities here

in terms of these tasks.

And I find that part actually impressive.

And that was a good achievement as well.

This is Sharina.

And I think that part of the reason

why this is a highly cited paper

is because it has such a cool factor.

I mean, being able to practically levitate something

with your mind, that's what it seems like almost.

So there's the question of how else

could such paradigms be used?

Could things happen like controlling music

or controlling various other things?

For example, what if there was a theramine pretty much

and it just increased the frequency

over different brain waves,

but corresponding to sound waves and so on?

That could create quite the game for life.

This is Sharina, and I am done speaking.

Thank you, Sharina.

Yeah, I think that's a good point.

And I think the number of detectors,

basically FNIRS detectors that they were using

was not that much.

I forget the number,

but I think it was not huge amount of detectors.

And I think in the section that they were using

in FNIRS signal processing,

the distance between source of the light

or that LED that they were using,

and the detector, basically the distance between them

is very important.

It cannot have, I don't know, more than,

if the distance is larger than the absorption amount

that detector is capturing is gonna change.

And the quality of signal is gonna be different as well.

And I think in that FNIRS signal processing part,

they were talking about that distance

inside the equation that they have.

And the same, another sort of concern

that they have for each signal processing.

And in order to make them both in a good way

and synchronize them,

I think that that's very difficult.

It requires lots of experiments

because I'm not sure if there is any kind of a theory

as a neurology point of view

that what's the best distance between source

and detector for FNIRS.

I don't know if such a thing exists

or we have to start experimenting

and then asking people, I don't know,

to think about music or do something

or do some brain activity

and then change the distance

and calculate it again and again and again and again.

Or if there is any kind of a theory

that what's the best distance between them.

I think we got an EEG.

Go ahead.

Oh, sorry. Yeah, I just had a question.

So from what I'm reading,

EEG, the EEG and the FNIRS part are completely separate, right?

They're not using the data together

to increase the accuracy.

Rather, they're using it separately

to increase the number of commands that they can use.

Correct?

That's what I thought.

Yeah, right?

I think so.

I understand I'm not 100% sure

because we get three that they were using.

I thought they are capturing those signals at the same time.

# Part 2

For sure, we're not the same device,

but at least at the same time.

I think they use the two techniques

to decode different types of tasks.

Like EEG was used for, you know, there's eight commands

and for these mental tasks, they use FNIRS

and there's these EEG tasks that are separate

and that these are eyeballing and movement tasks.

So this has been clear,

but I just didn't read every line of the methods part.

I don't know if there was an exploratory part of the paper

where they used them together in the analysis,

but they used these two at the same time.

That's correct.

So I think that is correct what was just said

and that the E-mode of device was used basically in a way

to basically pick up EMG signals from the eyes,

which is not exactly EEG, but the EEG device was used

because, you know, you can pick up those signals.

And so they're tracking the eyeballs,

but that was, so they sort of neatly avoided the potential

synchronization of timing between EEG signals

and FNIRS signals.

So you had one, you know, totally separate system

or totally separate control mechanism

that was just using the FNIRS for control of part

of the quadcopter and the eye blinks were used

for a different part of controlling the quadcopter.

And I thought that maybe the biggest sort of delay

in the paper was just the amount of time

from the signals collected to travel to the device itself.

And so it was just like that part wasn't fast enough.

So the quadcopter needs data from the brain much faster,

but you can't send data that fast over Wi-Fi with their setup.

So the Wi-Fi was the inhibiting factor to,

maybe the accuracy of control would improve

if they had a faster signal transmission

from the brain to the quadcopter.

Can we do that with only EEG or only FNIRS?

Or it's really not me, both of them?

This is Sherry.

And I have seen some applications

where people have used brain waves

that were not the combination of EEG and FNIRS.

I think it was just EEG to control a drone.

But I do not know how accurate

or how good of navigation there may have been for that.

This is Sherry and I am done speaking.

I think the main added value of using both

is to increase the number of commands that you can use.

That's where I'm gathering from reading the paper.

This is Sherry and yeah, that makes sense.

I imagine also that the more contacts there are

and the more accuracy and the less latency,

it just makes for a better user experience as well.

This is Sherry and I am done speaking.

Right, right, but when you guys talk about accuracy,

are you guys talking about the mapping

or the error rate of the intention of the user

to the computer decoding the actual command?

Is that what you're talking about when you talk about accuracy?

Because I don't see how the accuracy is increased

by using both FNIRS and EEG in this paper.

I feel like the paper is misleading a little bit.

So the paper talks about how with EEG,

having like a one channel EEG,

you can get more accuracy than multi-channel EEG,

but it's still sort of confusing the fact

that really they're measuring EMG with the emotive EEG device.

But yeah, so the idea is that with EEG,

your best accuracy is maybe with like a one channel

and so the whole thing, the whole benefit of FNIRS

then is to give you accuracy with more than that one channel

by having like a whole different sort of modality sensor set up.

My name is Micah.

Thank you Micah.

And I think you're right, the accuracy was just different commands

and in order to control something in a physical world,

we cannot have unlimited command

and that the classification that they're using,

I think they just look at the accuracy of their classification,

the precision and recall of that classification.

I think that's what we're talking about as an accuracy.

I see, yeah, that makes sense.

So by separating EEG and FNIRS, you have more,

so you would have more accuracy with four commands in EEG

than with eight and you would have more accuracy with four commands

with FNIRS than with eight.

So by separating the two, you get more accuracy in both.

Is that what you guys are trying to say?

That's true, yes.

But I think the part that I don't understand is why one channel EEG

is give them better accuracy than two channel EEG

or even more channel EEG.

Is it overfitting problem as a data science point of view

or this is another problem that they have?

I'm not sure.

# Part 3

Maybe Micah can answer that.

Give me a second.

I'm just sort of skimming the paper for what I read earlier

and then I'll get back to you.

Sure, cool sounds good.

You know, if you only look at, you know,

the number of commands that are controlled

or number of channels, I think, you know,

if you look at it like one of your other studies

that was performed by Kim at all could look

like a more successful study.

There's still like an accuracy that's at 90%.

It's only EEG and they only use some, I think,

eye movements controlled study.

But there's other things that are really important.

So I think first of all, what they say is that with that setup

with that EEG eye tracker setup, I think there was a difficulty

to maintain the quadropper controlling concentration

for a significant span of time.

So, you know, if a person is going to control this quadcopter

for, you know, like an hour or so, so that system

with only EEG wouldn't be just, you know, reliable alone.

So, and also they, I think they say that there is,

their system, that combination of EEG and affinaries

also provides people more freedom to use, to the,

to control the drone, I guess.

And also it avoids some misdirectional movements.

I think these are also important things.

So I think when we look at the, you know, accuracy is a really

like quick, you know, quick representation of like the success.

But there's usually other things as well.

I think for, especially for BCI, it's really important

to avoid these potential problems and, you know,

make it sustainable.

So that was, that was a power of that study too, I guess.

This is Sharina.

And I think that with the point where there was more accuracy

or rather the signals that were intended were carried

out the most properly with one versus two contacts.

In that case, why don't they just switch the model

to just pay attention to that one contact that is really good

when there are two contacts in the picture

for those particular applications?

This is Sharina.

I'm talking.

I don't know the answer to that question.

So, so in the paper, they referred to something called

the accuracy reduction problem or basically, so the activity type

of BCI is preferred over reactive BCIs.

It allows a person to communicate with the machines.

We'll, oh, hang on, wait a second.

So, I kind of got lost, okay.

So, I wish the lines were numbered like, okay.

So, for the purposes of FNERS based active BCIs,

mostly mental and motor related tasks are selected.

All the recent studies have shown the importance

of FNERS based FBCI for reactive and passive tasks.

The activity tasks are primarily used to increase the number

of commands for this modality.

However, the active type BCI is preferred over the reactive

as it allows a person to communicate with the machine.

Well, both the FNERS and EG drawback is the increasing,

is that the increasing the number of active commands

is the decrease in accuracy for BCI.

And so, that's where I got that from.

So, both the EG and FNERS, the drawback of increasing the number

of active commands is the decrease in accuracy for BCI.

So, as a means for compensating the accuracy reduction problem

is use of single brain signal acquisition modality.

The hybrid BCI concept was proposed and the design entails

a combination of either two modalities, at least one

of which is the brain signal acquisition modality.

And so, the two modalities I guess are basically the EG

and FNERS.

And the hybrid was designed to basically enhance

the classification accuracy and increase the number

of commands without decreasing the accuracy.

And so, that is the real reason why they're using FNERS

plus EG to basically give you more commands

without decreasing the accuracy, which was what would happen

if you were just using one modality.

This is kind of the same thing that we discussed

I think two weeks ago regarding that EG and music.

I think in that paper, they asked people to think

about true music.

There was a binary classification that based on the EG signal

out of their brain, they want to predict which music

they were thinking about.

And then it was a binary, only two music, their accuracy was

I think close to 90% but when they make that music from two,

they make I think 12 music, the accuracy was about 65%.

So, the huge decrease in the accuracy when you increase

the number of music or number of the classification,

the number of classifications.

So, it's kind of the same thing that they do here,

but what they are doing is 100% right.

We can go back to that paper and combine EG and FNERS

and the music classification for 12 music should get better.

So, earlier it was pointed out, I guess Adam pointed out

that the frequency of EG is usually much faster than your

blood flow which has to react to your neurons firing.

# Part 4

I sort of wonder about how it works exactly because there is

like a path between neurons firing in a cortical column

and then basically that activity being large enough

that you are going to have dipole activity which is a large

scale global brain dipole activity which is what is going

to be picked up by the EG sensor.

So, I wonder about the timing of that and how that,

because so what I am saying is like there is a delay also

between when your neurons fire at a low level

and when the dipole is going to fire.

Similar to how there is a delay between when your neurons

fire and when blood flow happens.

So, the timing issue there is very interesting.

Yeah, I would like to know more about that.

Yeah, I am glad to know that.

Thank you, this is Sharina and this may seem like a silly

question but how high a frequency can EG's pick up?

Is it 80 hertz?

Is it 60 hertz?

Does it depend on which EG electrodes are being used?

This is Sharina and I am done speaking.

I think neuroscientists should answer that question, I don't know.

Good question, hi Sharina.

So, I don't know about the exact threshold but I know that

for like 60, 80 hertz it is hard to get that but I think

there is also a positive correlation between the density

of the EG, the number of electrodes and that capacity

for acquiring that frequency.

I know that it can acquire like 40, 30 and it is not good

at acquiring 80, 70.

I don't know about the reference right now or I don't know

about the exact threshold.

In this paper they said 128 hertz and that is what they said.

Exactly, we mentioned that in the paper that 128 hertz was the

sampling rate.

Actually I think using that device, using a hybrid of

FNIRs and EEG has this advantage for them to,

comparing to the devices, only use the EEG signals that they

have more commands and have more freedom to use it to

control that coaculter and also comparing to the devices

only use the FNIRs, they can reduce the size of the window

for doing this faster.

For example, I mentioned that it changes from 2 to 7 seconds

to 0 to 2 seconds and then they cut those features.

So, actually the purpose of the method is not exactly about

improving the accuracy but to getting more commands and

getting more freedom and controlling the coaculter and

meanwhile doing that faster in FNIRs as well.

The sampling hertz is different from the

amount that the hertz are able to measure.

So, from EEG sensors you are not going to get more than

80 hertz with EEG sensors.

It's usually between 0 and 80 hertz and 8 and so 40 to 80 is

usually the high gamma for EEG and then if you need more than

that you've got to have a different kind of sensor.

The sampling rate is 120 hertz but that's a different hertz.

Thank you very much.

Actually that's what I was thinking about at first.

They read that sentence but they use the word acquire and

that using the word of acquisition makes me think about it

that maybe they're using this word because of showing that

this is the frequency that they can catch using their set.

I'm not sure about this because I have not worked with EEG so far

but in terms of using that word in the sentence it might be that.

This is Sharina and yeah, when it comes to picking up

brain samples or samples of neural data it seems that there is

a certain Nyquist rate or a rate that where the signal

acquisition has to be higher than the fastest event that is

being collected and it needs to be quite a bit faster in order

to collect those particular events.

Events they will change depending on numerous things and

there are some brain waves that are 130 hertz and so on.

I imagine that EEG would have a very hard time collecting

especially with dry electrodes.

But when it comes to the depth of EEG is does it capture all

six cortical layers and does it capture anything below that

and does that depend on the person's head size?

This is Sharina asking kind of silly questions but also curious.

So the EEG is primarily capturing large scale dipole activity

but you can use EEG localization to trace the origin

points of the signals all the way to the core of the brain

in the thalamus, as deep as the thalamus.

That's been sort of proven by also co-measuring with

deep brain stimulation implants which besides doing deep

brain stimulation can also do measurements.

And I've also used many different EEG devices myself including

the brain guina which samples at 256 hertz but we could not

get more than basically the 60 hertz.

I want you to hit 60 hertz that is also the range of muscle

activity and so we couldn't go higher than 60 hertz in terms

of capturing the brain but we are sampling at 256 hertz.

Yeah actually I think so if you talk about the brain waves

frequency based on what also Sharina mentioned that it might

come from the Nyquist equation that you need at least two times

more than a sampling rate to capture that frequency in your signal

so if it would be for example 128 hertz for sampling

definitely the brain waves should be less than 64 hertz to get

captured in the signal.

I have a question regarding that F nearest part of that which

using to get mental activities like mental counting.

So one of those in a training set one of the activity was

counting backward and I can understand that I'm counting

backward some part of my brain they probably need more

oxygen in order to just I don't know to think harder to go

backward but if I do it again and again and that's become

easy for me and I got trained by counting backward then

that part of my brain probably doesn't need that much oxygen

in order to do it anymore.

So that VCI over time might not work and over time they have

to maybe change those commands to make it a bit more difficult

in order to get that oxygen.

Is that true?

Part 5

This is Sharina and that absolutely makes sense and that's why

they need machine learning models or something to keep up with

people's neuroplasticity.

This is Sharina and I am done speaking.

Yeah I think that's a good point but I feel like content

backwards is also a task that still requires mental effort

even if you're trained but we could probably look at the

studies looking at the effect of training.

I think that's a good point and so probably just to get rid

of the effect of that training if participants are trained

before and if the experiment starts later on probably just

going to provide more homogeneous results.

But yeah good point.

I have a question regarding the frequency that you guys were

talking about because when you guys talk about something

frequency makes sense but when you start talking about the

frequency of the brain I don't know exactly what you mean

since I'm not a neuroscientist.

I'm not training that field.

So when you talk about the frequency of the brain I'm having

a hard time picturing a bunch of neurons extracting away a

single quantity of frequency from a bunch of neurons

firing so can you guys help me clear that?

Yeah this is Sharina and the brain it has numerous different

frequencies happening all of the time and a lot of times it

has multiple frequencies that are superimposed upon each other.

For example a brain wave that my lab has discovered is a very

high frequency oscillation that only happens at the peaks of

data waves so it's this 130 ish hertz frequency that happens

on top of these about 8 to 14 hertz frequencies.

So there's the question of okay if we filter in different bands

of frequencies then what do we get and can we use those to

control some sorts of devices.

This is Sharina and I am done speaking.

Okay so that makes sense but then I guess I don't know,

I'm not sure that I understand how brain waves are generated.

So how exactly is it that you generate brain waves from

single neurons firing?

So is it like the rate at which neurons fire kind of make

oscillations in the electromagnetic field and that's

where you're picking up, is that what it is?

I just have a hard time picturing what's the word,

a regular pattern of firing neurons so that an actual

frequency can be picked up.

This is Sharina and I definitely have an answer to that.

Okay imagine this, you have a rainfall of people and while

the people they're clapping at different rates,

okay that is some sort of frequency, it is a lot of noise

but it's a bunch of clapping and it's a bunch of signals.

If they were to clap such that half of the people clap at

one rate and the other people clap at another rate then

you can determine two different frequencies from that

and it is kind of strong because multiple people are in sync

with each other so it's kind of similar with brain waves

and if everyone in the room was to clap at the same frequency

then that would create a very large and strong brain wave

and this phenomenon is known as the one over F rule,

otherwise known as a power frequency dynamic that happens

in the brain.

So if you have brain waves that are at higher frequencies

then you'll generally find that they are lower in power

but if you will have brain waves that are higher in power

then you'll usually find that they are lower in frequency

and so the whole idea to keep in mind is synchronization

between different neurons and how well synchronized they are

so that if a lot of people are clapping at the same time

then it will produce a lot of power but if there are a bunch

of different people clapping at a bunch of different rates

that may be a high number, that may be a high amount of frequency

but not very much power because it's not as synchronized.

This is Sharina and I am done speaking.

So I want to share two resources that might be useful

to people in this group.

If you look on my Twitter it's my latest post,

but it's the post that I just posted.

One paper might be interesting to Sharina,

the other paper might be interesting to Ricky

and everyone else might get a kick out of these papers too.

The first one is about subcortical electrophysiology activity

which is detectable with EG source imaging

and that dives into basically the source imaging

is the idea of explaining how accurate and how deep the EG signals

can be detected.

Basically I said it goes all the way to the thalamus

and that's where I was referencing that.

In terms of how EG, in terms of how neural activity

at a low level becomes a brainwave, Ricky,

you might want to check out this biophysical,

it's linked right underneath,

biophysical modeling on the origin of EG

and it sort of dives deep on answering that question as well.

Where did you say that they were linked?

I'm sorry, I missed that part.

So just check my Twitter, if you click on my profile

and click on Twitter and then look at my most recent posts

you can see those two papers.

Got it, thank you ma'am, appreciate it.

# Part 6

Great, that was a great question.

So I want to go back to that training data set.

I think we were kind of on the same page,

if we got trained and if we can do some sort of mental activity

easier and easier, then we might,

that part of our brain might not need that much oxygen

so those comments might not work in the future.

So what about EG signals?

Is this true that if we don't have that much activity

or if those tasks have become easier for us,

brain and those neurons are not going to fire

or they're going to fire without oxygen?

So are you talking about the EG tasks here?

Yes, that's true, yes.

I think it's very independent from training.

I mean, according to my experience,

people are really robust and they take

actually a big part of the EG signal

and I think even when people are trained

they're still very robust EG activity.

I feel a little bit confused by the question.

I mean, every time a neuron fires it uses oxygen, right?

Is that true? I'm not sure.

Yes, yes it is.

And then every time it uses oxygen, blood has to flow to that spot.

Okay, so in that case,

consuming oxygen means it's consuming energy.

It's more difficult for me.

If there is something that's routine for me,

that's required less oxygen.

Maybe I'm just too simplifying brain activity,

which probably I am, but is that in high level?

Is that true that when I'm thinking hard

to solve a mathematical problem versus I'm relaxing?

So that's when I'm thinking harder and use my memory,

my brain needs more oxygen.

I guess a good story that can support that idea

is many people claim that they think better

when they go for a walk or something

and their brain is getting more oxygen.

So in that case, if we do something which is routine,

it probably doesn't need that much oxygen

so brains are not going to fire.

brains are not going to fire if their endurance needs oxygen.

This is Sharina and I am currently thinking about

how athletes train in hypoxic environments,

like high up in the mountains in order to get

really good athletic performance even under conditions

where there's not as much oxygen in the environment.

So I think that it really depends on

what the body is able to do with what it has.

Right now I'm also thinking about

how even when we're looking at slices and brain slices,

then the artificial cerebrospinal fluid,

it has bubbles in it.

It has oxygen for the cells to stay alive

as long as possible.

This is Sharina and I am done speaking.

Good Sharina, thank you.

Yes, I think I'm maybe too simplifying brain activity.

Probably there's going to be much, much more activity

going around something, something's happening.

And I think neurons are not going to just consume oxygen,

there's nutrition that they need.

They need both of them in order to fire.

But maybe in some cases with less oxygen

and less nutrition they can even fire.

Or in some other cases they have to consume oxygen

in order to fire.

I can kind of answer that a little bit.

So your cells have to metabolize the nutrition

that they receive and turn that into ATP.

And then ATP is the energy that the cells use

to conduct their physical activities.

This is Sharina.

And I think of this in terms of sodium and potassium pumps

as well as calcium signaling.

So those are the three main molecules

that seem to be involved in transduction of neurons.

So yeah, neurons, they're like a salty banana.

That's how you can think about them.

There is a lot of salt on the outside of neurons

and the insides of neurons, they have a lot of potassium in them.

So when the cell becomes more and more polarized over time,

when more sodium comes in and more potassium flows out,

then eventually it gains a stronger positive charge

and then it fires an action potential.

And this is how brain rhythms and neural circuits work,

which is that action potentials fire

and then they excite or inhibit the next neuron,

depending on whether it is an excitatory or inhibitory neuron.

This is Sharina and I am done talking.

# Part 7

I get out of fun fact that.

Sodium, potassium, and calcium on the periodic table,

these are under the classification of metals.

What's interesting is that they all have positive or negative charges.

And so basically the separation of positive and negative charges

is what leads to the action potential firing.

But there's like an analogy to that to a lightning strike

and that a lightning strike in the sky,

it's a loose analogy just for humor.

But a lightning strike in the sky is basically a separation

of positive and negative charges between the sky and the earth.

And then that results in the action potential,

I'm sorry, the lightning strike,

again just a little bit of analogous humor.

And I like to joke that basically the human beings

are literally metal robots because these electrical charges,

which are based upon the separation of positive and negative charges,

they're like lightning strikes,

that is basically, you can think of that as the root of a brain wave,

that our cells are transmitting like a little bit of electricity, maybe.

And then maybe also the cells are, the electricity is,

or the electromagnetism is bouncing around,

it's altering the positions of positive and negative ions

and other neurons and in that sense that could change

when those other neurons fire.

It's just a hypothesis, but it's a fun idea,

so I just wanted to share that.

I also have some idea I want to share,

I'm not quite sure about it,

but in terms of Adam's question, for example,

effect of neuroplasticity in the level of signal we can got,

I think the signal we've gotten, for example,

EEG is an extracellular signal coming from the chemical grant between the neurons.

So what we do have in neuroplasticity is one thing is

firing the neurons in lower thresholds,

not the high thresholds that used to be fired,

when it is in the first experiences

and the other one is making new paths in the brain.

So I think if, for example, the threshold would be lower

than the initial experiences, it is still fires

and we still got the signals from the extracellular level

and so on.

At the end of the day, we got the signals on EEG

or, for example, if we do get the signals from any source of

nutrition or oxygen or ATP that neural cells use to do this activation.

So I think it might affect a little bit,

but at the end it depends on what threshold we can use to capture the signal

and I think it doesn't be that much that could affect our results

at least in short-term trainings.

Thank you, Petra.

So let me ask this question, if in this paper,

if they run that experiment with the people that they have ADHD

or maybe some other attention or memory problem,

then do you think the result would change?

I think I actually need to think a little bit more about it.

Firstly, it depends on the brain regions we're going to capture the signals from.

So if the regions are not involved in the regions that we expect to be changed

based on ADHD or other situations in the people,

it shouldn't affect the signals, but, for example,

we do have some proof of changes in, for example, functional connectivity

that one part of it, for example, in prefrontal cortex that is in this experiment,

I think, for example, under your singular cortex,

that is more or less connected to some part of the brain functionally,

but what we've got from these experiments to use for that quadcopter control,

I think it's the level of activation and not sometimes like functional connectivity,

which is synchronization or a correlation between two different signals.

So I think it doesn't make any problem, but it still needs to be explored, I think.

That's a great point, yeah.

Sharina, go.

This is Sharina, and I think that when it comes to attention conditions,

what will tend to happen is that the signal that is collected will generally be noisier.

Maybe it will need to be trained upon, but it would be noisier,

not just at one frequency, but across a range of frequencies,

and that will create a sort of challenge for creating a sort of brain-computer interface.

Can a person become better at this stuff over time with training?

You bet.

I'm pretty sure that they can.

This is Sharina, and I am done talking.

# Part 8

I wanted to say sort of...

So I guess if the model of...

So I think some of the EEG devices really failed in terms of the way we went about

trying to devise a control system with EEG,

I guess the analogy is when you get into a car for the first time,

or when you learn anything for the first time,

your brain activity is greater than what it's going to be when you're really good at driving the car.

When you get good at driving the car, your brain activity is greatly reduced

because I would say at first your brain is just trying to figure it out,

it's throwing everything in the kitchen sink at trying to figure out how to drive this car,

and so there's a ton of brain activity,

and maybe your EEG signals will be really great at that point.

So trying to lift the box by thinking like the Jedi Mind Trick toy,

that is very straightforward in the beginning,

but then the better you get at it, the less brain activity it takes for you to accomplish that task,

and so that means that the power of your signals are decreasing,

and so then it becomes harder the more you get at it,

because your signals are decreasing as you get better at it,

and then it just becomes confusing because you were really good at it,

and your brain knows what to do, but it's no longer working

because your brain is not putting as much effort into it,

and so there's sort of like a little paradox with that,

and I think that's why this EEG works really good in the beginning,

but it doesn't seem to keep working.

Anyway, that's just a hypothesis.

I think it also...

Go ahead.

Yeah, sorry, so I think...

That's one of the reasons maybe combining another modality to EEG might help,

so I think EEG might not be good enough,

but it's still going to be useful.

It's going to give us some data if we use a good kind of data analysis model out of it.

This is Sharina, and yeah, I think that it needs to not just be brain signals,

but also behavioral correlates.

For example, performance on some sort of task like navigating a drone

that is going to make it a really good signal

or to see, okay, how is the person actually doing at this task?

Because at the end of the day, what really matters

doesn't matter whether they're able to navigate this thing

or able to pay attention to the things that they want to pay attention to,

or does it matter what their brain activity is at that point

and whether it should be picked up that they are putting a ton of effort.

So is it effort or outcome?

That is a fun question to ask.

This is Sharina, and I am done speaking.

My hypothesis about why this study may have been so successful

on the EEG side of things is that they were actually measuring the EMG

of the muscle movement of the eyes,

and so similar to how Facebook is focusing on the EMG

with their acquisition of control labs or CTRL labs.

I think that at the point when your brain has figured out the most efficient way to do it,

it's still going to consistently trigger the muscle in a consistent way,

even if the EEG activity becomes decreased.

And so I think if you're trying to do a brain-computer interface

by focusing on EMG signals instead of EEG signals,

you might have a more consistent BCI for controlling things,

just what I'm thinking.

I think that's a good point yet.

So we're going to say that.

So I think what they measure,

so the things that they are decoding with the EEG,

these eyeballings are really robust.

It's really not something difficult.

Even with one channel, you can very easily get that eyeballings with EEG.

So they're not trying to decode some mental activities like rotation

or something with EEG.

I think the role of EEG here is just to increase the number of commands

that is used for flying this drone.

And when it comes to the other mental tasks,

so I think regarding your earlier point, Adam,

so I think as for some tasks,

think about, for example, counting backwards or something.

If the task, as you are trained in the task,

if the task is transitioning to another mental activity,

so let's say that you get to memorize these numbers as you're counting backwards.

So if there's a transition between one task to the other,

if it's becoming less of a computational task and more of a memory task,

then I would see much more differentiation.

But if it's a kind of task that requires, still, no matter how much you're trained,

still you have to use, there's no transitioning in between different tasks,

I think it's still probably the effect of the training won't be that good.

But I also saw a lot of papers looking into trial-to-trial variability in FNIR signals.

I think that's a huge field.

So, yeah, I think that's probably a problem only for some group of tasks,

not all probably.

That's a good point. Thank you, Shayla.

And regarding my point on using EMG,

I kind of agree with that because at the end of the day,

there's a couple of muscles that they need to move,

and also the quality of the EMG signals are going to be better than EEG.

And combining those three EMG, EEG and FNIRs,

it might give us a better kind of information regarding what's going on in the brain

and what are the commands that you're thinking about,

and we can just control some sort of computer out of our brain.

Go ahead.

This is Sharina, and I remember playing Mario Kart as a kid.

And a really strange thing would happen,

especially when a person started playing for the first time,

which is that they would take this game controller,

and they would move their entire body while trying to move this virtual Kart around,

even though the controller, it didn't do anything.

I mean, it could not sense motion.

It was just a game cube controller.

So it's kind of fun to consider,

okay, how do people try to control devices?

How do they try to do this with not just their brain activity,

but with their muscles, at least at first?

And can they get this stuff to happen just in their brains,

just as people figure out over time in Mario Kart

that's turning their whole body,

does not actually make the Kart change direction.

It's just the movement of the fingers and thinking about things in that way,

instead of kind of overfitting and doing things that are just completely instinctual.

But working with human factors and thinking about what is instinctual

and would get something easier to use,

it's super fun as well,

and it's a huge problem in the world of brain-computer interfaces.

And I think that could make things better

if these signals are picked up in an efficient way.